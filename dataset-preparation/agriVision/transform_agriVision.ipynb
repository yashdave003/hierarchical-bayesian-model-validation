{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"agriVision\"\n",
    "FINAL_DATA_NAME = 'agriVision-full-fourier' # + channel\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"agriVision-RGB-cleaned-jitter\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','agriVision')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonmarks/opt/anaconda3/envs/HBMV/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/brandonmarks/opt/anaconda3/envs/HBMV/lib/python3.10/site-packages/numpy/_core/_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def get_batches(image_folder):\n",
    "    images = glob(os.path.join(image_folder, '*.jpg'))\n",
    "    batches = {}\n",
    "    for img in images:\n",
    "        prefix = os.path.basename(img)[:9]\n",
    "        batches.setdefault(prefix, []).append(img)\n",
    "    return batches\n",
    "\n",
    "def calculate_batch_avg_and_std_rgb(batch_images):\n",
    "    r_values, g_values, b_values = [], [], []\n",
    "    for img_path in batch_images:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        b, g, r = cv2.split(img.astype(np.float32))\n",
    "        r_values.append(r.mean())\n",
    "        g_values.append(g.mean())\n",
    "        b_values.append(b.mean())\n",
    "    # fallback if empty\n",
    "    if not r_values:\n",
    "        return (0,0,0), (1,1,1)\n",
    "    means = (np.mean(r_values), np.mean(g_values), np.mean(b_values))\n",
    "    stds  = (np.std(r_values)   or 1.0,\n",
    "             np.std(g_values)   or 1.0,\n",
    "             np.std(b_values)   or 1.0)\n",
    "    return means, stds\n",
    "\n",
    "def calculate_overall_avg_rgb(batches):\n",
    "    batch_avgs = []\n",
    "    for imgs in batches.values():\n",
    "        avg, _ = calculate_batch_avg_and_std_rgb(imgs)\n",
    "        batch_avgs.append(avg)\n",
    "    return np.mean(batch_avgs, axis=0)\n",
    "\n",
    "def adjust_image_color(img, batch_avg_rgb, batch_std_rgb, overall_avg_rgb):\n",
    "    b, g, r = cv2.split(img.astype(np.float32))\n",
    "    r_n = (r - batch_avg_rgb[0]) / batch_std_rgb[0]\n",
    "    g_n = (g - batch_avg_rgb[1]) / batch_std_rgb[1]\n",
    "    b_n = (b - batch_avg_rgb[2]) / batch_std_rgb[2]\n",
    "    return cv2.merge([b_n, g_n, r_n])\n",
    "\n",
    "batches       = get_batches(data_dir)\n",
    "overall_avg   = calculate_overall_avg_rgb(batches)\n",
    "\n",
    "# ── 3) Precompute each batch’s stats once ─────────────────────────────────────\n",
    "batch_stats = {\n",
    "    prefix: calculate_batch_avg_and_std_rgb(imgs)\n",
    "    for prefix, imgs in batches.items()\n",
    "}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def batch_image_opener(path):\n",
    "    # 1) load as uint8 BGR\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image {path!r}\")\n",
    "    \n",
    "    # 2) cast to float32 and add jitter in (-0.5, 0.5)\n",
    "    img = img.astype(np.float32)\n",
    "    img += np.random.uniform(-0.5, 0.5, size=img.shape).astype(np.float32)\n",
    "    \n",
    "    # 3) lookup this file’s batch stats\n",
    "    prefix            = os.path.basename(path)[:9]\n",
    "    batch_avg, batch_std = batch_stats[prefix]\n",
    "    \n",
    "    # 4) normalize each channel\n",
    "    b, g, r = cv2.split(img)\n",
    "    r_n = (r - batch_avg[0]) / batch_std[0]\n",
    "    g_n = (g - batch_avg[1]) / batch_std[1]\n",
    "    b_n = (b - batch_avg[2]) / batch_std[2]\n",
    "    \n",
    "    return cv2.merge([b_n, g_n, r_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_list = [os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "#file_names = os.listdir(os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\"))\n",
    "#file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch0-agriVision-RGB-cleaned-jitter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008052940675034493, 0.009260881776289667, 0.010650014042733115, 0.012247516149143082, 0.014084643571514543, 0.016197340107241723, 0.01862694112332798, 0.021420982291827175, 0.02463412963560125, 0.028329249080941435, 0.03257863644308265, 0.037465431909545044, 0.0430852466959768, 0.04954803370037331, 0.056980238755429305, 0.0655272745687437, 0.07535636575405526, 0.08665982061716354, 0.09965879370973807, 0.11460761276619877, 0.13179875468112856, 0.15156856788329784, 0.1743038530657925, 0.20044943102566135, 0.23051684567951053, 0.2650943725314371, 0.30485852841115263, 0.3505873076728255, 0.4031754038237493, 0.4636517143973116, 0.5331994715569083, 0.6131793922904445, 0.7051563011340111]\n"
     ]
    }
   ],
   "source": [
    "#Values obtained from plots in agriVisionFourierEDA.ipynb\n",
    "STARTING_VALUE = 0.008052940675034493\n",
    "ENDING_VALUE =0.6162627813472334\n",
    "MULT_FACTOR = 1.15\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"full-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")\n",
    "splits = getSplits(STARTING_VALUE,ENDING_VALUE, MULT_FACTOR)\n",
    "print(splits)\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997de17aa6c84a059b85351420571f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00805294 0.00926088 0.01065001 0.01224752 0.01408464 0.01619734\n",
      " 0.01862694 0.02142098 0.02463413 0.02832925 0.03257864 0.03746543\n",
      " 0.04308525 0.04954803 0.05698024 0.06552727 0.07535637 0.08665982\n",
      " 0.09965879 0.11460761 0.13179875 0.15156857 0.17430385 0.20044943\n",
      " 0.23051685 0.26509437 0.30485853 0.35058731 0.4031754  0.46365171\n",
      " 0.53319947 0.61317939 0.7051563 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8ba9f200b14742bb3229fc2556161f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[394.01752, -666.80164, -88.65232, -346.69336,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[26.300114, -5.951352, 4.2881002, 0.008455452,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[3.9159238, -3.8455935, -2.5847917, -1.3373663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-15.701049, 0.2895618, 1.8884472, 0.5027741, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-6.3131824, 2.3397906, -2.8301606, -0.4491938...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1     red                              (0.0, 0.0078125)   \n",
       "1     2     red  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3     red           (0.009765625, 0.010517900013934578)   \n",
       "3     4     red   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5     red  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [394.01752, -666.80164, -88.65232, -346.69336,...  \n",
       "1                  3  [26.300114, -5.951352, 4.2881002, 0.008455452,...  \n",
       "2                  3  [3.9159238, -3.8455935, -2.5847917, -1.3373663...  \n",
       "3                  4  [-15.701049, 0.2895618, 1.8884472, 0.5027741, ...  \n",
       "4                  6  [-6.3131824, 2.3397906, -2.8301606, -0.4491938...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae6b3836527490eb5d30601fe5501ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00805294 0.00926088 0.01065001 0.01224752 0.01408464 0.01619734\n",
      " 0.01862694 0.02142098 0.02463413 0.02832925 0.03257864 0.03746543\n",
      " 0.04308525 0.04954803 0.05698024 0.06552727 0.07535637 0.08665982\n",
      " 0.09965879 0.11460761 0.13179875 0.15156857 0.17430385 0.20044943\n",
      " 0.23051685 0.26509437 0.30485853 0.35058731 0.4031754  0.46365171\n",
      " 0.53319947 0.61317939 0.7051563 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afe1fe865e74e2c859819d1dea35bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[12.3713455, 388.75546, -71.01328, -525.39044,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[22.61509, -0.59491116, 7.503033, 3.4321887, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[11.672611, -2.066029, -1.9847326, 0.059833866...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-18.854862, 2.5201974, 4.3448296, -0.93405235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-4.9581738, 0.85346955, -1.0683059, -1.863001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1    blue                              (0.0, 0.0078125)   \n",
       "1     2    blue  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3    blue           (0.009765625, 0.010517900013934578)   \n",
       "3     4    blue   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5    blue  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [12.3713455, 388.75546, -71.01328, -525.39044,...  \n",
       "1                  3  [22.61509, -0.59491116, 7.503033, 3.4321887, -...  \n",
       "2                  3  [11.672611, -2.066029, -1.9847326, 0.059833866...  \n",
       "3                  4  [-18.854862, 2.5201974, 4.3448296, -0.93405235...  \n",
       "4                  6  [-4.9581738, 0.85346955, -1.0683059, -1.863001...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05afb58d43c94ccab66d2ffeffa71f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00805294 0.00926088 0.01065001 0.01224752 0.01408464 0.01619734\n",
      " 0.01862694 0.02142098 0.02463413 0.02832925 0.03257864 0.03746543\n",
      " 0.04308525 0.04954803 0.05698024 0.06552727 0.07535637 0.08665982\n",
      " 0.09965879 0.11460761 0.13179875 0.15156857 0.17430385 0.20044943\n",
      " 0.23051685 0.26509437 0.30485853 0.35058731 0.4031754  0.46365171\n",
      " 0.53319947 0.61317939 0.7051563 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab22fe3647344b79447c50742715b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[166.3832, -696.2711, -199.10786, -450.90964, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[39.019962, -3.128594, 4.1378517, 0.6378156, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[16.50757, -3.9409359, -2.0181026, -1.2763121,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-23.129368, 0.29991105, 2.0272126, 0.13882986...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-3.069001, 2.3259537, -1.939445, -0.5935018, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1   green                              (0.0, 0.0078125)   \n",
       "1     2   green  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3   green           (0.009765625, 0.010517900013934578)   \n",
       "3     4   green   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5   green  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [166.3832, -696.2711, -199.10786, -450.90964, ...  \n",
       "1                  3  [39.019962, -3.128594, 4.1378517, 0.6378156, -...  \n",
       "2                  3  [16.50757, -3.9409359, -2.0181026, -1.2763121,...  \n",
       "3                  4  [-23.129368, 0.29991105, 2.0272126, 0.13882986...  \n",
       "4                  6  [-3.069001, 2.3259537, -1.939445, -0.5935018, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de2c1e8c7164481a214a8486c986f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00805294 0.00926088 0.01065001 0.01224752 0.01408464 0.01619734\n",
      " 0.01862694 0.02142098 0.02463413 0.02832925 0.03257864 0.03746543\n",
      " 0.04308525 0.04954803 0.05698024 0.06552727 0.07535637 0.08665982\n",
      " 0.09965879 0.11460761 0.13179875 0.15156857 0.17430385 0.20044943\n",
      " 0.23051685 0.26509437 0.30485853 0.35058731 0.4031754  0.46365171\n",
      " 0.53319947 0.61317939 0.7051563 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd01e2ca98b44aebb36179e6768b904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[216.8491, -563.7, -151.47, -428.2051, 602.027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[33.34394, -3.6831636, 4.565978, 0.7681947, -2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[12.191092, -3.6983044, -2.1834798, -1.1421131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-20.419437, 0.5499004, 2.249741, 0.12529033, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-4.2537456, 2.1619937, -2.1061761, -0.6950318...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1    gray                              (0.0, 0.0078125)   \n",
       "1     2    gray  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3    gray           (0.009765625, 0.010517900013934578)   \n",
       "3     4    gray   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5    gray  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [216.8491, -563.7, -151.47, -428.2051, 602.027...  \n",
       "1                  3  [33.34394, -3.6831636, 4.565978, 0.7681947, -2...  \n",
       "2                  3  [12.191092, -3.6983044, -2.1834798, -1.1421131...  \n",
       "3                  4  [-20.419437, 0.5499004, 2.249741, 0.12529033, ...  \n",
       "4                  6  [-4.2537456, 2.1619937, -2.1061761, -0.6950318...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_NUM = 0\n",
    "FINAL_DATA_NAME = 'agriVision-full-wavelet'\n",
    "if BATCH_NUM is None: \n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"full-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brandonmarks/Desktop/hierarchical-bayesian-model-validation/raw-data/agriVision/batch0-agriVision-RGB-cleaned-jitter'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b96e43a524460186340e4e5e420c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099611</td>\n",
       "      <td>L1</td>\n",
       "      <td>[394.01746, -666.8014, -88.65229, -346.69324, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>D</td>\n",
       "      <td>[-79.15201, 5.5634704, -78.94214, 2.1960812, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>H</td>\n",
       "      <td>[493.79977, 17.223394, 125.77101, 35.972504, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>V</td>\n",
       "      <td>[-525.7385, 29.98764, -39.575523, 13.5215, -49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>3</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-235.7246, -6.8624268, -2.5247765, 127.96384,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0     red      1   0.099611          L1   \n",
       "1     red      2   0.110679           D   \n",
       "2     red      2   0.110679           H   \n",
       "3     red      2   0.110679           V   \n",
       "4     red      3   0.124514           D   \n",
       "\n",
       "                                                data  \n",
       "0  [394.01746, -666.8014, -88.65229, -346.69324, ...  \n",
       "1  [-79.15201, 5.5634704, -78.94214, 2.1960812, 1...  \n",
       "2  [493.79977, 17.223394, 125.77101, 35.972504, -...  \n",
       "3  [-525.7385, 29.98764, -39.575523, 13.5215, -49...  \n",
       "4  [-235.7246, -6.8624268, -2.5247765, 127.96384,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-horizVert-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-horizVert-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-horizVert-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-horizVert-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_wv[(channel_wv['orientation'] == 'D') & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agriVision-full-wavelet-diagonal-red.pickle'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{FINAL_DATA_NAME}-diagonal-{channel}.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bd5e135ff646608a5fb0f17de14104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099611</td>\n",
       "      <td>L1</td>\n",
       "      <td>[166.38313, -696.2709, -199.10779, -450.9095, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>D</td>\n",
       "      <td>[-78.687256, 1.6996417, -69.56931, 4.1930723, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>H</td>\n",
       "      <td>[470.17047, 14.006964, 113.739845, 31.497345, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>V</td>\n",
       "      <td>[-340.00568, 20.368378, -35.560028, 18.069427,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>green</td>\n",
       "      <td>3</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-148.00755, 9.828606, -40.51377, 67.99269, -2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0   green      1   0.099611          L1   \n",
       "1   green      2   0.110679           D   \n",
       "2   green      2   0.110679           H   \n",
       "3   green      2   0.110679           V   \n",
       "4   green      3   0.124514           D   \n",
       "\n",
       "                                                data  \n",
       "0  [166.38313, -696.2709, -199.10779, -450.9095, ...  \n",
       "1  [-78.687256, 1.6996417, -69.56931, 4.1930723, ...  \n",
       "2  [470.17047, 14.006964, 113.739845, 31.497345, ...  \n",
       "3  [-340.00568, 20.368378, -35.560028, 18.069427,...  \n",
       "4  [-148.00755, 9.828606, -40.51377, 67.99269, -2...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-horizVert-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-horizVert-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-horizVert-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-horizVert-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_wv[(channel_wv['orientation'] == 'D') & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebef5f6468a843ce82fe5691b99b12db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099611</td>\n",
       "      <td>L1</td>\n",
       "      <td>[12.371368, 388.7553, -71.01327, -525.39026, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>D</td>\n",
       "      <td>[-56.829453, 10.117099, -65.62854, 3.6826935, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>H</td>\n",
       "      <td>[426.78058, 36.812557, 2.2249393, 41.117294, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>V</td>\n",
       "      <td>[-458.5982, 52.58409, -45.257187, -4.22406, 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-192.27968, 1.2400818, -6.41411, 114.561295, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    blue      1   0.099611          L1   \n",
       "1    blue      2   0.110679           D   \n",
       "2    blue      2   0.110679           H   \n",
       "3    blue      2   0.110679           V   \n",
       "4    blue      3   0.124514           D   \n",
       "\n",
       "                                                data  \n",
       "0  [12.371368, 388.7553, -71.01327, -525.39026, -...  \n",
       "1  [-56.829453, 10.117099, -65.62854, 3.6826935, ...  \n",
       "2  [426.78058, 36.812557, 2.2249393, 41.117294, 3...  \n",
       "3  [-458.5982, 52.58409, -45.257187, -4.22406, 4....  \n",
       "4  [-192.27968, 1.2400818, -6.41411, 114.561295, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-horizVert-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-horizVert-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-horizVert-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-horizVert-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_wv[(channel_wv['orientation'] == 'D') & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343eb6e1e46d4762a4188e8b801b85fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gray</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099611</td>\n",
       "      <td>L1</td>\n",
       "      <td>[216.8491, -563.7, -151.47, -428.2051, 602.027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>D</td>\n",
       "      <td>[-76.326515, 3.813951, -71.914665, 3.537564, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>H</td>\n",
       "      <td>[472.23996, 17.566793, 104.61193, 33.9285, 1.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>V</td>\n",
       "      <td>[-409.00687, 26.91413, -37.862198, 14.166796, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gray</td>\n",
       "      <td>3</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-179.25845, 3.859598, -25.267452, 91.22012, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    gray      1   0.099611          L1   \n",
       "1    gray      2   0.110679           D   \n",
       "2    gray      2   0.110679           H   \n",
       "3    gray      2   0.110679           V   \n",
       "4    gray      3   0.124514           D   \n",
       "\n",
       "                                                data  \n",
       "0  [216.8491, -563.7, -151.47, -428.2051, 602.027...  \n",
       "1  [-76.326515, 3.813951, -71.914665, 3.537564, 1...  \n",
       "2  [472.23996, 17.566793, 104.61193, 33.9285, 1.6...  \n",
       "3  [-409.00687, 26.91413, -37.862198, 14.166796, ...  \n",
       "4  [-179.25845, 3.859598, -25.267452, 91.22012, -...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-horizVert-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-horizVert-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-horizVert-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-horizVert-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_wv[(channel_wv['orientation'] == 'D') & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HBMV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
