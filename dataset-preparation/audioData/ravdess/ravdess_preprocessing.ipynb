{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign directory\n",
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "from plotting import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "\n",
    "data_dir  = os.path.join(ROOT_DIR, 'raw-data', 'ravdess', 'full-ravdess-wav')\n",
    "# iterate over files in that directory\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename != \".DS_Store\"]\n",
    "file_names = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2627130",
   "metadata": {},
   "source": [
    "## Audio Processing using Librosa and soundfile\n",
    "\n",
    "* Detects audio files that contain clipping and removes them from the data set\n",
    "* Filters out beginning and end silence \n",
    "* Normalizes loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa #Need to pip install librosa \n",
    "import soundfile as sf #Need to pip install soundfile\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates new wav files that have been processed\n",
    "\n",
    "CLIP_THRESHOLD = 1 \n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, 'raw-data', 'ravdess', 'full-ravdess-wav-processed')\n",
    "\n",
    "def is_clipped(y, threshold = CLIP_THRESHOLD):\n",
    "    return np.any(np.abs(y) >= threshold)\n",
    "\n",
    "def normalize_peaks(y):\n",
    "    return (y - np.mean(y))/ np.std(y) if np.std(y) > 0 else y\n",
    "\n",
    "def normalize_pitch_shifting(y, sr, target_hz=150.0):\n",
    "    f0, voiced_flag, _ = librosa.pyin(y, \n",
    "                                      fmin=librosa.note_to_hz('C2'), \n",
    "                                      fmax=librosa.note_to_hz('C7'))\n",
    "    \n",
    "    voiced_f0 = f0[voiced_flag]\n",
    "    voiced_f0 = voiced_f0[~np.isnan(voiced_f0)]\n",
    "\n",
    "    current_pitch_hz = np.median(voiced_f0)\n",
    "    if current_pitch_hz <= 0:\n",
    "        return y\n",
    "    n_steps = 12 * np.log2(target_hz / current_pitch_hz)\n",
    "\n",
    "    y_shifted = librosa.effects.pitch_shift(y=y, sr=sr, n_steps=n_steps)\n",
    "    \n",
    "    return y_shifted\n",
    "\n",
    "def process_audio_file(filename):\n",
    "    if filename.lower().endswith('wav'):\n",
    "        path_in = os.path.join(data_dir, filename)\n",
    "        path_out = os.path.join(OUTPUT_DIR, filename)\n",
    "        \n",
    "        y, sr = librosa.load(path_in, sr=None)\n",
    "\n",
    "        if is_clipped(y):\n",
    "            return\n",
    "\n",
    "        y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "        \n",
    "        # pitch normalization\n",
    "        y_normalized = normalize_pitch_shifting(y_trimmed, sr, target_hz=150.0)\n",
    "\n",
    "        y_loudness_normalized = normalize_peaks(y_normalized) \n",
    "\n",
    "        sf.write(path_out, y_loudness_normalized, sr)\n",
    "\n",
    "try:\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "total_files = len(file_names)\n",
    "print(f\"Starting processing for {total_files} files...\")\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(process_audio_file)(filename) for filename in tqdm(file_names, desc=\"Processing audio files\"))\n",
    "\n",
    "print(\"\\nProcessing complete. All files have been handled.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
