{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign directory\n",
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "from plotting import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "DATA = 'ravdess'\n",
    "\n",
    "data_dir  = os.path.join(ROOT_DIR, 'raw-data', DATA, f\"full-{DATA}-audio\")\n",
    "# iterate over files in that directory\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename != \".DS_Store\"]\n",
    "file_names = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2627130",
   "metadata": {},
   "source": [
    "## Audio Processing using Librosa and soundfile\n",
    "\n",
    "* Detects audio files that contain clipping and removes them from the data set\n",
    "* Filters out beginning and end silence \n",
    "* Normalizes loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd38682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf #Need to pip install soundfile\n",
    "import librosa #Need to pip install librosa \n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17750ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing for 1441 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing audio files: 100%|██████████| 1441/1441 [00:02<00:00, 632.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete. All files have been handled.\n"
     ]
    }
   ],
   "source": [
    "#Creates new wav files that have been processed\n",
    "\n",
    "CLIP_THRESHOLD = 1 \n",
    "NORMALIZE = 0 # 1 for pitch normalization, 0 for no pitch normalization\n",
    "TRIM = 1 # 1 for trimming silence, 0 for no trimming\n",
    "SILENCE_THRESHOLD = 20 #smaller is more sensitive\n",
    "\n",
    "dir_suffix = []\n",
    "if NORMALIZE == 1:\n",
    "    dir_suffix.append('pitch-normalized')\n",
    "if TRIM == 1:\n",
    "    dir_suffix.append('trimmed')\n",
    "\n",
    "if dir_suffix:\n",
    "    suffix = '-'.join(dir_suffix)\n",
    "    OUTPUT_DIR = os.path.join(ROOT_DIR, 'raw-data', DATA, f'full-{DATA}-audio-processed-{suffix}')\n",
    "else:\n",
    "    OUTPUT_DIR = os.path.join(ROOT_DIR, 'raw-data', DATA, f'full-{DATA}-audio-processed')\n",
    "\n",
    "def is_clipped(y, threshold = CLIP_THRESHOLD):\n",
    "    return np.any(np.abs(y) >= threshold)\n",
    "\n",
    "def normalize_peaks(y):\n",
    "    return (y - np.mean(y))/ np.std(y) if np.std(y) > 0 else y\n",
    "\n",
    "def normalize_pitch_shifting(y, sr, target_hz=150.0):\n",
    "    f0, voiced_flag, _ = librosa.pyin(y, \n",
    "                                      fmin=librosa.note_to_hz('C2'), \n",
    "                                      fmax=librosa.note_to_hz('C7'))\n",
    "    \n",
    "    voiced_f0 = f0[voiced_flag]\n",
    "    voiced_f0 = voiced_f0[~np.isnan(voiced_f0)]\n",
    "\n",
    "    current_pitch_hz = np.median(voiced_f0)\n",
    "    if current_pitch_hz <= 0:\n",
    "        return y\n",
    "    n_steps = 12 * np.log2(target_hz / current_pitch_hz)\n",
    "\n",
    "    y_shifted = librosa.effects.pitch_shift(y=y, sr=sr, n_steps=n_steps)\n",
    "    \n",
    "    return y_shifted\n",
    "\n",
    "def remove_silence(y, threshold = SILENCE_THRESHOLD): #smaller is more sensitive\n",
    "    silent_intervals = librosa.effects.split(y, top_db = threshold)\n",
    "    y = np.concatenate([y[start:end] for start, end in silent_intervals])\n",
    "    return y\n",
    "\n",
    "def process_audio_file(filename, pitch_normalize = False, trim_silence = False):\n",
    "    if filename.lower().endswith('wav'):\n",
    "        path_in = os.path.join(data_dir, filename)\n",
    "        path_out = os.path.join(OUTPUT_DIR, filename)\n",
    "        \n",
    "        y, sr = librosa.load(path_in, sr=None)\n",
    "\n",
    "        if is_clipped(y):\n",
    "            return\n",
    "\n",
    "        y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "        \n",
    "        y_proc = y_trimmed\n",
    "        if trim_silence:\n",
    "            y_proc = remove_silence(y if pitch_normalize else y_trimmed)\n",
    "        if pitch_normalize:\n",
    "            y_proc = normalize_pitch_shifting(y_proc, sr, target_hz=150.0)\n",
    "        y_loudness_normalized = normalize_peaks(y_proc)\n",
    "\n",
    "        sf.write(path_out, y_loudness_normalized, sr)\n",
    "\n",
    "try:\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "total_files = len(file_names)\n",
    "print(f\"Starting processing for {total_files} files...\")\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(process_audio_file)(filename, trim_silence = TRIM, pitch_normalize = NORMALIZE) for filename in tqdm(file_names, desc=\"Processing audio files\"))\n",
    "\n",
    "print(\"\\nProcessing complete. All files have been handled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ece697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changes dataset to post-processed dataset\n",
    "data_dir = OUTPUT_DIR\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename != \".DS_Store\"]\n",
    "file_names = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b5d72f",
   "metadata": {},
   "source": [
    "## numpy representation\n",
    "\n",
    "using `scipy.io.wavfile.read(filename)` to intake .wav audio files \n",
    "\n",
    "> returns \n",
    "> * rate, registing the hertz of the audio \n",
    "> * data, an array with each index representing a point in time for the audio and its value representing amplitude at said time \n",
    ">   * index position divided by the length of array represents its temporal occurence in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f3e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ed4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_rates, wav_coeffs = zip(*[wavfile.read(file) for file in file_list])\n",
    "wav_rates = np.array(wav_rates)\n",
    "wav_coeffs = np.array(wav_coeffs, dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d5ef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert len(wav_rates) == len(wav_rates), \"Check for lossy data in .wav scipy numpy representation\"\n",
    "n = len(wav_rates)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_lengths = pd.Series(wav_coeffs).apply(len) / wav_rates[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68cda2e",
   "metadata": {},
   "source": [
    "## info parsing to .csv\n",
    "\n",
    "file naming conventions (from RAVDESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = {\n",
    "    \"01\": \"full-AV\", \n",
    "    \"02\": \"video-only\",\n",
    "    \"03\": \"audio-only\"\n",
    "} \n",
    "\n",
    "channels = {\n",
    "    \"01\": \"speech\",\n",
    "    \"02\": \"song\"\n",
    "}\n",
    "\n",
    "emotions = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"suprised\",\n",
    "} \n",
    "\n",
    "intensities = {\n",
    "    \"01\": \"normal\",\n",
    "    \"02\": \"strong\"\n",
    "}\n",
    "\n",
    "statements = {\n",
    "    \"01\": \"Kids are talking by the door\",\n",
    "    \"02\": \"Dogs are sitting by the door\"\n",
    "}\n",
    "\n",
    "speaker_sex = [\"female\", \"male\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modality</th>\n",
       "      <th>channel</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>statement</th>\n",
       "      <th>repetition</th>\n",
       "      <th>actor</th>\n",
       "      <th>sex</th>\n",
       "      <th>filename</th>\n",
       "      <th>length (s)</th>\n",
       "      <th>rate (Hz)</th>\n",
       "      <th>amplitudes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio-only</td>\n",
       "      <td>speech</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>03-01-01-01-01-01-01.wav</td>\n",
       "      <td>1.194667</td>\n",
       "      <td>48000</td>\n",
       "      <td>[-4883, -8277, -6176, 2673, 1426, 4029, -9323,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio-only</td>\n",
       "      <td>speech</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>03-01-01-01-01-01-02.wav</td>\n",
       "      <td>1.493333</td>\n",
       "      <td>48000</td>\n",
       "      <td>[1650, -7080, -14393, -15750, -13091, -10771, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio-only</td>\n",
       "      <td>speech</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>03-01-01-01-01-01-03.wav</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>48000</td>\n",
       "      <td>[-1923, 1238, 6424, 4895, -3206, -6331, -5615,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio-only</td>\n",
       "      <td>speech</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>03-01-01-01-01-01-04.wav</td>\n",
       "      <td>1.269333</td>\n",
       "      <td>48000</td>\n",
       "      <td>[9592, 2479, -5311, -7207, -23370, -7113, 1322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio-only</td>\n",
       "      <td>speech</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "      <td>03-01-01-01-01-01-05.wav</td>\n",
       "      <td>1.525333</td>\n",
       "      <td>48000</td>\n",
       "      <td>[-4330, 4490, 4748, -7338, -3693, 2737, 1192, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     modality channel  emotion intensity                     statement  \\\n",
       "0  audio-only  speech  neutral    normal  Kids are talking by the door   \n",
       "1  audio-only  speech  neutral    normal  Kids are talking by the door   \n",
       "2  audio-only  speech  neutral    normal  Kids are talking by the door   \n",
       "3  audio-only  speech  neutral    normal  Kids are talking by the door   \n",
       "4  audio-only  speech  neutral    normal  Kids are talking by the door   \n",
       "\n",
       "   repetition  actor     sex                  filename  length (s)  rate (Hz)  \\\n",
       "0           1      1    male  03-01-01-01-01-01-01.wav    1.194667      48000   \n",
       "1           1      2  female  03-01-01-01-01-01-02.wav    1.493333      48000   \n",
       "2           1      3    male  03-01-01-01-01-01-03.wav    1.344000      48000   \n",
       "3           1      4  female  03-01-01-01-01-01-04.wav    1.269333      48000   \n",
       "4           1      5    male  03-01-01-01-01-01-05.wav    1.525333      48000   \n",
       "\n",
       "                                          amplitudes  \n",
       "0  [-4883, -8277, -6176, 2673, 1426, 4029, -9323,...  \n",
       "1  [1650, -7080, -14393, -15750, -13091, -10771, ...  \n",
       "2  [-1923, 1238, 6424, 4895, -3206, -6331, -5615,...  \n",
       "3  [9592, 2479, -5311, -7207, -23370, -7113, 1322...  \n",
       "4  [-4330, 4490, 4748, -7338, -3693, 2737, 1192, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ravdess_cols = [\"modality\", \"channel\", \"emotion\", \"intensity\", \"statement\", \"repetition\", \"actor\", \"sex\", \"filename\"]\n",
    "rows = []\n",
    "\n",
    "for f in file_names:\n",
    "    if f != \".DS_Store\":\n",
    "        parsed_info = f[:-4].split(\"-\")\n",
    "\n",
    "        modality = modalities[parsed_info[0]]\n",
    "        channel = channels[parsed_info[1]]\n",
    "        emotion = emotions[parsed_info[2]]\n",
    "        intensity = intensities[parsed_info[3]]\n",
    "        sentence = statements[parsed_info[4]]\n",
    "        rep = int(parsed_info[5])\n",
    "        no1 = int(parsed_info[6])\n",
    "        sx = speaker_sex[no1 % 2]\n",
    "\n",
    "        rows.append({\n",
    "            \"modality\": modality,\n",
    "            \"channel\": channel,\n",
    "            \"emotion\": emotion,\n",
    "            \"intensity\": intensity,\n",
    "            \"statement\": sentence,\n",
    "            \"repetition\": rep,\n",
    "            \"actor\": no1,\n",
    "            \"sex\": sx,\n",
    "            \"filename\": f\n",
    "        })\n",
    "\n",
    "ravdess_df = pd.DataFrame(rows, columns=ravdess_cols)\n",
    "\n",
    "\n",
    "ravdess_df[\"length (s)\"] = wav_lengths\n",
    "ravdess_df[\"rate (Hz)\"] = wav_rates\n",
    "ravdess_df[\"amplitudes\"] = wav_coeffs\n",
    "\n",
    "ravdess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xport_name = f\"full-{DATA}.csv\"\n",
    "EXPORT_DIR = os.path.join(ROOT_DIR, \"raw-data\", DATA)\n",
    "EXPORT_PATH = os.path.join(EXPORT_DIR, xport_name)\n",
    "\n",
    "ravdess_df.to_csv(EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd2a850",
   "metadata": {},
   "source": [
    "## npz representation export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DIR = os.path.join(ROOT_DIR, 'raw-data', DATA, f'full-{DATA}-npz')\n",
    "\n",
    "try:\n",
    "    os.mkdir(EXPORT_DIR)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "for f in np.arange(len(file_list)):\n",
    "    coef = wav_coeffs[f]\n",
    "    file_name = file_list[f][-24:-4] ## removes the .wav naming convention\n",
    "\n",
    "    np.savez(os.path.join(EXPORT_DIR, file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
