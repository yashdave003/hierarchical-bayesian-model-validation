{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"segmentAnything\"\n",
    "FINAL_DATA_NAME = 'segmentAnything-full-wavelet-horizontal' # + channel\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"toy-segmentAnything-resizedBlurred-normalized\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','segmentAnything')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sa_1.npz', 'sa_1000.npz', 'sa_10002.npz', 'sa_10006.npz', 'sa_10007.npz']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "1 batches created\n"
     ]
    }
   ],
   "source": [
    "# '''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 5000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'segmentAnything') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toy-segmentAnything-resizedBlurred-normalized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def npz_opener_pickle(path):\n",
    "    # Load the .npz file\n",
    "    with np.load(path) as data:\n",
    "        arr = data['image']  # Default key if saved without naming the array\n",
    "\n",
    "    arr = arr.astype(np.float32)\n",
    "    \n",
    "    # Apply jitter\n",
    "    jitter = np.random.uniform(-0.5, 0.5, arr.shape)\n",
    "    arr += jitter\n",
    "    arr = np.clip(arr, 0, 255)\n",
    "    \n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'segmentAnything-full-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"segmentAnything\", f\"{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"segmentAnything\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572c1e4d3f624f359b470d28784fef6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-678.17676, -652.22003, -627.13464, ...,  635.1172 ,  642.8971 ,\n",
      "        668.0058 ], dtype=float32), np.int64(3): array([-383.4756 , -350.61157, -344.27124, ...,  358.90594,  383.8398 ,\n",
      "        439.1955 ], dtype=float32), np.int64(4): array([-197.38457, -194.1794 , -193.46155, ...,  213.51157,  217.4771 ,\n",
      "        233.04819], dtype=float32), np.int64(5): array([-120.972855, -113.009445, -111.623   , ...,  112.34401 ,\n",
      "        117.64409 ,  123.9428  ], dtype=float32), np.int64(6): array([-64.19457 , -57.760605, -56.30384 , ...,  56.519196,  57.852917,\n",
      "        62.611885], dtype=float32), np.int64(7): array([-31.164955, -28.736496, -27.866615, ...,  28.118803,  29.118126,\n",
      "        31.532665], dtype=float32), np.int64(8): array([-16.524029, -14.629215, -14.146246, ...,  14.208488,  14.647401,\n",
      "        16.376846], dtype=float32), np.int64(9): array([-8.73206  , -7.6480093, -7.4027996, ...,  7.3780775,  7.6129622,\n",
      "        8.550173 ], dtype=float32), np.int64(10): array([-4.562013 , -4.1404886, -4.030632 , ...,  4.010283 ,  4.126378 ,\n",
      "        4.558702 ], dtype=float32)}\n",
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f484c965b294e2189bcea3a61678882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-507.0229 , -474.34564, -471.00323, ...,  524.03986,  526.02856,\n",
      "        558.3641 ], dtype=float32), np.int64(3): array([-365.56583, -336.74982, -331.74265, ...,  352.39352,  353.48416,\n",
      "        357.52692], dtype=float32), np.int64(4): array([-235.2328 , -233.21875, -220.95795, ...,  209.02469,  214.79887,\n",
      "        233.7411 ], dtype=float32), np.int64(5): array([-124.15203 , -113.04047 , -111.39036 , ...,  120.61478 ,\n",
      "        123.81845 ,  125.086914], dtype=float32), np.int64(6): array([-62.513077, -58.668137, -56.83395 , ...,  57.358032,  59.190853,\n",
      "        62.479527], dtype=float32), np.int64(7): array([-32.244205, -28.7179  , -27.849846, ...,  28.041912,  28.957552,\n",
      "        32.651352], dtype=float32), np.int64(8): array([-16.44661 , -14.61588 , -14.133879, ...,  14.079398,  14.518905,\n",
      "        16.3822  ], dtype=float32), np.int64(9): array([-8.638791 , -7.587668 , -7.298391 , ...,  7.2978473,  7.553642 ,\n",
      "        8.570476 ], dtype=float32), np.int64(10): array([-4.563482 , -4.079391 , -3.9564548, ...,  3.9674993,  4.0896096,\n",
      "        4.5609756], dtype=float32)}\n",
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bcbaee175348f48c9f5a3d60b7fc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-276.86133, -262.0598 , -257.53687, ...,  255.44385,  296.43854,\n",
      "        319.80322], dtype=float32), np.int64(3): array([-199.62662, -196.44006, -185.09824, ...,  189.14688,  206.41696,\n",
      "        242.54683], dtype=float32), np.int64(4): array([-146.56544 , -120.879074, -119.34096 , ...,  117.40605 ,\n",
      "        119.79411 ,  121.802536], dtype=float32), np.int64(5): array([-75.21974 , -66.07452 , -63.38159 , ...,  58.915104,  60.578575,\n",
      "        67.70299 ], dtype=float32), np.int64(6): array([-39.207752, -31.50662 , -30.27081 , ...,  30.792849,  32.78789 ,\n",
      "        41.850323], dtype=float32), np.int64(7): array([-21.839128, -16.54106 , -15.550946, ...,  15.565826,  16.495071,\n",
      "        22.10962 ], dtype=float32), np.int64(8): array([-12.339653 ,  -8.450267 ,  -7.9618206, ...,   8.075727 ,\n",
      "         8.615284 ,  14.694235 ], dtype=float32), np.int64(9): array([-7.8178825, -4.6844397, -4.3581557, ...,  4.368044 ,  4.673856 ,\n",
      "        7.380308 ], dtype=float32), np.int64(10): array([-4.4739676, -3.005346 , -2.768481 , ...,  2.791287 ,  3.0383973,\n",
      "        4.49347  ], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a3aa31bb1d4db2af0c9c505562c278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-745.0589 , -660.1778 , -615.7639 , ...,  661.88934,  663.0331 ,\n",
      "        681.46606], dtype=float32), np.int64(3): array([-380.91626, -368.74414, -360.72458, ...,  392.23517,  392.31415,\n",
      "        429.35916], dtype=float32), np.int64(4): array([-216.66418, -211.31573, -210.39293, ...,  228.18356,  231.08788,\n",
      "        250.41232], dtype=float32), np.int64(5): array([-127.02686 , -121.52211 , -118.35333 , ...,  121.321625,\n",
      "        126.39818 ,  130.88031 ], dtype=float32), np.int64(6): array([-69.08226 , -63.17247 , -60.961338, ...,  60.534454,  62.345936,\n",
      "        65.23005 ], dtype=float32), np.int64(7): array([-34.667534, -31.362051, -30.449223, ...,  30.894566,  31.819233,\n",
      "        34.76724 ], dtype=float32), np.int64(8): array([-17.774971, -16.00138 , -15.527179, ...,  15.507706,  15.993097,\n",
      "        17.68345 ], dtype=float32), np.int64(9): array([-9.29077 , -8.299215, -8.06871 , ...,  8.032114,  8.27582 ,\n",
      "        9.106714], dtype=float32), np.int64(10): array([-4.887476 , -4.454588 , -4.351509 , ...,  4.323557 ,  4.4285784,\n",
      "        4.875697 ], dtype=float32)}\n",
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1a5dc75e364af4a1ad8c07664f1dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-524.0553 , -494.09946, -488.73392, ...,  503.87653,  559.31287,\n",
      "        589.9274 ], dtype=float32), np.int64(3): array([-365.16125, -350.11737, -345.13196, ...,  357.7389 ,  363.19775,\n",
      "        374.1172 ], dtype=float32), np.int64(4): array([-245.49539, -237.72186, -234.70297, ...,  205.97685,  207.81915,\n",
      "        221.2168 ], dtype=float32), np.int64(5): array([-134.5758  , -123.814674, -120.665344, ...,  123.84921 ,\n",
      "        128.50462 ,  131.19844 ], dtype=float32), np.int64(6): array([-67.52861 , -62.340614, -60.518204, ...,  61.728012,  63.871063,\n",
      "        67.83798 ], dtype=float32), np.int64(7): array([-34.905376, -31.407738, -30.510624, ...,  30.778635,  31.734108,\n",
      "        35.007156], dtype=float32), np.int64(8): array([-17.802124, -15.949037, -15.433606, ...,  15.419381,  15.855267,\n",
      "        17.636768], dtype=float32), np.int64(9): array([-9.264736 , -8.275581 , -8.008594 , ...,  7.972843 ,  8.2182045,\n",
      "        9.230653 ], dtype=float32), np.int64(10): array([-4.874581 , -4.4086657, -4.2969327, ...,  4.2936435,  4.405476 ,\n",
      "        4.873701 ], dtype=float32)}\n",
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85581c3517244449759dcea6cab8d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-274.73557, -269.17352, -262.5015 , ...,  277.70035,  291.55402,\n",
      "        303.25763], dtype=float32), np.int64(3): array([-233.23123, -206.1759 , -178.03772, ...,  198.42703,  213.8274 ,\n",
      "        228.48665], dtype=float32), np.int64(4): array([-146.90253 , -130.30504 , -124.06758 , ...,  117.792   ,\n",
      "        125.65044 ,  125.973206], dtype=float32), np.int64(5): array([-81.24581 , -67.99548 , -66.423325, ...,  62.18097 ,  65.64177 ,\n",
      "        72.779144], dtype=float32), np.int64(6): array([-40.333416, -34.17533 , -32.44834 , ...,  33.214935,  35.696686,\n",
      "        47.302155], dtype=float32), np.int64(7): array([-24.402777, -17.89554 , -16.820183, ...,  17.065174,  17.99655 ,\n",
      "        23.030743], dtype=float32), np.int64(8): array([-12.817153,  -9.351709,  -8.77149 , ...,   8.869112,   9.382162,\n",
      "        16.392273], dtype=float32), np.int64(9): array([-7.925021 , -5.158463 , -4.8427896, ...,  4.8412523,  5.143056 ,\n",
      "        7.6745787], dtype=float32), np.int64(10): array([-4.776451 , -3.4325345, -3.1773095, ...,  3.185779 ,  3.4368706,\n",
      "        4.7864246], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5ddf7ed1fc4d3aa0c5bd17cd90f94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-765.0437 , -649.1371 , -637.76855, ...,  572.7265 ,  589.72736,\n",
      "        599.34625], dtype=float32), np.int64(3): array([-368.55417, -334.8588 , -334.07532, ...,  352.27148,  357.2025 ,\n",
      "        386.99487], dtype=float32), np.int64(4): array([-197.84314, -197.50827, -197.4984 , ...,  200.12436,  200.4216 ,\n",
      "        208.73447], dtype=float32), np.int64(5): array([-108.06545 , -102.89774 , -101.7272  , ...,  104.93591 ,\n",
      "        107.5596  ,  110.073006], dtype=float32), np.int64(6): array([-55.1263  , -53.980312, -52.404346, ...,  51.65838 ,  52.828945,\n",
      "        56.50515 ], dtype=float32), np.int64(7): array([-29.23072 , -26.735775, -26.069893, ...,  26.328579,  27.008957,\n",
      "        29.253971], dtype=float32), np.int64(8): array([-14.868102, -13.673993, -13.259178, ...,  13.268541,  13.612808,\n",
      "        14.950344], dtype=float32), np.int64(9): array([-8.133192 , -7.1145887, -6.940129 , ...,  6.9330883,  7.1278305,\n",
      "        7.860303 ], dtype=float32), np.int64(10): array([-4.1907196, -3.8706393, -3.7830477, ...,  3.7708132,  3.8597536,\n",
      "        4.192743 ], dtype=float32)}\n",
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ed95230f8f40708a7181a49f366d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-521.03564, -417.38257, -408.82617, ...,  462.90598,  464.4419 ,\n",
      "        511.82846], dtype=float32), np.int64(3): array([-322.5283 , -298.25977, -291.41797, ...,  323.11188,  345.85312,\n",
      "        377.97726], dtype=float32), np.int64(4): array([-204.18643, -198.65082, -195.73509, ...,  178.83403,  180.81245,\n",
      "        182.22253], dtype=float32), np.int64(5): array([-112.54578 , -105.10488 , -102.76629 , ...,   98.847786,\n",
      "        102.25737 ,  105.92656 ], dtype=float32), np.int64(6): array([-56.594635, -53.44225 , -52.05373 , ...,  52.513367,  54.149654,\n",
      "        57.536682], dtype=float32), np.int64(7): array([-28.767658, -26.589567, -26.012533, ...,  26.490025,  27.169966,\n",
      "        29.670425], dtype=float32), np.int64(8): array([-15.124186, -13.596886, -13.176613, ...,  13.214161,  13.546956,\n",
      "        14.966848], dtype=float32), np.int64(9): array([-7.8034344, -7.094029 , -6.902368 , ...,  6.876287 ,  7.0712166,\n",
      "        7.9179697], dtype=float32), np.int64(10): array([-4.1864305, -3.8468628, -3.7521996, ...,  3.7534964,  3.8473277,\n",
      "        4.185519 ], dtype=float32)}\n",
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6934ecbdbb4d4284f5c3acd7cc06f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-304.45337, -279.3346 , -265.54678, ...,  274.3365 ,  299.36945,\n",
      "        327.89365], dtype=float32), np.int64(3): array([-199.55441, -165.4736 , -160.96179, ...,  188.58817,  190.09554,\n",
      "        243.46375], dtype=float32), np.int64(4): array([-112.89511, -105.28693, -104.49629, ...,  106.43698,  108.49592,\n",
      "        111.76595], dtype=float32), np.int64(5): array([-68.958145, -62.788788, -58.076134, ...,  53.760624,  58.557533,\n",
      "        65.22092 ], dtype=float32), np.int64(6): array([-37.88192 , -30.515762, -28.716373, ...,  29.196152,  30.83167 ,\n",
      "        36.998905], dtype=float32), np.int64(7): array([-20.029139 , -15.528746 , -14.706953 , ...,  14.973723 ,\n",
      "        15.9225855,  19.909603 ], dtype=float32), np.int64(8): array([-12.904782 ,  -8.041643 ,  -7.5617924, ...,   7.6254787,\n",
      "         8.077616 ,  13.29251  ], dtype=float32), np.int64(9): array([-6.4893007, -4.4856486, -4.218037 , ...,  4.204706 ,  4.4519095,\n",
      "        7.1635456], dtype=float32), np.int64(10): array([-4.1120896, -3.016438 , -2.799455 , ...,  2.8020608,  3.0167038,\n",
      "        4.178758 ], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df18070772049e9a23f2ff4db18dc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-704.569  , -607.08405, -559.78577, ...,  617.7823 ,  637.99677,\n",
      "        665.35504], dtype=float32), np.int64(3): array([-364.742  , -343.5474 , -338.537  , ...,  366.35535,  376.45566,\n",
      "        426.90564], dtype=float32), np.int64(4): array([-203.23235, -196.8623 , -195.13094, ...,  215.30226,  222.2339 ,\n",
      "        240.54794], dtype=float32), np.int64(5): array([-121.53675 , -114.557434, -112.37513 , ...,  113.060326,\n",
      "        119.310745,  124.02354 ], dtype=float32), np.int64(6): array([-65.573654, -59.012535, -57.014668, ...,  57.170624,  59.142414,\n",
      "        62.446926], dtype=float32), np.int64(7): array([-32.364998, -29.489904, -28.604473, ...,  28.935509,  29.914597,\n",
      "        33.164055], dtype=float32), np.int64(8): array([-16.908709 , -15.0862255, -14.556751 , ...,  14.6297   ,\n",
      "        15.079869 ,  16.902363 ], dtype=float32), np.int64(9): array([-8.640656 , -7.8426027, -7.612022 , ...,  7.577165 ,  7.8283405,\n",
      "        8.671572 ], dtype=float32), np.int64(10): array([-4.5729933, -4.1465507, -4.057703 , ...,  4.040032 ,  4.1294127,\n",
      "        4.5447655], dtype=float32)}\n",
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e63fe670804210b822602f7f1c0622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-505.66888, -474.3186 , -439.83362, ...,  483.0393 ,  537.469  ,\n",
      "        545.4199 ], dtype=float32), np.int64(3): array([-343.49133, -327.9904 , -324.11502, ...,  340.9485 ,  347.99835,\n",
      "        355.5823 ], dtype=float32), np.int64(4): array([-233.44553, -228.37988, -227.2399 , ...,  198.78986,  200.93167,\n",
      "        214.31   ], dtype=float32), np.int64(5): array([-128.14407, -116.44908, -114.48159, ...,  117.39251,  119.5475 ,\n",
      "        125.12438], dtype=float32), np.int64(6): array([-64.94067 , -59.36039 , -57.718063, ...,  58.41139 ,  60.474037,\n",
      "        64.640816], dtype=float32), np.int64(7): array([-33.538944, -29.468643, -28.655918, ...,  28.93518 ,  29.9935  ,\n",
      "        33.8389  ], dtype=float32), np.int64(8): array([-16.951433 , -15.08076  , -14.560465 , ...,  14.4853115,\n",
      "        14.972651 ,  16.698717 ], dtype=float32), np.int64(9): array([-8.7051115, -7.812136 , -7.534867 , ...,  7.5076127,  7.7362676,\n",
      "        8.6642275], dtype=float32), np.int64(10): array([-4.554811 , -4.102576 , -4.009726 , ...,  4.006109 ,  4.1029716,\n",
      "        4.5582695], dtype=float32)}\n",
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919c43c1d0fe457f8b9aec6fbb45c52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-259.48788, -246.48027, -241.51027, ...,  255.20638,  268.2892 ,\n",
      "        284.3253 ], dtype=float32), np.int64(3): array([-208.68544, -197.849  , -167.87766, ...,  189.37817,  198.16553,\n",
      "        201.98859], dtype=float32), np.int64(4): array([-141.60658 , -122.759636, -120.282585, ...,  108.049614,\n",
      "        116.733925,  120.30652 ], dtype=float32), np.int64(5): array([-77.76811 , -62.47676 , -61.42484 , ...,  56.51991 ,  58.395004,\n",
      "        64.78164 ], dtype=float32), np.int64(6): array([-39.735985, -31.97435 , -30.519793, ...,  30.626606,  33.15329 ,\n",
      "        44.658333], dtype=float32), np.int64(7): array([-23.221815, -16.775387, -15.665968, ...,  15.824578,  16.942217,\n",
      "        22.574657], dtype=float32), np.int64(8): array([-12.337745 ,  -8.716613 ,  -8.197234 , ...,   8.337269 ,\n",
      "         8.8252325,  15.835283 ], dtype=float32), np.int64(9): array([-7.742275 , -4.812896 , -4.5002117, ...,  4.4925904,  4.7935243,\n",
      "        7.3426533], dtype=float32), np.int64(10): array([-4.3767195, -3.1500275, -2.9077053, ...,  2.9234698,  3.1604867,\n",
      "        4.334529 ], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_backup2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
