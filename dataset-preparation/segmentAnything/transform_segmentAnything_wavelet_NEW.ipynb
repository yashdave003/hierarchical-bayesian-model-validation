{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"segmentAnything\"\n",
    "FINAL_DATA_NAME = 'segmentAnything-full-wavelet' # + channel\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"segmentAnything-croppedDeblurred\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','segmentAnything')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sa_7209.jpg', 'sa_2371.jpg', 'sa_4700.jpg', 'sa_3709.jpg', 'sa_5378.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 5000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'segmentAnything') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentAnything-croppedDeblurred\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)  \n",
    "def jpg_opener(path):\n",
    "    \n",
    "    # Apply jitter\n",
    "    image = np.array(Image.open(path).convert('RGB'))\n",
    "    arr = image.astype(np.float64)\n",
    "    jitter = np.random.uniform(-0.5, 0.5, arr.shape)\n",
    "    arr += jitter\n",
    "    arr = arr - np.mean(arr)\n",
    "    arr = arr / np.std(arr)\n",
    "\n",
    "    \n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'segmentAnything-full-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"segmentAnything\", f\"{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"segmentAnything\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f86758f7d6436fa6a997aa96895dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-733.8397 , -523.5202 , -497.3036 , ...,  477.03714,  480.7086 ,\n",
      "        490.19824], dtype=float32), np.int64(3): array([-381.5477 , -326.1934 , -321.54593, ...,  320.8372 ,  342.97174,\n",
      "        349.04706], dtype=float32), np.int64(4): array([-228.4368 , -201.56972, -201.24597, ...,  214.87521,  228.35588,\n",
      "        272.5188 ], dtype=float32), np.int64(5): array([-283.77243 , -124.51998 , -116.712364, ...,  122.18985 ,\n",
      "        130.19968 ,  204.02596 ], dtype=float32), np.int64(6): array([-126.91914 ,  -63.65492 ,  -58.643837, ...,   63.722054,\n",
      "         71.40992 ,   88.32904 ], dtype=float32), np.int64(7): array([-56.944874, -32.69587 , -30.127714, ...,  30.413774,  33.974655,\n",
      "        61.469116], dtype=float32), np.int64(8): array([-51.78339  , -16.095322 , -14.7365675, ...,  15.01632  ,\n",
      "        16.552618 ,  41.069557 ], dtype=float32), np.int64(9): array([-36.255848 ,  -8.269207 ,  -7.485098 , ...,   7.4724035,\n",
      "         8.217231 ,  19.918056 ], dtype=float32), np.int64(10): array([-10.571056,  -4.480206,  -4.064932, ...,   3.987412,   4.368519,\n",
      "        10.304121], dtype=float32)}\n",
      "printing V\n",
      "{np.int64(2): array([-511.83704, -430.8288 , -371.61502, ...,  458.45837,  507.26526,\n",
      "        523.2627 ], dtype=float32), np.int64(3): array([-373.72644, -286.26483, -275.96567, ...,  266.6062 ,  274.13443,\n",
      "        296.57227], dtype=float32), np.int64(4): array([-236.79991, -205.01865, -194.02168, ...,  207.06569,  211.83347,\n",
      "        236.22899], dtype=float32), np.int64(5): array([-138.78137 , -103.459526, -100.57589 , ...,  112.68341 ,\n",
      "        123.15655 ,  183.59059 ], dtype=float32), np.int64(6): array([-109.91326 ,  -61.208984,  -57.867855, ...,   57.328518,\n",
      "         61.449516,  119.06168 ], dtype=float32), np.int64(7): array([-63.435528, -33.510017, -29.422438, ...,  28.928192,  31.389751,\n",
      "        88.41273 ], dtype=float32), np.int64(8): array([-38.856182, -15.971302, -14.408667, ...,  14.244504,  15.724716,\n",
      "        41.24196 ], dtype=float32), np.int64(9): array([-20.322113 ,  -8.103468 ,  -7.2216387, ...,   7.118514 ,\n",
      "         7.922621 ,  24.462532 ], dtype=float32), np.int64(10): array([-9.783887 , -4.205559 , -3.8170862, ...,  3.8013752,  4.1926517,\n",
      "       10.614243 ], dtype=float32)}\n",
      "printing D\n",
      "{np.int64(2): array([-271.55322, -264.29315, -253.98929, ...,  240.49971,  240.57603,\n",
      "        268.0549 ], dtype=float32), np.int64(3): array([-209.05843, -182.4036 , -160.61613, ...,  180.32372,  195.28827,\n",
      "        224.50119], dtype=float32), np.int64(4): array([-119.10383, -103.65311, -102.26748, ...,  115.75349,  128.76605,\n",
      "        129.32057], dtype=float32), np.int64(5): array([-84.4299  , -69.164856, -63.996994, ...,  63.270737,  72.71274 ,\n",
      "        96.80904 ], dtype=float32), np.int64(6): array([-49.75576 , -32.981426, -29.640564, ...,  29.773842,  33.088947,\n",
      "        51.15895 ], dtype=float32), np.int64(7): array([-36.59286 , -16.18933 , -14.744215, ...,  15.073117,  16.80031 ,\n",
      "        38.74017 ], dtype=float32), np.int64(8): array([-37.41213  ,  -8.518897 ,  -7.5820436, ...,   7.635515 ,\n",
      "         8.604468 ,  21.810873 ], dtype=float32), np.int64(9): array([-12.235688 ,  -4.368727 ,  -3.9821832, ...,   4.0269656,\n",
      "         4.4211454,  10.399009 ], dtype=float32), np.int64(10): array([-11.18694  ,  -2.6847663,  -2.4444795, ...,   2.4664586,\n",
      "         2.7126586,   7.8872566], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=jpg_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "del channel_wv\n",
    "del group_data_map\n",
    "del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019f87aab90e4b2fb34d8d63b2395f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-464.96548, -455.56238, -442.8803 , ...,  402.6478 ,  405.05383,\n",
      "        425.76584], dtype=float32), np.int64(3): array([-307.8523 , -282.25876, -278.19205, ...,  267.09433,  280.1341 ,\n",
      "        337.51926], dtype=float32), np.int64(4): array([-217.27238, -215.33658, -213.24695, ...,  194.79546,  214.85889,\n",
      "        255.17145], dtype=float32), np.int64(5): array([-137.30583 , -111.144714, -107.31204 , ...,  113.94874 ,\n",
      "        124.08283 ,  185.43411 ], dtype=float32), np.int64(6): array([-92.68034 , -57.744896, -55.16004 , ...,  55.34837 ,  61.13868 ,\n",
      "        79.6083  ], dtype=float32), np.int64(7): array([-45.79167 , -31.009092, -28.286446, ...,  28.971672,  31.469461,\n",
      "        50.34251 ], dtype=float32), np.int64(8): array([-28.716234, -15.585561, -14.379328, ...,  14.614774,  15.840999,\n",
      "        34.298542], dtype=float32), np.int64(9): array([-17.980148,  -8.16033 ,  -7.417339, ...,   7.431506,   8.110897,\n",
      "        18.179914], dtype=float32), np.int64(10): array([-10.216311 ,  -4.4801297,  -4.065773 , ...,   3.990078 ,\n",
      "         4.370411 ,  10.309952 ], dtype=float32)}\n",
      "printing V\n",
      "{np.int64(2): array([-383.72357, -362.4573 , -351.3806 , ...,  379.4316 ,  408.9809 ,\n",
      "        459.7165 ], dtype=float32), np.int64(3): array([-315.85345, -268.14053, -264.3393 , ...,  249.78098,  271.18948,\n",
      "        294.6797 ], dtype=float32), np.int64(4): array([-327.66318, -176.59514, -167.91438, ...,  188.11288,  201.1428 ,\n",
      "        220.87022], dtype=float32), np.int64(5): array([-133.12863 , -103.9364  , -101.53569 , ...,  107.034225,\n",
      "        112.373276,  144.59415 ], dtype=float32), np.int64(6): array([-85.18721 , -58.3226  , -53.937656, ...,  54.373886,  58.07637 ,\n",
      "        93.048676], dtype=float32), np.int64(7): array([-64.21431 , -31.37037 , -27.999228, ...,  28.155865,  31.065443,\n",
      "        59.361507], dtype=float32), np.int64(8): array([-36.291977 , -15.894398 , -14.246742 , ...,  14.12943  ,\n",
      "        15.6224575,  33.083363 ], dtype=float32), np.int64(9): array([-19.357553 ,  -8.029465 ,  -7.1892257, ...,   7.0806336,\n",
      "         7.9006977,  18.917822 ], dtype=float32), np.int64(10): array([-9.761995 , -4.2159224, -3.829904 , ...,  3.7983181,  4.1938195,\n",
      "       10.616174 ], dtype=float32)}\n",
      "printing D\n",
      "{np.int64(2): array([-245.04199, -244.11412, -225.35454, ...,  207.75381,  243.87411,\n",
      "        248.51921], dtype=float32), np.int64(3): array([-176.84921, -164.93839, -159.70782, ...,  162.147  ,  181.65143,\n",
      "        183.68517], dtype=float32), np.int64(4): array([-109.45714 , -104.878815,  -99.477356, ...,  104.31999 ,\n",
      "        106.67485 ,  124.10724 ], dtype=float32), np.int64(5): array([-71.759224, -61.31442 , -57.31553 , ...,  55.319294,  66.72351 ,\n",
      "        85.47721 ], dtype=float32), np.int64(6): array([-49.27204 , -30.62136 , -28.22178 , ...,  29.4732  ,  31.157703,\n",
      "        51.40182 ], dtype=float32), np.int64(7): array([-34.34349 , -15.514086, -14.299892, ...,  14.522844,  16.272144,\n",
      "        35.93795 ], dtype=float32), np.int64(8): array([-18.405348 ,  -8.350501 ,  -7.4821796, ...,   7.565973 ,\n",
      "         8.429404 ,  21.492212 ], dtype=float32), np.int64(9): array([-12.232544 ,  -4.3702517,  -3.9824076, ...,   4.0201387,\n",
      "         4.4115624,  10.3470545], dtype=float32), np.int64(10): array([-11.223726 ,  -2.6873837,  -2.4467165, ...,   2.4700863,\n",
      "         2.7167516,   7.859889 ], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=jpg_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "del channel_wv\n",
    "del group_data_map\n",
    "del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ca6fb6b2ea495b9a159ee396e26f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-610.7345 , -515.8348 , -484.62192, ...,  503.93292,  561.12604,\n",
      "        565.79175], dtype=float32), np.int64(3): array([-329.62918, -319.91806, -312.8861 , ...,  293.40527,  298.4928 ,\n",
      "        349.25482], dtype=float32), np.int64(4): array([-221.2627 , -214.76782, -211.10687, ...,  212.02336,  236.4869 ,\n",
      "        246.3517 ], dtype=float32), np.int64(5): array([-128.5363 , -116.51817, -114.92238, ...,  119.09147,  124.08746,\n",
      "        176.22348], dtype=float32), np.int64(6): array([-73.61792 , -58.264446, -55.811554, ...,  57.67349 ,  64.341705,\n",
      "        99.774925], dtype=float32), np.int64(7): array([-50.291943, -31.983091, -28.517921, ...,  28.646849,  31.05483 ,\n",
      "        45.23739 ], dtype=float32), np.int64(8): array([-27.120691 , -15.3747635, -14.261824 , ...,  14.495656 ,\n",
      "        15.692236 ,  28.480913 ], dtype=float32), np.int64(9): array([-17.295876 ,  -8.0578375,  -7.3574514, ...,   7.310516 ,\n",
      "         7.983105 ,  16.79103  ], dtype=float32), np.int64(10): array([-10.258126 ,  -4.4586315,  -4.0418196, ...,   3.970296 ,\n",
      "         4.348942 ,  10.233039 ], dtype=float32)}\n",
      "printing V\n",
      "{np.int64(2): array([-428.90985, -412.7621 , -404.5037 , ...,  406.74304,  415.30795,\n",
      "        424.32773], dtype=float32), np.int64(3): array([-325.26727, -282.82156, -280.74957, ...,  275.82587,  283.81787,\n",
      "        311.53183], dtype=float32), np.int64(4): array([-190.7658 , -187.78241, -184.07121, ...,  186.05948,  188.12553,\n",
      "        209.00085], dtype=float32), np.int64(5): array([-172.19775 , -113.003044, -101.59306 , ...,  105.06685 ,\n",
      "        109.03715 ,  144.59961 ], dtype=float32), np.int64(6): array([-86.242836, -60.254066, -55.933586, ...,  54.04943 ,  58.516396,\n",
      "        76.89713 ], dtype=float32), np.int64(7): array([-54.41512 , -29.832876, -27.743883, ...,  27.837847,  30.735987,\n",
      "        52.69324 ], dtype=float32), np.int64(8): array([-30.65653 , -15.533743, -14.145156, ...,  13.921728,  15.397573,\n",
      "        30.429005], dtype=float32), np.int64(9): array([-19.23025  ,  -7.942046 ,  -7.0977097, ...,   6.963584 ,\n",
      "         7.800112 ,  16.873747 ], dtype=float32), np.int64(10): array([-9.804256 , -4.171696 , -3.7895088, ...,  3.774463 ,  4.1707273,\n",
      "       10.596413 ], dtype=float32)}\n",
      "printing D\n",
      "{np.int64(2): array([-309.14343, -263.23917, -246.82242, ...,  239.05922,  246.81386,\n",
      "        247.2318 ], dtype=float32), np.int64(3): array([-176.00748, -171.96042, -171.95738, ...,  184.4267 ,  185.35765,\n",
      "        195.15408], dtype=float32), np.int64(4): array([-111.33358 , -109.75971 , -106.22271 , ...,  121.103165,\n",
      "        122.16472 ,  129.80107 ], dtype=float32), np.int64(5): array([-78.408356, -66.48553 , -63.01506 , ...,  58.203476,  64.75935 ,\n",
      "        68.581924], dtype=float32), np.int64(6): array([-55.133713, -30.957132, -28.99938 , ...,  29.326336,  31.605116,\n",
      "        57.662136], dtype=float32), np.int64(7): array([-29.240604, -15.872536, -14.542358, ...,  14.495398,  16.03423 ,\n",
      "        28.281559], dtype=float32), np.int64(8): array([-16.383417 ,  -8.154009 ,  -7.3662753, ...,   7.431288 ,\n",
      "         8.3352785,  16.824753 ], dtype=float32), np.int64(9): array([-12.172798 ,  -4.326654 ,  -3.9446743, ...,   3.983512 ,\n",
      "         4.3711247,  10.363086 ], dtype=float32), np.int64(10): array([-11.157752 ,  -2.675448 ,  -2.4351869, ...,   2.455723 ,\n",
      "         2.703578 ,   7.8781114], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=jpg_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "del channel_wv\n",
    "del group_data_map\n",
    "del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86beba5fcff4310a17e9bfe4d8ac326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-426.3494 , -400.0464 , -398.47656, ...,  412.7874 ,  415.9912 ,\n",
      "        424.8862 ], dtype=float32), np.int64(3): array([-309.98468, -280.3155 , -264.45114, ...,  266.73306,  268.48187,\n",
      "        333.83807], dtype=float32), np.int64(4): array([-199.80577, -197.40376, -193.0675 , ...,  195.10178,  207.13661,\n",
      "        258.20688], dtype=float32), np.int64(5): array([-140.68346, -111.25855, -107.59347, ...,  115.22226,  124.06321,\n",
      "        189.25455], dtype=float32), np.int64(6): array([-93.496635, -57.410706, -54.609184, ...,  55.93286 ,  60.035305,\n",
      "        77.639854], dtype=float32), np.int64(7): array([-46.621693, -30.627481, -27.968359, ...,  28.414833,  30.714956,\n",
      "        50.19887 ], dtype=float32), np.int64(8): array([-29.096115, -15.41388 , -14.2338  , ...,  14.447264,  15.536437,\n",
      "        33.073692], dtype=float32), np.int64(9): array([-17.80166  ,  -8.124304 ,  -7.387607 , ...,   7.3680005,\n",
      "         8.067773 ,  18.252169 ], dtype=float32), np.int64(10): array([-10.248332 ,  -4.47366  ,  -4.0592146, ...,   3.9831452,\n",
      "         4.364555 ,  10.297837 ], dtype=float32)}\n",
      "printing V\n",
      "{np.int64(2): array([-381.32602, -374.53052, -362.41946, ...,  376.51004,  382.87863,\n",
      "        469.90955], dtype=float32), np.int64(3): array([-329.09784, -268.55414, -261.04132, ...,  245.20197,  257.3323 ,\n",
      "        258.78165], dtype=float32), np.int64(4): array([-269.06516, -181.45724, -174.6855 , ...,  188.09799,  205.21022,\n",
      "        218.68188], dtype=float32), np.int64(5): array([-135.70074, -102.75331,  -97.82868, ...,  104.9624 ,  111.62633,\n",
      "        144.59912], dtype=float32), np.int64(6): array([-85.206436, -58.753254, -53.877968, ...,  53.341652,  57.920452,\n",
      "        96.303635], dtype=float32), np.int64(7): array([-59.980976, -31.032354, -27.775944, ...,  27.764168,  30.340714,\n",
      "        60.709366], dtype=float32), np.int64(8): array([-33.96513 , -15.615988, -14.045302, ...,  13.877852,  15.291995,\n",
      "        31.591248], dtype=float32), np.int64(9): array([-19.077219 ,  -7.9969344,  -7.136606 , ...,   7.033243 ,\n",
      "         7.852245 ,  18.589947 ], dtype=float32), np.int64(10): array([-9.774123 , -4.204126 , -3.818278 , ...,  3.7910888,  4.18806  ,\n",
      "       10.5815115], dtype=float32)}\n",
      "printing D\n",
      "{np.int64(2): array([-241.96004, -222.3023 , -220.82378, ...,  212.23795,  241.63686,\n",
      "        241.98274], dtype=float32), np.int64(3): array([-185.03802, -164.87624, -161.81044, ...,  160.00848,  174.92908,\n",
      "        191.76868], dtype=float32), np.int64(4): array([-101.02136 ,  -95.185974,  -92.72428 , ...,   98.69892 ,\n",
      "        110.894226,  125.42858 ], dtype=float32), np.int64(5): array([-71.11197 , -61.244473, -57.611816, ...,  56.641953,  65.836685,\n",
      "        86.93011 ], dtype=float32), np.int64(6): array([-49.322765, -30.396626, -28.224302, ...,  28.290886,  30.147587,\n",
      "        51.890823], dtype=float32), np.int64(7): array([-32.687298, -15.230983, -14.071893, ...,  14.364369,  16.130283,\n",
      "        34.171574], dtype=float32), np.int64(8): array([-18.31714  ,  -8.321663 ,  -7.4513574, ...,   7.5203843,\n",
      "         8.40732  ,  20.878164 ], dtype=float32), np.int64(9): array([-12.201373 ,  -4.3544717,  -3.9760108, ...,   4.012013 ,\n",
      "         4.4032354,  10.326549 ], dtype=float32), np.int64(10): array([-11.194628 ,  -2.6839895,  -2.4441512, ...,   2.465463 ,\n",
      "         2.7118602,   7.87808  ], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=jpg_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "del channel_wv\n",
    "del group_data_map\n",
    "del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HBMV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
