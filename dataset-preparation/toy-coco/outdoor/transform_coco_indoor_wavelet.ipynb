{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'coco-indoor-wavelet'\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"coco-cropped-Indoor\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','coco')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000182611.jpg',\n",
       " '000000479126.jpg',\n",
       " '000000304396.jpg',\n",
       " '000000231339.jpg',\n",
       " '000000377393.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [os.path.join(data_dir, f\"toy-{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(os.path.join(data_dir, f\"toy-{RAW_DATA_SUFFIX}\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toy-coco-cropped-Indoor\n",
      "._toy-coco-cropped-Indoor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npz_opener_pickle(path):\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'coco-indoor-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"toy-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:08<00:00, 184.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-18543.719, -17717.684, -17385.676, ...,  18247.875,  20605.406,\n",
      "        20710.25 ], shape=(1604,), dtype=float32), np.int64(3): array([-10430.547, -10339.836,  -9587.359, ...,   9851.672,  11157.68 ,\n",
      "        12393.016], shape=(6416,), dtype=float32), np.int64(4): array([-6697.2812, -6542.2188, -6271.875 , ...,  5856.5625,  5998.3594,\n",
      "        6574.3125], shape=(25664,), dtype=float32), np.int64(5): array([-3342.8438, -3152.5625, -3013.7812, ...,  3164.4375,  3244.6875,\n",
      "        3248.1562], shape=(100000,), dtype=float32), np.int64(6): array([-1798.5   , -1714.75  , -1641.875 , ...,  1577.875 ,  1651.625 ,\n",
      "        1701.1875], shape=(100000,), dtype=float32), np.int64(7): array([-906.5  , -841.25 , -821.5  , ...,  796.625,  820.625,  869.125],\n",
      "      shape=(100000,), dtype=float32), np.int64(8): array([-469.5 , -418.  , -403.75, ...,  397.25,  411.  ,  461.5 ],\n",
      "      shape=(100000,), dtype=float32), np.int64(9): array([-250.5, -215.5, -208. , ...,  206.5,  216. ,  255. ],\n",
      "      shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:02<00:00, 777.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-21876.5  , -17983.02 , -15719.383, ...,  15973.383,  17924.586,\n",
      "        21353.223], shape=(1604,), dtype=float32), np.int64(3): array([-10322.133, -10310.031, -10190.125, ...,   9512.305,  10047.492,\n",
      "        11434.602], shape=(6416,), dtype=float32), np.int64(4): array([-6386.3594, -6183.672 , -5816.078 , ...,  6326.1094,  6453.9375,\n",
      "        6739.25  ], shape=(25664,), dtype=float32), np.int64(5): array([-3333.3438, -3300.25  , -3275.1562, ...,  3132.9062,  3146.1562,\n",
      "        3290.3125], shape=(100000,), dtype=float32), np.int64(6): array([-1736.75  , -1664.375 , -1646.0625, ...,  1593.25  ,  1640.    ,\n",
      "        1783.4375], shape=(100000,), dtype=float32), np.int64(7): array([-881.625, -825.125, -796.5  , ...,  779.75 ,  822.   ,  988.875],\n",
      "      shape=(100000,), dtype=float32), np.int64(8): array([-460.75, -414.25, -399.  , ...,  395.5 ,  408.75,  484.  ],\n",
      "      shape=(100000,), dtype=float32), np.int64(9): array([-253. , -213. , -203. , ...,  204.5,  213. ,  253.5],\n",
      "      shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:02<00:00, 756.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-18103.84 , -16203.844, -14760.898, ...,  18247.875,  18295.133,\n",
      "        20574.61 ], shape=(1604,), dtype=float32), np.int64(3): array([-11018.328 ,  -9731.242 ,  -9676.281 , ...,   9518.023 ,\n",
      "         9654.5625,  11885.25  ], shape=(6416,), dtype=float32), np.int64(4): array([-7052.7344, -6691.1094, -6679.5625, ...,  6826.3438,  6920.8906,\n",
      "        6970.7656], shape=(25664,), dtype=float32), np.int64(5): array([-3414.6562, -3412.75  , -3394.8438, ...,  3153.875 ,  3187.125 ,\n",
      "        3244.6875], shape=(100000,), dtype=float32), np.int64(6): array([-1861.9375, -1729.625 , -1689.75  , ...,  1608.    ,  1664.6875,\n",
      "        1746.3125], shape=(100000,), dtype=float32), np.int64(7): array([-927.375, -832.875, -797.   , ...,  807.5  ,  819.875,  881.625],\n",
      "      shape=(100000,), dtype=float32), np.int64(8): array([-471.75, -418.5 , -404.  , ...,  398.  ,  411.25,  466.  ],\n",
      "      shape=(100000,), dtype=float32), np.int64(9): array([-252.5, -217. , -208.5, ...,  207.5,  217. ,  250. ],\n",
      "      shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:02<00:00, 744.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-20436.48 , -18298.633, -14272.234, ...,  14553.844,  18239.445,\n",
      "        20241.312], shape=(1604,), dtype=float32), np.int64(3): array([-11019.3125, -11007.883 , -10331.539 , ...,   9000.555 ,\n",
      "         9104.016 ,   9221.461 ], shape=(6416,), dtype=float32), np.int64(4): array([-6242.1562, -6073.0156, -6002.875 , ...,  5466.1562,  6075.0156,\n",
      "        6503.0156], shape=(25664,), dtype=float32), np.int64(5): array([-3425.2188, -3372.9688, -3355.4688, ...,  3059.8125,  3455.2812,\n",
      "        3690.2188], shape=(100000,), dtype=float32), np.int64(6): array([-1746.6875, -1647.875 , -1607.3125, ...,  1622.875 ,  1684.    ,\n",
      "        1771.625 ], shape=(100000,), dtype=float32), np.int64(7): array([-903.   , -816.375, -795.25 , ...,  787.25 ,  805.5  ,  983.375],\n",
      "      shape=(100000,), dtype=float32), np.int64(8): array([-458.75, -415.25, -402.  , ...,  400.75,  414.25,  480.  ],\n",
      "      shape=(100000,), dtype=float32), np.int64(9): array([-252.5, -214. , -205. , ...,  205. ,  214. ,  255. ],\n",
      "      shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:02<00:00, 737.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-18660.398, -13917.836, -13476.832, ...,  18541.96 ,  18543.102,\n",
      "        19479.684], shape=(1604,), dtype=float32), np.int64(3): array([-11494.656, -10832.461, -10765.508, ...,  10922.93 ,  11049.117,\n",
      "        11586.109], shape=(6416,), dtype=float32), np.int64(4): array([-6689.4375, -6631.5156, -6622.9062, ...,  6231.25  ,  7058.797 ,\n",
      "        7156.297 ], shape=(25664,), dtype=float32), np.int64(5): array([-3415.125 , -3306.7188, -3273.0625, ...,  3212.4688,  3222.5   ,\n",
      "        3244.6875], shape=(100000,), dtype=float32), np.int64(6): array([-1751.875 , -1711.75  , -1649.0625, ...,  1587.    ,  1642.5625,\n",
      "        1719.3125], shape=(100000,), dtype=float32), np.int64(7): array([-905.375, -814.75 , -786.875, ...,  778.   ,  812.625,  889.375],\n",
      "      shape=(100000,), dtype=float32), np.int64(8): array([-469.5 , -414.5 , -399.5 , ...,  392.25,  408.5 ,  485.  ],\n",
      "      shape=(100000,), dtype=float32), np.int64(9): array([-250.5, -215.5, -207. , ...,  206. ,  215. ,  255. ],\n",
      "      shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:02<00:00, 765.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-18438.293, -15851.887, -15436.078, ...,  15699.289,  16376.777,\n",
      "        19879.383], shape=(1604,), dtype=float32), np.int64(3): array([-12946.625, -12442.297, -11031.656, ...,   9263.578,   9427.094,\n",
      "         9620.664], shape=(6416,), dtype=float32), np.int64(4): array([-6277.078 , -5966.5156, -5947.4062, ...,  5700.453 ,  6211.047 ,\n",
      "        6453.6875], shape=(25664,), dtype=float32), np.int64(5): array([-3380.0312, -3201.1562, -3188.2812, ...,  3354.125 ,  3424.7188,\n",
      "        3625.75  ], shape=(100000,), dtype=float32), np.int64(6): array([-1765.375 , -1691.125 , -1644.25  , ...,  1623.875 ,  1658.6875,\n",
      "        1802.3125], shape=(100000,), dtype=float32), np.int64(7): array([-896.75 , -812.875, -786.   , ...,  785.   ,  808.625,  917.625],\n",
      "      shape=(100000,), dtype=float32), np.int64(8): array([-461.5 , -411.25, -393.75, ...,  396.  ,  412.  ,  473.  ],\n",
      "      shape=(100000,), dtype=float32), np.int64(9): array([-252.5, -212.5, -204. , ...,  203.5,  211.5,  252. ],\n",
      "      shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:03<00:00, 510.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-18050.055, -15122.361, -13620.761, ...,  17984.03 ,  18246.05 ,\n",
      "        20488.273], shape=(1604,), dtype=float32), np.int64(3): array([-10895.84 ,  -9433.887,  -9411.363, ...,   9435.939,   9520.618,\n",
      "        12001.73 ], shape=(6416,), dtype=float32), np.int64(4): array([-6685.491 , -6638.9683, -6432.349 , ...,  6133.2397,  6484.7754,\n",
      "        6843.443 ], shape=(25664,), dtype=float32), np.int64(5): array([-3341.1008, -3244.1067, -3210.0337, ...,  3124.6318,  3184.0579,\n",
      "        3244.363 ], shape=(100000,), dtype=float32), np.int64(6): array([-1725.6556, -1684.93  , -1659.922 , ...,  1561.0361,  1632.9418,\n",
      "        1700.681 ], shape=(100000,), dtype=float32), np.int64(7): array([-905.99304, -805.3275 , -782.7231 , ...,  797.17285,  814.96747,\n",
      "        869.01685], shape=(100000,), dtype=float32), np.int64(8): array([-468.35513, -414.5815 , -400.18256, ...,  394.60294,  408.34427,\n",
      "        465.80292], shape=(100000,), dtype=float32), np.int64(9): array([-251.13596, -215.6903 , -207.9792 , ...,  206.5093 ,  215.78046,\n",
      "        249.918  ], shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:03<00:00, 496.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-20034.992, -18218.387, -14097.58 , ...,  14483.667,  17931.166,\n",
      "        20530.379], shape=(1604,), dtype=float32), np.int64(3): array([-10810.907, -10509.112, -10174.677, ...,   9099.767,   9140.594,\n",
      "         9512.948], shape=(6416,), dtype=float32), np.int64(4): array([-5983.4688, -5945.6274, -5802.36  , ...,  5222.7627,  6135.2783,\n",
      "        6482.0723], shape=(25664,), dtype=float32), np.int64(5): array([-3351.32  , -3325.228 , -3287.9463, ...,  2848.847 ,  2931.7986,\n",
      "        2964.4297], shape=(100000,), dtype=float32), np.int64(6): array([-1739.9016, -1615.5277, -1607.1517, ...,  1571.7694,  1660.4429,\n",
      "        1747.4661], shape=(100000,), dtype=float32), np.int64(7): array([-895.8082, -804.7751, -779.0027, ...,  771.4911,  800.6024,\n",
      "        971.7964], shape=(100000,), dtype=float32), np.int64(8): array([-457.70154, -411.4987 , -395.43542, ...,  395.59308,  408.70312,\n",
      "        480.3496 ], shape=(100000,), dtype=float32), np.int64(9): array([-251.77686, -213.2206 , -204.22235, ...,  204.16225,  213.25066,\n",
      "        253.59715], shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
