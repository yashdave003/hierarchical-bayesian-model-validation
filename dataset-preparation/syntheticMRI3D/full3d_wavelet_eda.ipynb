{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahchung/Documents/GitHub/hierarchical-bayesian-model-validation/utilities/testing.py:14: UserWarning: legacy printing option can currently only be '1.13', '1.21', or `False`\n",
      "  np.set_printoptions(legacy='1.25')\n"
     ]
    }
   ],
   "source": [
    "# assign directory\n",
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy import fft\n",
    "import random\n",
    "import pywt.data\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "from plotting import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "\n",
    "# data_dir = '/Users/hannahchung/Downloads/cleaned/'\n",
    "# file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename != \".DS_Store\"]\n",
    "# file_names = os.listdir(data_dir)\n",
    "import joblib\n",
    "\n",
    "#Reassigning directory to cleaned + jittered \n",
    "data_dir = '/Users/hannahchung/Downloads/cleaned_jittered/'\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename != \".DS_Store\"]\n",
    "file_names = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orientation_direction = {\n",
    "#     'aaa': 'Smooth Volume',\n",
    "#     'aad': 'Z Detail',\n",
    "#     'ada': 'Y Detail',\n",
    "#     'add': 'Y-Z Diagonal',\n",
    "#     'daa': 'X Detail',\n",
    "#     'dad': 'X-Z Diagonal',\n",
    "#     'dda': 'X-Y Diagonal',\n",
    "#     'ddd': 'XYZ Diagonal',\n",
    "#     'L1': 'Approximation Layer'\n",
    "# }\n",
    "\n",
    "# axis_description = {\n",
    "#     'aaa': 'Smooth overall brain structure',\n",
    "#     'aad': 'Brainstem → Crown',\n",
    "#     'ada': 'Face → Back of head',\n",
    "#     'add': 'Front-bottom → Back-top',\n",
    "#     'daa': 'Right → Left hemisphere',\n",
    "#     'dad': 'Right-bottom → Left-top',\n",
    "#     'dda': 'Right-front → Left-back',\n",
    "#     'ddd': 'All-direction fine features',\n",
    "#     'L1': 'Low-freq base structure'\n",
    "# }\n",
    "\n",
    "# gray_df[\"First_label\"] = gray_df[\"First\"].map(axis_description)\n",
    "# gray_df[\"Second_label\"] = gray_df[\"Second\"].map(axis_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dtype: float32\n",
      "Single voxel value: 94.15749\n",
      "Single voxel dtype: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# Double-check dtype of 3d mri: float32\n",
    "# file_path = os.path.join(data_dir, file_names[0])\n",
    "# data = np.load(file_path)\n",
    "# image = data['arr_0']\n",
    "\n",
    "# print(\"Image dtype:\", image.dtype)\n",
    "\n",
    "# voxel = image[100, 100, 100]\n",
    "# print(\"Single voxel value:\", voxel)\n",
    "# print(\"Single voxel dtype:\", type(voxel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jitter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npz_opener_with_jitter(path):\n",
    "    arr = np.load(path)[\"arr_0\"].astype(np.float32)\n",
    "    jitter = np.random.uniform(-0.5, 0.5, arr.shape).astype(np.float32)\n",
    "    arr = np.where(np.isnan(arr), np.nan, arr + jitter)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add jitter + save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67302e1443249b3a4564af970d4d064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# src_dir    = '/Users/hannahchung/Downloads/cleaned/'\n",
    "# jitter_dir = '/Users/hannahchung/Downloads/cleaned_jittered/'\n",
    "# os.makedirs(jitter_dir, exist_ok=True)\n",
    "\n",
    "# for fname in tqdm(os.listdir(src_dir)):\n",
    "#     if not fname.endswith('.npz'):\n",
    "#         continue\n",
    "#     arr = npz_opener_with_jitter(os.path.join(src_dir, fname))\n",
    "#     np.savez_compressed(os.path.join(jitter_dir, fname), arr_0=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wavelet_basis_3d(folder_dir, basis=\"db1\", normalized = False):\n",
    "    file_list = [os.path.join(folder_dir, filename) for filename in os.listdir(folder_dir) if filename.endswith('.npz')]\n",
    "    #Setup df Dict\n",
    "    data = np.load(file_list[0])\n",
    "    image = data['arr_0']\n",
    "    first_image = pywt.wavedecn(image, basis)\n",
    "    layer_len = len(first_image)\n",
    "    direction_names = first_image[1].keys()\n",
    "    direction_num = len(direction_names)\n",
    "    print(str(layer_len) + \" layers being used\")\n",
    "    \n",
    "\n",
    "    #Fill DF DICT\n",
    "    layer_arr = [0] * (len(file_list) * (layer_len - 1) * direction_num + len(file_list))\n",
    "    orientation = [0] * (len(file_list) * (layer_len - 1) * direction_num + len(file_list))\n",
    "    data_arr = [0] * (len(file_list) * (layer_len - 1) * direction_num + len(file_list))\n",
    "    cnt = 0\n",
    "    for k in tqdm(range(len(file_list))):\n",
    "\n",
    "        data = np.load(file_list[k])\n",
    "        image = data['arr_0']\n",
    "\n",
    "\n",
    "        if normalized:\n",
    "            std= np.std(image)\n",
    "            mean = np.mean(image)\n",
    "            image = (image- mean)/std\n",
    "\n",
    "    \n",
    "        transformed = pywt.wavedecn(image, 'db1')\n",
    "        \n",
    "\n",
    "        arr = transformed[0].flatten()\n",
    "        layer_arr[cnt] = 1\n",
    "        orientation[cnt] =  \"L1\"\n",
    "        data_arr[cnt] = arr.flatten()\n",
    "        cnt += 1\n",
    "\n",
    "        for i in range(1, layer_len): \n",
    "            for j in direction_names:\n",
    "                \n",
    "                arr = np.array(transformed[i][j]).flatten()\n",
    "                layer_arr[cnt] = i+1\n",
    "                orientation[cnt] =  j\n",
    "                data_arr[cnt] = arr.flatten()\n",
    "                cnt += 1\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df[\"layer\"] = layer_arr\n",
    "    df[\"orientation\"] = orientation\n",
    "    df[\"data\"] = data_arr\n",
    "    new_df = pd.DataFrame(columns=[\"layer\", \"orientation\", \"data\"])\n",
    "    for lo, sf in df.groupby([\"layer\", \"orientation\"])[[\"data\"]]:#.agg(lambda sf: np.concatenate(sf[\"Data\"].tonumpy()))\n",
    "        new_df.loc[len(new_df.index)] = [lo[0], lo[1],  np.hstack(sf['data'])]\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksCombinations(samps, samp_names, layer):\n",
    "    df = pd.DataFrame(columns = [\"Layer\", \"First\", \"Second\", \"KS_Stat\", \"Pvalue\"])\n",
    "    for i in tqdm(range(len(samps))):\n",
    "        for j in range(i+1, len(samps)):\n",
    "            s1 = samps[i][np.isfinite(samps[i])]\n",
    "            s2 = samps[j][np.isfinite(samps[j])]\n",
    "\n",
    "            if len(s1) == 0 or len(s2) == 0:\n",
    "                continue \n",
    "            ksres = stats.ks_2samp(s1, s2)\n",
    "            df.loc[len(df)] = [layer, samp_names[i], samp_names[j], ksres.statistic, ksres.pvalue]\n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir is set to: /Users/hannahchung/Downloads/cleaned_jittered/\n",
      "expected_dir     : /Users/hannahchung/Downloads/cleaned_jittered/\n",
      "\n",
      "data_dir points to cleaned_jittered\n"
     ]
    }
   ],
   "source": [
    "expected_dir = '/Users/hannahchung/Downloads/cleaned_jittered/'\n",
    "import pathlib\n",
    "print(\"data_dir is set to:\", data_dir)\n",
    "print(\"expected_dir     :\", expected_dir)\n",
    "print()\n",
    "if pathlib.Path(data_dir).resolve() == pathlib.Path(expected_dir).resolve():\n",
    "    print(\"data_dir points to cleaned_jittered\")\n",
    "else:\n",
    "    print(\"data_dir is NOT the jittered folder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdd2687c8254d07a143cafc129c14a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>L1</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>aad</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ada</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>add</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>daa</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer orientation                                               data\n",
       "0      1          L1  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "1      2         aad  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "2      2         ada  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "3      2         add  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "4      2         daa  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_wv = convert_to_wavelet_basis_3d(data_dir)\n",
    "gray_wv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9198dc35e0114f9a803054c0f3f5674b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5935700d634486a152f87ba8e13fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/nwm9l18x22zc8_fj15gvgg2h0000gp/T/ipykernel_44464/1923987592.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  jittered_gray_df = pd.concat([jittered_gray_df, ks_df], axis = 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55556d2d69714bd7b7d71467105dc88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bd831e79c14dc3b55f126d81add2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14de33331694a95b8336b598d01dd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2810e048024f388e55ffa510b02be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e1fae2eb2346deab4c3b7efa9130de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dccdf647cd4163a2a6243ed60ef412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/nwm9l18x22zc8_fj15gvgg2h0000gp/T/ipykernel_44464/1923987592.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  jittered_gray_df = pd.concat([jittered_gray_df, ks_df], axis = 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cc66ac7a474cc5a0822306d913546c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/nwm9l18x22zc8_fj15gvgg2h0000gp/T/ipykernel_44464/1923987592.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  jittered_gray_df = pd.concat([jittered_gray_df, ks_df], axis = 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>KS_Stat</th>\n",
       "      <th>Pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>add</td>\n",
       "      <td>daa</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>2.409579e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>daa</td>\n",
       "      <td>dad</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>2.409579e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>dda</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.119880</td>\n",
       "      <td>1.100344e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>add</td>\n",
       "      <td>dad</td>\n",
       "      <td>0.128871</td>\n",
       "      <td>1.160573e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>dad</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.212787</td>\n",
       "      <td>2.992032e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>aad</td>\n",
       "      <td>add</td>\n",
       "      <td>0.189767</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>aad</td>\n",
       "      <td>dad</td>\n",
       "      <td>0.196239</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>ada</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.259576</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>daa</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.261190</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>aad</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.290564</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Layer First Second   KS_Stat        Pvalue\n",
       "11     3   add    daa  0.081918  2.409579e-03\n",
       "15     3   daa    dad  0.081918  2.409579e-03\n",
       "20     3   dda    ddd  0.119880  1.100344e-06\n",
       "12     3   add    dad  0.128871  1.160573e-07\n",
       "19     3   dad    ddd  0.212787  2.992032e-20\n",
       "..   ...   ...    ...       ...           ...\n",
       "1      8   aad    add  0.189767  0.000000e+00\n",
       "3      8   aad    dad  0.196239  0.000000e+00\n",
       "10     8   ada    ddd  0.259576  0.000000e+00\n",
       "17     8   daa    ddd  0.261190  0.000000e+00\n",
       "5      8   aad    ddd  0.290564  0.000000e+00\n",
       "\n",
       "[126 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jittered_gray_df = pd.DataFrame(columns = [\"Layer\", \"First\", \"Second\", \"KS_Stat\", \"Pvalue\"])\n",
    "for i in range(2, 11):\n",
    "    layer_df = gray_wv[gray_wv[\"layer\"] == i]\n",
    "    data = layer_df[\"data\"].to_list()\n",
    "    names = layer_df[\"orientation\"].to_list()\n",
    "    ks_df = ksCombinations(data, layer_df[\"orientation\"].to_list(), i).sort_values([\"Layer\", \"KS_Stat\"])\n",
    "    jittered_gray_df = pd.concat([jittered_gray_df, ks_df], axis = 0)\n",
    "jittered_gray_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jittered_gray_df.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(jittered_gray_df, 'jittered_gray_df.pkl')\n",
    "# gray_df = joblib.load('gray_df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jittered_gray_df = joblib.load('jittered_gray_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>KS_Stat</th>\n",
       "      <th>Pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>add</td>\n",
       "      <td>daa</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>2.409579e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>daa</td>\n",
       "      <td>dad</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>2.409579e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>dda</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.119880</td>\n",
       "      <td>1.100344e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>add</td>\n",
       "      <td>dad</td>\n",
       "      <td>0.128871</td>\n",
       "      <td>1.160573e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>dad</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.212787</td>\n",
       "      <td>2.992032e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>aad</td>\n",
       "      <td>add</td>\n",
       "      <td>0.189767</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>aad</td>\n",
       "      <td>dad</td>\n",
       "      <td>0.196239</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>ada</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.259576</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>daa</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.261190</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>aad</td>\n",
       "      <td>ddd</td>\n",
       "      <td>0.290564</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Layer First Second   KS_Stat        Pvalue\n",
       "11     3   add    daa  0.081918  2.409579e-03\n",
       "15     3   daa    dad  0.081918  2.409579e-03\n",
       "20     3   dda    ddd  0.119880  1.100344e-06\n",
       "12     3   add    dad  0.128871  1.160573e-07\n",
       "19     3   dad    ddd  0.212787  2.992032e-20\n",
       "..   ...   ...    ...       ...           ...\n",
       "1      8   aad    add  0.189767  0.000000e+00\n",
       "3      8   aad    dad  0.196239  0.000000e+00\n",
       "10     8   ada    ddd  0.259576  0.000000e+00\n",
       "17     8   daa    ddd  0.261190  0.000000e+00\n",
       "5      8   aad    ddd  0.290564  0.000000e+00\n",
       "\n",
       "[126 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jittered_gray_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiSampleComparisonPlots(data, samp_names, bw=0.2, hist_plot=True):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "    for i in range(len(data)):\n",
    "        samp = data[i]\n",
    "        name = samp_names[i]\n",
    "        n = len(samp)\n",
    "\n",
    "        sns.kdeplot(ax=axes[0], x=samp, bw_method=bw, label=name)\n",
    "        sns.kdeplot(ax=axes[1], x=samp, bw_method=bw, log_scale=[False, True], label=name)\n",
    "        axes[2].plot(np.sort(samp), np.arange(1, n+1)/n, label=name)\n",
    "\n",
    "        if hist_plot:\n",
    "            sns.histplot(ax=axes[0], x=samp, stat='density', label=name, alpha=0.2)\n",
    "            sns.histplot(ax=axes[1], x=samp, stat='density', log=True, label=name, alpha=0.2)\n",
    "\n",
    "    axes[0].set_title(\"Non-Log PDF\")\n",
    "    axes[1].set_title(\"Log-Scale PDF\")\n",
    "    axes[2].set_title(\"CDF\")\n",
    "    for ax in axes: ax.legend()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoSampleComparisonPlots(gray_wv, layer_num, ori1, ori2, bw=0.2, alpha=0.2, plot_hist=False):\n",
    "    df = gray_wv[gray_wv[\"layer\"] == layer_num]\n",
    "    samp1_row = df[df[\"orientation\"] == ori1]\n",
    "    samp2_row = df[df[\"orientation\"] == ori2]\n",
    "\n",
    "    if samp1_row.empty or samp2_row.empty:\n",
    "        print(f\"One or both orientations not found in layer {layer_num}: {ori1}, {ori2}\")\n",
    "        return\n",
    "\n",
    "    s1 = samp1_row[\"data\"].values[0]\n",
    "    s2 = samp2_row[\"data\"].values[0]\n",
    "    name1 = samp1_row[\"axis_description\"].values[0]\n",
    "    name2 = samp2_row[\"axis_description\"].values[0]\n",
    "\n",
    "    ksres = stats.ks_2samp(s1, s2)\n",
    "    ks_stat = ksres.statistic\n",
    "    ks_pval = ksres.pvalue\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "    sns.kdeplot(ax=axes[0], x=s1, bw_method=bw, label=name1)\n",
    "    sns.kdeplot(ax=axes[0], x=s2, bw_method=bw, label=name2)\n",
    "    sns.kdeplot(ax=axes[1], x=s1, bw_method=bw, log_scale=[False, True], label=name1)\n",
    "    sns.kdeplot(ax=axes[1], x=s2, bw_method=bw, log_scale=[False, True], label=name2)\n",
    "\n",
    "    if plot_hist:\n",
    "        sns.histplot(ax=axes[0], x=s1, stat='density', alpha=alpha, label=name1)\n",
    "        sns.histplot(ax=axes[0], x=s2, stat='density', alpha=alpha, label=name2)\n",
    "        sns.histplot(ax=axes[1], x=s1, stat='density', log=True, alpha=alpha, label=name1)\n",
    "        sns.histplot(ax=axes[1], x=s2, stat='density', log=True, alpha=alpha, label=name2)\n",
    "\n",
    "    axes[2].plot(np.sort(s1), np.arange(1, len(s1)+1)/len(s1), label=name1)\n",
    "    axes[2].plot(np.sort(s2), np.arange(1, len(s2)+1)/len(s2), label=name2)\n",
    "\n",
    "    axes[0].set_title(\"Non-Log PDF\")\n",
    "    axes[1].set_title(\"Log-Scale PDF\")\n",
    "    axes[2].set_title(f\"CDF (p={ks_pval:.2e}, D={ks_stat:.4f})\")\n",
    "    for ax in axes: ax.legend()\n",
    "    return fig\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv",
   "language": "python",
   "name": "hbmv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
