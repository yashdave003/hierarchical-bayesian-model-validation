{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"pastis\"\n",
    "FINAL_DATA_NAME = 'pastis-full-fourier' # + channel\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"pastis-RGB-jitter\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','pastis')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test0.npz', 'test1.npz', 'test10.npz', 'test100.npz', 'test1000.npz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full-pastis-RGB-jitter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values obtained from plots in pastisFourierEDA.ipynb\n",
    "STARTING_VALUE = 0.059498227389561786\n",
    "ENDING_VALUE = 0.6743233008450027\n",
    "MULT_FACTOR = 1.08\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"pastis\", f\"full-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"pastis\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")\n",
    "splits = getSplits(STARTING_VALUE,ENDING_VALUE, MULT_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/1590 [00:00<00:17, 88.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:10<00:00, 156.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05949823 0.06425809 0.06939873 0.07495063 0.08094668 0.08742242\n",
      " 0.09441621 0.10196951 0.11012707 0.11893723 0.12845221 0.13872839\n",
      " 0.14982666 0.16181279 0.17475781 0.18873844 0.20383751 0.22014452\n",
      " 0.23775608 0.25677656 0.27731869 0.29950418 0.32346452 0.34934168\n",
      " 0.37728901 0.40747213 0.44006991 0.4752755  0.51329754 0.55436134\n",
      " 0.59871025 0.64660707 0.69833563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 22.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.0, 0.05687585851000405)</td>\n",
       "      <td>27</td>\n",
       "      <td>[-24.861084, 30.276884, -56.80937, 131.9214, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.059498227389561786, 0.06298638865858242)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-6.030884, 1.4241083, -0.52024317, -1.1112274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.06442352540027595, 0.06720566614877052)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-2.9934132, -1.3881443, -0.03483515, -5.82839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.06987712429686843, 0.07411588266019639)</td>\n",
       "      <td>6</td>\n",
       "      <td>[3.6712542, 1.7049004, 2.7085834, -2.007795, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.07694420157653206, 0.08043461047646094)</td>\n",
       "      <td>6</td>\n",
       "      <td>[3.2446606, -2.3480656, 0.9849038, -0.30818298...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                          magnitude_endpoints  \\\n",
       "0     1     red                   (0.0, 0.05687585851000405)   \n",
       "1     2     red  (0.059498227389561786, 0.06298638865858242)   \n",
       "2     3     red   (0.06442352540027595, 0.06720566614877052)   \n",
       "3     4     red   (0.06987712429686843, 0.07411588266019639)   \n",
       "4     5     red   (0.07694420157653206, 0.08043461047646094)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 27  [-24.861084, 30.276884, -56.80937, 131.9214, -...  \n",
       "1                  4  [-6.030884, 1.4241083, -0.52024317, -1.1112274...  \n",
       "2                  4  [-2.9934132, -1.3881443, -0.03483515, -5.82839...  \n",
       "3                  6  [3.6712542, 1.7049004, 2.7085834, -2.007795, 2...  \n",
       "4                  6  [3.2446606, -2.3480656, 0.9849038, -0.30818298...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:09<00:00, 160.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05949823 0.06425809 0.06939873 0.07495063 0.08094668 0.08742242\n",
      " 0.09441621 0.10196951 0.11012707 0.11893723 0.12845221 0.13872839\n",
      " 0.14982666 0.16181279 0.17475781 0.18873844 0.20383751 0.22014452\n",
      " 0.23775608 0.25677656 0.27731869 0.29950418 0.32346452 0.34934168\n",
      " 0.37728901 0.40747213 0.44006991 0.4752755  0.51329754 0.55436134\n",
      " 0.59871025 0.64660707 0.69833563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 26.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.0, 0.05687585851000405)</td>\n",
       "      <td>27</td>\n",
       "      <td>[-18.225143, 13.255581, -140.12164, 310.49835,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.059498227389561786, 0.06298638865858242)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-7.0464673, 2.12714, 0.034075595, -0.96772146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.06442352540027595, 0.06720566614877052)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-3.9977355, -2.1376965, -0.24100864, -6.82660...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.06987712429686843, 0.07411588266019639)</td>\n",
       "      <td>6</td>\n",
       "      <td>[4.5522947, 1.6904095, 3.4049926, -2.2560484, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.07694420157653206, 0.08043461047646094)</td>\n",
       "      <td>6</td>\n",
       "      <td>[5.6217756, -3.2498698, 1.6942921, 0.5276802, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                          magnitude_endpoints  \\\n",
       "0     1    blue                   (0.0, 0.05687585851000405)   \n",
       "1     2    blue  (0.059498227389561786, 0.06298638865858242)   \n",
       "2     3    blue   (0.06442352540027595, 0.06720566614877052)   \n",
       "3     4    blue   (0.06987712429686843, 0.07411588266019639)   \n",
       "4     5    blue   (0.07694420157653206, 0.08043461047646094)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 27  [-18.225143, 13.255581, -140.12164, 310.49835,...  \n",
       "1                  4  [-7.0464673, 2.12714, 0.034075595, -0.96772146...  \n",
       "2                  4  [-3.9977355, -2.1376965, -0.24100864, -6.82660...  \n",
       "3                  6  [4.5522947, 1.6904095, 3.4049926, -2.2560484, ...  \n",
       "4                  6  [5.6217756, -3.2498698, 1.6942921, 0.5276802, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:07<00:00, 201.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05949823 0.06425809 0.06939873 0.07495063 0.08094668 0.08742242\n",
      " 0.09441621 0.10196951 0.11012707 0.11893723 0.12845221 0.13872839\n",
      " 0.14982666 0.16181279 0.17475781 0.18873844 0.20383751 0.22014452\n",
      " 0.23775608 0.25677656 0.27731869 0.29950418 0.32346452 0.34934168\n",
      " 0.37728901 0.40747213 0.44006991 0.4752755  0.51329754 0.55436134\n",
      " 0.59871025 0.64660707 0.69833563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 23.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.0, 0.05687585851000405)</td>\n",
       "      <td>27</td>\n",
       "      <td>[9.734376, 101.640686, -63.905636, 208.2195, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.059498227389561786, 0.06298638865858242)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-6.2086134, 2.059569, -1.7726663, -1.6128868,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.06442352540027595, 0.06720566614877052)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-3.2425828, -2.7061038, 0.4256218, -5.6334505...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.06987712429686843, 0.07411588266019639)</td>\n",
       "      <td>6</td>\n",
       "      <td>[3.7014298, 1.8141629, 2.4538603, -2.1576967, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.07694420157653206, 0.08043461047646094)</td>\n",
       "      <td>6</td>\n",
       "      <td>[4.112957, -2.101753, 1.1816337, -0.14651218, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                          magnitude_endpoints  \\\n",
       "0     1   green                   (0.0, 0.05687585851000405)   \n",
       "1     2   green  (0.059498227389561786, 0.06298638865858242)   \n",
       "2     3   green   (0.06442352540027595, 0.06720566614877052)   \n",
       "3     4   green   (0.06987712429686843, 0.07411588266019639)   \n",
       "4     5   green   (0.07694420157653206, 0.08043461047646094)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 27  [9.734376, 101.640686, -63.905636, 208.2195, -...  \n",
       "1                  4  [-6.2086134, 2.059569, -1.7726663, -1.6128868,...  \n",
       "2                  4  [-3.2425828, -2.7061038, 0.4256218, -5.6334505...  \n",
       "3                  6  [3.7014298, 1.8141629, 2.4538603, -2.1576967, ...  \n",
       "4                  6  [4.112957, -2.101753, 1.1816337, -0.14651218, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:08<00:00, 180.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05949823 0.06425809 0.06939873 0.07495063 0.08094668 0.08742242\n",
      " 0.09441621 0.10196951 0.11012707 0.11893723 0.12845221 0.13872839\n",
      " 0.14982666 0.16181279 0.17475781 0.18873844 0.20383751 0.22014452\n",
      " 0.23775608 0.25677656 0.27731869 0.29950418 0.32346452 0.34934168\n",
      " 0.37728901 0.40747213 0.44006991 0.4752755  0.51329754 0.55436134\n",
      " 0.59871025 0.64660707 0.69833563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 25.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.0, 0.05687585851000405)</td>\n",
       "      <td>27</td>\n",
       "      <td>[-3.794566, 70.223976, -70.4668, 197.05296, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.059498227389561786, 0.06298638865858242)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-6.2503843, 1.8771269, -1.1921712, -1.3892307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.06442352540027595, 0.06720566614877052)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-3.253869, -2.2470965, 0.21195279, -5.8271747...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.06987712429686843, 0.07411588266019639)</td>\n",
       "      <td>6</td>\n",
       "      <td>[3.7890387, 1.767215, 2.6381807, -2.1238875, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.07694420157653206, 0.08043461047646094)</td>\n",
       "      <td>6</td>\n",
       "      <td>[4.0250173, -2.306051, 1.181156, -0.11796299, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                          magnitude_endpoints  \\\n",
       "0     1    gray                   (0.0, 0.05687585851000405)   \n",
       "1     2    gray  (0.059498227389561786, 0.06298638865858242)   \n",
       "2     3    gray   (0.06442352540027595, 0.06720566614877052)   \n",
       "3     4    gray   (0.06987712429686843, 0.07411588266019639)   \n",
       "4     5    gray   (0.07694420157653206, 0.08043461047646094)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 27  [-3.794566, 70.223976, -70.4668, 197.05296, -1...  \n",
       "1                  4  [-6.2503843, 1.8771269, -1.1921712, -1.3892307...  \n",
       "2                  4  [-3.253869, -2.2470965, 0.21195279, -5.8271747...  \n",
       "3                  6  [3.7890387, 1.767215, 2.6381807, -2.1238875, 2...  \n",
       "4                  6  [4.0250173, -2.306051, 1.181156, -0.11796299, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'pastis-full-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"pastis\", f\"full-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"pastis\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a92252dd126423abe47f84eb4b4f831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>L1</td>\n",
       "      <td>[-17.87532, 35.166245, -48.626526, 133.00833, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[-10.262734, -29.364178, -24.123205, -15.51534...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>H</td>\n",
       "      <td>[-5.1620855, -14.308258, 10.178457, -17.504862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>V</td>\n",
       "      <td>[-14.575477, 21.073135, -3.916397, 48.622383, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166018</td>\n",
       "      <td>D</td>\n",
       "      <td>[9.321508, -15.187627, -17.848015, -0.11846423...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0     red      1   0.124514          L1   \n",
       "1     red      2   0.142301           D   \n",
       "2     red      2   0.142301           H   \n",
       "3     red      2   0.142301           V   \n",
       "4     red      3   0.166018           D   \n",
       "\n",
       "                                                data  \n",
       "0  [-17.87532, 35.166245, -48.626526, 133.00833, ...  \n",
       "1  [-10.262734, -29.364178, -24.123205, -15.51534...  \n",
       "2  [-5.1620855, -14.308258, 10.178457, -17.504862...  \n",
       "3  [-14.575477, 21.073135, -3.916397, 48.622383, ...  \n",
       "4  [9.321508, -15.187627, -17.848015, -0.11846423...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_wv[(channel_wv['orientation'] == 'D') & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4e04835cf0425395d8a8ce747695c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>L1</td>\n",
       "      <td>[-10.37733, 75.73772, -79.390594, 175.60312, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[-12.031702, -30.325314, -17.278893, -1.111858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>H</td>\n",
       "      <td>[-0.42663336, -11.753025, 8.718273, -37.660652...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>V</td>\n",
       "      <td>[-6.8753595, 18.896374, -3.8363228, 52.096413,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>green</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166018</td>\n",
       "      <td>D</td>\n",
       "      <td>[9.789757, -18.019499, -19.674395, -3.8005397,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0   green      1   0.124514          L1   \n",
       "1   green      2   0.142301           D   \n",
       "2   green      2   0.142301           H   \n",
       "3   green      2   0.142301           V   \n",
       "4   green      3   0.166018           D   \n",
       "\n",
       "                                                data  \n",
       "0  [-10.37733, 75.73772, -79.390594, 175.60312, -...  \n",
       "1  [-12.031702, -30.325314, -17.278893, -1.111858...  \n",
       "2  [-0.42663336, -11.753025, 8.718273, -37.660652...  \n",
       "3  [-6.8753595, 18.896374, -3.8363228, 52.096413,...  \n",
       "4  [9.789757, -18.019499, -19.674395, -3.8005397,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_wv[(channel_wv['orientation'] == 'D') & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753ea380300a4dc4b5cc60c11c520e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>L1</td>\n",
       "      <td>[-22.356903, 7.0353584, -136.08597, 284.36432,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[-24.884548, -30.965683, -37.750427, -21.34841...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>H</td>\n",
       "      <td>[-3.8561678, -9.655399, 20.538467, -36.587543,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>V</td>\n",
       "      <td>[-16.508152, 32.295002, -13.752541, 90.18894, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166018</td>\n",
       "      <td>D</td>\n",
       "      <td>[9.132104, -22.443195, -28.56291, -0.9180093, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    blue      1   0.124514          L1   \n",
       "1    blue      2   0.142301           D   \n",
       "2    blue      2   0.142301           H   \n",
       "3    blue      2   0.142301           V   \n",
       "4    blue      3   0.166018           D   \n",
       "\n",
       "                                                data  \n",
       "0  [-22.356903, 7.0353584, -136.08597, 284.36432,...  \n",
       "1  [-24.884548, -30.965683, -37.750427, -21.34841...  \n",
       "2  [-3.8561678, -9.655399, 20.538467, -36.587543,...  \n",
       "3  [-16.508152, 32.295002, -13.752541, 90.18894, ...  \n",
       "4  [9.132104, -22.443195, -28.56291, -0.9180093, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_wv[(channel_wv['orientation'] == 'D') & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d841e0dabeb4ffa80c90dcd6d4b4318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gray</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>L1</td>\n",
       "      <td>[-13.983116, 55.771275, -76.650566, 175.25279,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[-12.966983, -30.108007, -21.65669, -7.7239122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>H</td>\n",
       "      <td>[-2.2329843, -12.276482, 10.501353, -31.509989...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>V</td>\n",
       "      <td>[-10.274378, 21.072567, -4.990321, 55.39537, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gray</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166018</td>\n",
       "      <td>D</td>\n",
       "      <td>[9.573847, -17.675556, -20.139816, -2.3709795,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    gray      1   0.124514          L1   \n",
       "1    gray      2   0.142301           D   \n",
       "2    gray      2   0.142301           H   \n",
       "3    gray      2   0.142301           V   \n",
       "4    gray      3   0.166018           D   \n",
       "\n",
       "                                                data  \n",
       "0  [-13.983116, 55.771275, -76.650566, 175.25279,...  \n",
       "1  [-12.966983, -30.108007, -21.65669, -7.7239122...  \n",
       "2  [-2.2329843, -12.276482, 10.501353, -31.509989...  \n",
       "3  [-10.274378, 21.072567, -4.990321, 55.39537, 6...  \n",
       "4  [9.573847, -17.675556, -20.139816, -2.3709795,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_wv[(channel_wv['orientation'] == 'D') & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-diagonal-{channel}-size.pickle\"))\n",
    "\n",
    "\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HBMV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
