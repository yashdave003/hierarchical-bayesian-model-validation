{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'approx1e5-coco-outdoor-fourier' # + channel\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"coco-cropped-Outdoor\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','coco')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000335177.jpg',\n",
       " '000000278705.jpg',\n",
       " '000000568981.jpg',\n",
       " '000000092416.jpg',\n",
       " '000000173830.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [os.path.join(data_dir, f\"toy-{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(os.path.join(data_dir, f\"toy-{RAW_DATA_SUFFIX}\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toy-coco-cropped-Outdoor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX) and not x.__contains__(\"._\")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npz_opener_pickle(path):\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.026203921611325662, 0.03092062750136428, 0.036486340451609846, 0.04305388173289962, 0.05080358044482155, 0.05994822492488942, 0.07073890541136951, 0.08347190838541602, 0.09849685189479089, 0.11622628523585324, 0.1371470165783068, 0.16183347956240202, 0.19096350588363437, 0.22533693694268853, 0.2658975855923724, 0.3137591509989994, 0.3702357981788193, 0.43687824185100677, 0.5155163253841879, 0.6083092639533417, 0.7178049314649432]\n"
     ]
    }
   ],
   "source": [
    "#Values obtained from plots in coco_indoor_Fourier_NEW.ipynb\n",
    "STARTING_VALUE = 0.026203921611325662\n",
    "ENDING_VALUE =0.6138159492317302\n",
    "MULT_FACTOR = 1.18\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"toy-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")\n",
    "splits = getSplits(STARTING_VALUE,ENDING_VALUE, MULT_FACTOR)\n",
    "print(splits)\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2446/2446 [00:11<00:00, 212.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02620392 0.03092063 0.03648634 0.04305388 0.05080358 0.05994822\n",
      " 0.07073891 0.08347191 0.09849685 0.11622629 0.13714702 0.16183348\n",
      " 0.19096351 0.22533694 0.26589759 0.31375915 0.3702358  0.43687824\n",
      " 0.51551633 0.60830926 0.71780493]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:03<00:00,  6.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.0, 0.025012204052472065)</td>\n",
       "      <td>22</td>\n",
       "      <td>[28482.855, 30711.96, 35676.426, 29848.79, 389...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.026203921611325662, 0.030508787796510367)</td>\n",
       "      <td>7</td>\n",
       "      <td>[65.72201, -254.89946, -53.10038, 250.94365, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.03125, 0.03601384553630034)</td>\n",
       "      <td>10</td>\n",
       "      <td>[30.199188, 84.70316, 555.7424, -144.31247, -7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.036851488797096106, 0.04296875)</td>\n",
       "      <td>13</td>\n",
       "      <td>[-66.74939, -64.2344, 70.77693, 32.897762, -10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.04314594147338774, 0.05078125)</td>\n",
       "      <td>17</td>\n",
       "      <td>[273.52667, 453.15985, -8.039323, 134.58537, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1     red                   (0.0, 0.025012204052472065)   \n",
       "1     2     red  (0.026203921611325662, 0.030508787796510367)   \n",
       "2     3     red                (0.03125, 0.03601384553630034)   \n",
       "3     4     red            (0.036851488797096106, 0.04296875)   \n",
       "4     5     red             (0.04314594147338774, 0.05078125)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 22  [28482.855, 30711.96, 35676.426, 29848.79, 389...  \n",
       "1                  7  [65.72201, -254.89946, -53.10038, 250.94365, -...  \n",
       "2                 10  [30.199188, 84.70316, 555.7424, -144.31247, -7...  \n",
       "3                 13  [-66.74939, -64.2344, 70.77693, 32.897762, -10...  \n",
       "4                 17  [273.52667, 453.15985, -8.039323, 134.58537, -...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener_pickle)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:04<00:00, 371.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02620392 0.03223082 0.03964391 0.04876201 0.05997728 0.07377205\n",
      " 0.09073962 0.11160973 0.13727997 0.16885437 0.20769087 0.25545977\n",
      " 0.31421552 0.38648509 0.47537666 0.58471329 0.71919734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00,  9.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.0, 0.025012204052472065)</td>\n",
       "      <td>22</td>\n",
       "      <td>[25380.016, 30578.777, 43920.64, 22871.48, 249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.026203921611325662, 0.03221176270013797)</td>\n",
       "      <td>10</td>\n",
       "      <td>[-29.592005, -5.743617, 269.38425, -99.818245,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.03314563036811941, 0.039257326645003476)</td>\n",
       "      <td>13</td>\n",
       "      <td>[10.993307, -31.40373, -139.4958, -7.939845, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.03983608994994363, 0.048317644050206957)</td>\n",
       "      <td>19</td>\n",
       "      <td>[-120.00683, -54.023926, -365.25037, -63.58884...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.04894517221149089, 0.05975413492491545)</td>\n",
       "      <td>28</td>\n",
       "      <td>[11.270843, -51.959522, 25.22712, -34.639797, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                          magnitude_endpoints  \\\n",
       "0     1    blue                  (0.0, 0.025012204052472065)   \n",
       "1     2    blue  (0.026203921611325662, 0.03221176270013797)   \n",
       "2     3    blue  (0.03314563036811941, 0.039257326645003476)   \n",
       "3     4    blue  (0.03983608994994363, 0.048317644050206957)   \n",
       "4     5    blue   (0.04894517221149089, 0.05975413492491545)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 22  [25380.016, 30578.777, 43920.64, 22871.48, 249...  \n",
       "1                 10  [-29.592005, -5.743617, 269.38425, -99.818245,...  \n",
       "2                 13  [10.993307, -31.40373, -139.4958, -7.939845, -...  \n",
       "3                 19  [-120.00683, -54.023926, -365.25037, -63.58884...  \n",
       "4                 28  [11.270843, -51.959522, 25.22712, -34.639797, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener_pickle)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:04<00:00, 371.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02620392 0.03223082 0.03964391 0.04876201 0.05997728 0.07377205\n",
      " 0.09073962 0.11160973 0.13727997 0.16885437 0.20769087 0.25545977\n",
      " 0.31421552 0.38648509 0.47537666 0.58471329 0.71919734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00,  8.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.0, 0.025012204052472065)</td>\n",
       "      <td>22</td>\n",
       "      <td>[24739.984, 34184.09, 45530.055, 27241.96, 308...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.026203921611325662, 0.03221176270013797)</td>\n",
       "      <td>10</td>\n",
       "      <td>[-91.89867, -166.39987, 243.79117, -100.061554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.03314563036811941, 0.039257326645003476)</td>\n",
       "      <td>13</td>\n",
       "      <td>[-3.8628771, 10.944305, -136.06499, 13.759761,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.03983608994994363, 0.048317644050206957)</td>\n",
       "      <td>19</td>\n",
       "      <td>[-151.74765, -10.343752, -296.91342, -40.27313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.04894517221149089, 0.05975413492491545)</td>\n",
       "      <td>28</td>\n",
       "      <td>[-6.313587, -67.33274, -3.907643, -10.753381, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                          magnitude_endpoints  \\\n",
       "0     1   green                  (0.0, 0.025012204052472065)   \n",
       "1     2   green  (0.026203921611325662, 0.03221176270013797)   \n",
       "2     3   green  (0.03314563036811941, 0.039257326645003476)   \n",
       "3     4   green  (0.03983608994994363, 0.048317644050206957)   \n",
       "4     5   green   (0.04894517221149089, 0.05975413492491545)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 22  [24739.984, 34184.09, 45530.055, 27241.96, 308...  \n",
       "1                 10  [-91.89867, -166.39987, 243.79117, -100.061554...  \n",
       "2                 13  [-3.8628771, 10.944305, -136.06499, 13.759761,...  \n",
       "3                 19  [-151.74765, -10.343752, -296.91342, -40.27313...  \n",
       "4                 28  [-6.313587, -67.33274, -3.907643, -10.753381, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener_pickle)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1604/1604 [00:05<00:00, 294.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02620392 0.03223082 0.03964391 0.04876201 0.05997728 0.07377205\n",
      " 0.09073962 0.11160973 0.13727997 0.16885437 0.20769087 0.25545977\n",
      " 0.31421552 0.38648509 0.47537666 0.58471329 0.71919734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00,  8.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.0, 0.025012204052472065)</td>\n",
       "      <td>22</td>\n",
       "      <td>[25300.414, 33779.24, 46227.543, 28610.145, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.026203921611325662, 0.03221176270013797)</td>\n",
       "      <td>10</td>\n",
       "      <td>[-102.580414, -145.0102, 237.34221, -74.68768,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.03314563036811941, 0.039257326645003476)</td>\n",
       "      <td>13</td>\n",
       "      <td>[-33.4497, -42.67274, -123.34379, 17.246386, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.03983608994994363, 0.048317644050206957)</td>\n",
       "      <td>19</td>\n",
       "      <td>[-157.2597, -57.384617, -313.06015, -34.103252...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.04894517221149089, 0.05975413492491545)</td>\n",
       "      <td>28</td>\n",
       "      <td>[14.109035, -68.36598, -6.147733, -23.62347, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                          magnitude_endpoints  \\\n",
       "0     1    gray                  (0.0, 0.025012204052472065)   \n",
       "1     2    gray  (0.026203921611325662, 0.03221176270013797)   \n",
       "2     3    gray  (0.03314563036811941, 0.039257326645003476)   \n",
       "3     4    gray  (0.03983608994994363, 0.048317644050206957)   \n",
       "4     5    gray   (0.04894517221149089, 0.05975413492491545)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 22  [25300.414, 33779.24, 46227.543, 28610.145, 30...  \n",
       "1                 10  [-102.580414, -145.0102, 237.34221, -74.68768,...  \n",
       "2                 13  [-33.4497, -42.67274, -123.34379, 17.246386, 3...  \n",
       "3                 19  [-157.2597, -57.384617, -313.06015, -34.103252...  \n",
       "4                 28  [14.109035, -68.36598, -6.147733, -23.62347, 1...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener_pickle)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'approx1e5-agriVision-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"full-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [01:33<00:00, 48.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099611</td>\n",
       "      <td>L1</td>\n",
       "      <td>[12.37854, 388.76587, -71.011154, -525.40607, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>D</td>\n",
       "      <td>[-56.85054, 10.112775, -65.61645, 3.6756237, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>H</td>\n",
       "      <td>[426.77856, 36.807053, 2.2234993, 41.115826, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>V</td>\n",
       "      <td>[-458.58713, 52.57764, -45.266056, -4.2271876,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>3</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-192.24008, 1.2320688, -6.463406, 114.53845, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0     red      1   0.099611          L1   \n",
       "1     red      2   0.110679           D   \n",
       "2     red      2   0.110679           H   \n",
       "3     red      2   0.110679           V   \n",
       "4     red      3   0.124514           D   \n",
       "\n",
       "                                                data  \n",
       "0  [12.37854, 388.76587, -71.011154, -525.40607, ...  \n",
       "1  [-56.85054, 10.112775, -65.61645, 3.6756237, -...  \n",
       "2  [426.77856, 36.807053, 2.2234993, 41.115826, 3...  \n",
       "3  [-458.58713, 52.57764, -45.266056, -4.2271876,...  \n",
       "4  [-192.24008, 1.2320688, -6.463406, 114.53845, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1416/4500 [00:32<01:11, 43.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m TRANSFORM \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwavelet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m channel_wv \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_wavelet_basis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_opener\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnpz_opener\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m channel_wv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m channel_wv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SAVE_DF:\n",
      "File \u001b[0;32m~/Desktop/hierarchical-bayesian-model-validation/utilities/transform.py:63\u001b[0m, in \u001b[0;36mconvert_to_wavelet_basis\u001b[0;34m(folder_dir, color, basis, image_func, debug, image_opener)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image_opener \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[43mimage_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:,:,c]\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m         image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(file_list[k]))[:,:,c]\n",
      "File \u001b[0;32m~/Desktop/hierarchical-bayesian-model-validation/utilities/transform.py:23\u001b[0m, in \u001b[0;36mnpz_opener\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnpz_opener\u001b[39m(path):\n\u001b[1;32m     22\u001b[0m     npz_file \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path)\n\u001b[0;32m---> 23\u001b[0m     array_data \u001b[38;5;241m=\u001b[39m \u001b[43mnpz_file\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnpz_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array_data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/site-packages/numpy/lib/npyio.py:256\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/site-packages/numpy/lib/format.py:831\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    829\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[1;32m    830\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[0;32m--> 831\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    833\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/site-packages/numpy/lib/format.py:966\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 966\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m    968\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/zipfile.py:929\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 929\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/zipfile.py:1005\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_DEFLATED:\n\u001b[1;32m   1004\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m-> 1005\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39meof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:04<00:00, 365.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>L1</td>\n",
       "      <td>[0.20727114, -33.177452, -23.717556, -104.1030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-26.155533, 6.1044655, 21.780111, 24.545807, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>H</td>\n",
       "      <td>[-90.20362, -75.99399, 19.310474, -11.829856, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>V</td>\n",
       "      <td>[76.4653, 12.720116, -29.556787, -10.373663, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[53.602417, 3.668749, -16.509668, -0.57486, -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    blue      1   0.110679          L1   \n",
       "1    blue      2   0.124514           D   \n",
       "2    blue      2   0.124514           H   \n",
       "3    blue      2   0.124514           V   \n",
       "4    blue      3   0.142301           D   \n",
       "\n",
       "                                                data  \n",
       "0  [0.20727114, -33.177452, -23.717556, -104.1030...  \n",
       "1  [-26.155533, 6.1044655, 21.780111, 24.545807, ...  \n",
       "2  [-90.20362, -75.99399, 19.310474, -11.829856, ...  \n",
       "3  [76.4653, 12.720116, -29.556787, -10.373663, 0...  \n",
       "4  [53.602417, 3.668749, -16.509668, -0.57486, -1...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:04<00:00, 339.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gray</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>L1</td>\n",
       "      <td>[-6.1360106, 35.824085, -12.069928, -92.59161,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-20.23139, 5.5501356, 18.585161, 14.010576, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>H</td>\n",
       "      <td>[-54.903618, -72.86237, 8.412701, -6.4397974, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>V</td>\n",
       "      <td>[55.306328, 9.492829, -24.910969, -6.03024, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gray</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[36.00795, 3.1733897, -9.826171, -1.8638246, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    gray      1   0.110679          L1   \n",
       "1    gray      2   0.124514           D   \n",
       "2    gray      2   0.124514           H   \n",
       "3    gray      2   0.124514           V   \n",
       "4    gray      3   0.142301           D   \n",
       "\n",
       "                                                data  \n",
       "0  [-6.1360106, 35.824085, -12.069928, -92.59161,...  \n",
       "1  [-20.23139, 5.5501356, 18.585161, 14.010576, -...  \n",
       "2  [-54.903618, -72.86237, 8.412701, -6.4397974, ...  \n",
       "3  [55.306328, 9.492829, -24.910969, -6.03024, 0....  \n",
       "4  [36.00795, 3.1733897, -9.826171, -1.8638246, -...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
