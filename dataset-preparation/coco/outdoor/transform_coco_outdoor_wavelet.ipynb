{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'coco-outdoor-wavelet'\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"coco-cropped-Outdoor\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'sandbox', 'raw-data','coco')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000335177.jpg',\n",
       " '000000278705.jpg',\n",
       " '000000568981.jpg',\n",
       " '000000092416.jpg',\n",
       " '000000173830.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [os.path.join(data_dir, f\"toy-{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(os.path.join(data_dir, f\"toy-{RAW_DATA_SUFFIX}\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toy-coco-cropped-Outdoor\n",
      "._toy-coco-cropped-Outdoor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def npz_opener_pickle(path):\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    arr = np.array(image).astype(np.float32)\n",
    "    jitter = np.random.uniform(-0.5, 0.5, arr.shape)\n",
    "    arr += jitter\n",
    "    arr = np.clip(arr, 0, 255)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'coco-outdoor-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"sandbox\", \"raw-data\", \"coco\", f\"toy-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"sandbox\", \"raw-data\", \"coco\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2582a235b3457ea768774200e86bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-19259.096, -19165.588, -18495.984, ...,  19158.129,  20503.637,\n",
      "        20818.31 ], shape=(2446,), dtype=float32), np.int64(3): array([-11188.516, -10392.083, -10239.648, ...,  10450.108,  10530.21 ,\n",
      "        11950.772], shape=(9784,), dtype=float32), np.int64(4): array([-6124.298 , -5833.559 , -5626.8105, ...,  6262.9136,  6299.09  ,\n",
      "        6600.382 ], shape=(39136,), dtype=float32), np.int64(5): array([-3272.7366, -3217.279 , -3204.5447, ...,  2951.105 ,  2989.04  ,\n",
      "        3182.3494], shape=(100000,), dtype=float32), np.int64(6): array([-1872.535 , -1683.3845, -1629.1167, ...,  1566.377 ,  1647.2451,\n",
      "        1848.1818], shape=(100000,), dtype=float32), np.int64(7): array([-950.33307, -857.24194, -833.4833 , ...,  869.6318 ,  987.3166 ,\n",
      "       1005.174  ], shape=(100000,), dtype=float32), np.int64(8): array([-478.55368, -421.2182 , -408.9013 , ...,  405.9977 ,  418.0344 ,\n",
      "        480.25632], shape=(100000,), dtype=float32), np.int64(9): array([-254.86325, -223.54234, -214.87793, ...,  213.16614,  222.2171 ,\n",
      "        254.28825], shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04e4c3503d84b9a91ac15d85c6f0663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-15188.622, -14982.646, -14880.948, ...,  15315.091,  16848.74 ,\n",
      "        20400.133], shape=(2446,), dtype=float32), np.int64(3): array([-10839.301, -10380.639, -10374.067, ...,   9680.847,   9706.972,\n",
      "        11956.701], shape=(9784,), dtype=float32), np.int64(4): array([-6885.585 , -5911.5225, -5693.3926, ...,  5691.756 ,  5693.115 ,\n",
      "        6515.33  ], shape=(39136,), dtype=float32), np.int64(5): array([-3458.7192, -3206.842 , -3182.3455, ...,  3245.37  ,  3413.8237,\n",
      "        3518.4849], shape=(100000,), dtype=float32), np.int64(6): array([-1743.8726, -1671.4539, -1619.5424, ...,  1594.2013,  1644.232 ,\n",
      "        1697.441 ], shape=(100000,), dtype=float32), np.int64(7): array([-928.20575, -852.58405, -822.7509 , ...,  826.851  ,  853.3226 ,\n",
      "        975.524  ], shape=(100000,), dtype=float32), np.int64(8): array([-499.7656 , -419.54602, -406.72797, ...,  403.475  ,  417.8548 ,\n",
      "        480.72662], shape=(100000,), dtype=float32), np.int64(9): array([-254.8214 , -222.81592, -213.86064, ...,  215.14253,  222.33052,\n",
      "        253.84915], shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-outdoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58a1144ebe247a89a72d558caf52dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-20245.676, -19686.979, -19627.152, ...,  20321.568,  20503.916,\n",
      "        21014.857], shape=(2446,), dtype=float32), np.int64(3): array([-11345.502, -10547.392,  -9891.067, ...,  10354.834,  10430.316,\n",
      "        10767.508], shape=(9784,), dtype=float32), np.int64(4): array([-6208.51  , -5481.024 , -5310.303 , ...,  6167.0435,  6262.6553,\n",
      "        6600.7656], shape=(39136,), dtype=float32), np.int64(5): array([-3302.074 , -3172.6914, -3170.0044, ...,  3039.9048,  3081.7722,\n",
      "        3197.9546], shape=(100000,), dtype=float32), np.int64(6): array([-1882.6305, -1705.424 , -1632.1721, ...,  1559.0328,  1590.8412,\n",
      "        1845.7057], shape=(100000,), dtype=float32), np.int64(7): array([-946.31604, -854.3783 , -827.62164, ...,  864.6023 ,  994.39294,\n",
      "       1001.1417 ], shape=(100000,), dtype=float32), np.int64(8): array([-473.1598 , -422.60107, -409.84268, ...,  408.83832,  420.07513,\n",
      "        480.38675], shape=(100000,), dtype=float32), np.int64(9): array([-254.72624, -223.96466, -215.1017 , ...,  213.81018,  222.43748,\n",
      "        254.24625], shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a33633affef4c709905470387a7a9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-15017.322, -14822.194, -13834.171, ...,  15381.168,  16505.91 ,\n",
      "        22862.508], shape=(2446,), dtype=float32), np.int64(3): array([-10380.948 , -10008.695 ,  -9973.551 , ...,  10228.3955,\n",
      "        11162.02  ,  12200.279 ], shape=(9784,), dtype=float32), np.int64(4): array([-5561.006 , -5444.5947, -5443.6177, ...,  5783.563 ,  5880.4688,\n",
      "        5925.144 ], shape=(39136,), dtype=float32), np.int64(5): array([-3346.7402, -3270.9043, -3189.063 , ...,  3297.836 ,  3424.2952,\n",
      "        3543.9485], shape=(100000,), dtype=float32), np.int64(6): array([-1797.0463, -1715.9141, -1623.4104, ...,  1623.5222,  1674.8535,\n",
      "        1796.1827], shape=(100000,), dtype=float32), np.int64(7): array([-927.5306 , -840.86414, -817.57776, ...,  833.0665 ,  865.07874,\n",
      "        941.0327 ], shape=(100000,), dtype=float32), np.int64(8): array([-496.66235, -427.11072, -410.058  , ...,  405.06876,  417.81473,\n",
      "        473.08957], shape=(100000,), dtype=float32), np.int64(9): array([-254.89548, -223.3863 , -215.18062, ...,  215.2641 ,  222.07219,\n",
      "        253.92499], shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-outdoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d394103de0a44b0b97b384efe7f871fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-20960.207, -20495.621, -20480.123, ...,  20643.627,  20793.748,\n",
      "        22358.604], shape=(2446,), dtype=float32), np.int64(3): array([-11730.287, -10498.101, -10266.637, ...,  10977.15 ,  11197.2  ,\n",
      "        12348.804], shape=(9784,), dtype=float32), np.int64(4): array([-6297.9595, -6006.769 , -5952.9707, ...,  6440.356 ,  6600.2925,\n",
      "        6699.411 ], shape=(39136,), dtype=float32), np.int64(5): array([-3371.2244, -3096.3096, -3094.7905, ...,  3111.8323,  3115.4915,\n",
      "        3209.3257], shape=(100000,), dtype=float32), np.int64(6): array([-1771.9393, -1627.7697, -1568.1664, ...,  1566.5753,  1654.5873,\n",
      "        1855.4291], shape=(100000,), dtype=float32), np.int64(7): array([-924.93823, -841.90137, -817.2251 , ...,  848.3376 ,  989.9903 ,\n",
      "       1008.96674], shape=(100000,), dtype=float32), np.int64(8): array([-475.0304 , -418.4434 , -405.07098, ...,  404.3105 ,  416.19315,\n",
      "        483.16223], shape=(100000,), dtype=float32), np.int64(9): array([-253.51007, -222.07169, -213.29037, ...,  212.18578,  221.08032,\n",
      "        254.16742], shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c505bbbe25a4268af72dcb8ce3a47f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-18012.498, -15959.873, -15821.478, ...,  15986.565,  16314.797,\n",
      "        24955.012], shape=(2446,), dtype=float32), np.int64(3): array([-10382.622, -10380.72 ,  -9259.255, ...,  10019.688,  11603.592,\n",
      "        12318.254], shape=(9784,), dtype=float32), np.int64(4): array([-5711.103 , -5598.871 , -5486.5693, ...,  6093.2646,  6131.593 ,\n",
      "        6167.28  ], shape=(39136,), dtype=float32), np.int64(5): array([-3314.54  , -2983.0366, -2964.9946, ...,  3192.2756,  3322.932 ,\n",
      "        3413.1592], shape=(100000,), dtype=float32), np.int64(6): array([-1884.147 , -1660.9617, -1587.2683, ...,  1575.6835,  1595.1849,\n",
      "        1782.2495], shape=(100000,), dtype=float32), np.int64(7): array([-927.56213, -827.19904, -790.5832 , ...,  809.268  ,  844.90375,\n",
      "        931.78766], shape=(100000,), dtype=float32), np.int64(8): array([-499.12378, -424.6758 , -406.85135, ...,  398.94794,  412.64224,\n",
      "        464.90692], shape=(100000,), dtype=float32), np.int64(9): array([-254.87355, -222.08093, -212.8464 , ...,  213.9703 ,  221.41449,\n",
      "        254.00078], shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-outdoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d97a9950efd427a9a109491471414d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-19802.484, -19648.938, -19584.682, ...,  19897.523,  20501.799,\n",
      "        20737.477], shape=(2446,), dtype=float32), np.int64(3): array([-11341.274, -10494.2  ,  -9820.746, ...,  10167.977,  10413.218,\n",
      "        10598.259], shape=(9784,), dtype=float32), np.int64(4): array([-5998.9683, -5499.8877, -5151.819 , ...,  6072.8247,  6262.427 ,\n",
      "        6599.9136], shape=(39136,), dtype=float32), np.int64(5): array([-3280.3245, -3169.5886, -3147.337 , ...,  2933.7307,  2948.397 ,\n",
      "        3141.189 ], shape=(100000,), dtype=float32), np.int64(6): array([-1866.7701, -1637.1066, -1571.6494, ...,  1546.3054,  1585.7024,\n",
      "        1847.6471], shape=(100000,), dtype=float32), np.int64(7): array([-928.52844, -845.6403 , -819.7389 , ...,  853.00653,  993.2215 ,\n",
      "        996.14886], shape=(100000,), dtype=float32), np.int64(8): array([-474.64325, -418.39862, -405.06866, ...,  406.31616,  417.09332,\n",
      "        480.55566], shape=(100000,), dtype=float32), np.int64(9): array([-254.44528, -223.22366, -214.56505, ...,  213.0656 ,  221.64194,\n",
      "        254.30338], shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b533b2d28cf451d9031a658d65c81ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-15064.251, -13838.759, -13499.741, ...,  15116.192,  16274.763,\n",
      "        22363.076], shape=(2446,), dtype=float32), np.int64(3): array([-10379.79 , -10127.814,  -9949.482, ...,   9389.099,   9558.925,\n",
      "        12139.925], shape=(9784,), dtype=float32), np.int64(4): array([-5463.1035, -5413.224 , -5344.7715, ...,  5770.4663,  5795.575 ,\n",
      "        5932.093 ], shape=(39136,), dtype=float32), np.int64(5): array([-3325.2043, -3015.0757, -2938.896 , ...,  3165.458 ,  3419.411 ,\n",
      "        3513.8735], shape=(100000,), dtype=float32), np.int64(6): array([-1790.275 , -1630.92  , -1594.9766, ...,  1583.8788,  1643.5669,\n",
      "        1728.9775], shape=(100000,), dtype=float32), np.int64(7): array([-927.5774 , -834.90295, -797.7751 , ...,  818.54553,  849.7706 ,\n",
      "        939.40155], shape=(100000,), dtype=float32), np.int64(8): array([-497.4475 , -422.3033 , -406.52994, ...,  400.7926 ,  414.4386 ,\n",
      "        471.1863 ], shape=(100000,), dtype=float32), np.int64(9): array([-254.79051, -222.8683 , -214.3421 , ...,  214.74545,  221.96704,\n",
      "        253.94153], shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-outdoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
