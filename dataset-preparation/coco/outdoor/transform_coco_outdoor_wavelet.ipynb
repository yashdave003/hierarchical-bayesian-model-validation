{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'coco-outdoor-wavelet'\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"coco-outdoor-cropped-normalized\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','coco')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outdoor_000000000285.npz',\n",
       " 'outdoor_000000000724.npz',\n",
       " 'outdoor_000000000785.npz',\n",
       " 'outdoor_000000000872.npz',\n",
       " 'outdoor_000000000885.npz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\n",
    "    filename\n",
    "    for filename in os.listdir(os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\"))\n",
    "    if not filename.startswith(\".\")\n",
    "]\n",
    "\n",
    "file_list = [\n",
    "    os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\", filename)\n",
    "    for filename in file_names\n",
    "]\n",
    "\n",
    "file_names[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco-outdoor-cropped-normalized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def npz_opener_pickle(path):\n",
    "    # Load the .npz file\n",
    "    with np.load(path) as data:\n",
    "        arr = data['image']  # Default key if saved without naming the array\n",
    "\n",
    "    arr = arr.astype(np.float32)\n",
    "    \n",
    "    # Apply jitter\n",
    "    jitter = np.random.uniform(-0.5, 0.5, arr.shape)\n",
    "    arr += jitter\n",
    "    arr = np.clip(arr, 0, 255)\n",
    "    \n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'coco-outdoor-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfb18dc07cd42b190bf4e73d50e7bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv_full = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "channel_wv_full['data'] = channel_wv_full['data'].apply(lambda x: x.astype(np.float32))  # if needed, or skip if you jittered already\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = channel_wv_full[channel_wv_full['orientation'] == orientation_code].copy()\n",
    "\n",
    "    if SAVE_DF:\n",
    "        df_save_path = os.path.join(\n",
    "            ROOT_DIR,\n",
    "            \"transformed-data\",\n",
    "            f\"dataframes/{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"\n",
    "        )\n",
    "        pd.to_pickle(channel_wv, df_save_path)\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = {}\n",
    "    group_data_map_size = {}\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        filtered = channel_wv[channel_wv['layer'] == group]\n",
    "        if filtered.empty:\n",
    "            continue\n",
    "\n",
    "        data = filtered['data'].iloc[0]\n",
    "        sampled = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "\n",
    "        group_data_map[group] = sampled\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-outdoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    freq_df_save_path = os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")\n",
    "    freq_df.to_csv(freq_df_save_path)\n",
    "\n",
    "    group_save_base = os.path.join(\n",
    "        ROOT_DIR,\n",
    "        \"transformed-data\",\n",
    "        f\"{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}\"\n",
    "    )\n",
    "    pd.to_pickle(group_data_map, f\"{group_save_base}.pickle\")\n",
    "    pd.to_pickle(group_data_map_size, f\"{group_save_base}-size.pickle\")\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n",
    "    gc.collect()\n",
    "\n",
    "del channel_wv_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaeddf9be0549bfad4b0b73c3e68c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv_full = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "channel_wv_full['data'] = channel_wv_full['data'].apply(lambda x: x.astype(np.float32))  # if needed, or skip if you jittered already\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = channel_wv_full[channel_wv_full['orientation'] == orientation_code].copy()\n",
    "\n",
    "    if SAVE_DF:\n",
    "        df_save_path = os.path.join(\n",
    "            ROOT_DIR,\n",
    "            \"transformed-data\",\n",
    "            f\"dataframes/{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"\n",
    "        )\n",
    "        pd.to_pickle(channel_wv, df_save_path)\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = {}\n",
    "    group_data_map_size = {}\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        filtered = channel_wv[channel_wv['layer'] == group]\n",
    "        if filtered.empty:\n",
    "            continue\n",
    "\n",
    "        data = filtered['data'].iloc[0]\n",
    "        sampled = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "\n",
    "        group_data_map[group] = sampled\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-outdoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    freq_df_save_path = os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")\n",
    "    freq_df.to_csv(freq_df_save_path)\n",
    "\n",
    "    group_save_base = os.path.join(\n",
    "        ROOT_DIR,\n",
    "        \"transformed-data\",\n",
    "        f\"{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}\"\n",
    "    )\n",
    "    pd.to_pickle(group_data_map, f\"{group_save_base}.pickle\")\n",
    "    pd.to_pickle(group_data_map_size, f\"{group_save_base}-size.pickle\")\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n",
    "    gc.collect()\n",
    "\n",
    "del channel_wv_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab497d476ac4400978149630ed94eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-422.43558, -296.65897, -284.92206, ...,  336.5459 ,  354.8944 ,\n",
      "        398.1622 ], dtype=float32), np.int64(3): array([-210.37883, -175.50592, -175.06528, ...,  191.41302,  194.44191,\n",
      "        199.10428], dtype=float32), np.int64(4): array([-111.24049, -103.54764, -102.33232, ...,  106.91356,  107.54587,\n",
      "        111.87244], dtype=float32), np.int64(5): array([-54.95793 , -54.50914 , -53.489067, ...,  54.204308,  56.107887,\n",
      "        57.162865], dtype=float32), np.int64(6): array([-29.474308, -28.347984, -27.541843, ...,  27.370152,  28.186024,\n",
      "        30.114313], dtype=float32), np.int64(7): array([-15.403011, -14.298624, -14.034199, ...,  14.887789,  15.069923,\n",
      "        15.51539 ], dtype=float32), np.int64(8): array([-8.070071 , -7.4080553, -7.2497315, ...,  7.1290865,  7.2992315,\n",
      "        7.824546 ], dtype=float32), np.int64(9): array([-4.3054457, -4.0546207, -3.9765482, ...,  3.9377124,  4.0202265,\n",
      "        4.3197994], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c3e1ad371e46a3be268828b6063466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-292.85895, -218.22467, -214.47041, ...,  265.03024,  286.28748,\n",
      "        288.63464], dtype=float32), np.int64(3): array([-165.75829, -162.91586, -157.63864, ...,  165.98592,  170.98074,\n",
      "        184.14436], dtype=float32), np.int64(4): array([-102.07339,  -97.34307,  -97.15141, ...,   93.38152,   94.39914,\n",
      "         95.41106], dtype=float32), np.int64(5): array([-57.293587, -53.673096, -52.482975, ...,  52.198414,  56.077602,\n",
      "        58.741753], dtype=float32), np.int64(6): array([-28.227037, -27.498676, -26.865114, ...,  26.55831 ,  27.460215,\n",
      "        28.40338 ], dtype=float32), np.int64(7): array([-15.051987, -14.184348, -13.789672, ...,  13.853134,  14.150279,\n",
      "        15.24598 ], dtype=float32), np.int64(8): array([-7.9758153, -7.3700895, -7.191359 , ...,  7.085859 ,  7.274251 ,\n",
      "        7.9877253], dtype=float32), np.int64(9): array([-4.324072 , -4.0582585, -3.9774332, ...,  3.9645524,  4.04367  ,\n",
      "        4.3177786], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777b21dfbed44776a30f1ef5260b8b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-210.16107, -169.18207, -156.10913, ...,  154.16127,  165.36575,\n",
      "        167.46085], dtype=float32), np.int64(3): array([-96.7817  , -88.30004 , -85.82272 , ...,  91.648415,  93.03665 ,\n",
      "       100.59108 ], dtype=float32), np.int64(4): array([-62.194435, -56.748814, -55.60083 , ...,  57.402298,  57.422585,\n",
      "        58.65851 ], dtype=float32), np.int64(5): array([-31.845484, -30.097033, -29.282936, ...,  29.409954,  31.86261 ,\n",
      "        32.173138], dtype=float32), np.int64(6): array([-18.102413, -16.702972, -15.706913, ...,  15.257603,  15.717578,\n",
      "        17.326885], dtype=float32), np.int64(7): array([-9.841684 , -8.304268 , -7.9268475, ...,  7.6713943,  8.2335205,\n",
      "        9.957454 ], dtype=float32), np.int64(8): array([-5.666997 , -4.7185035, -4.4592824, ...,  4.4285717,  4.6269674,\n",
      "        5.5622253], dtype=float32), np.int64(9): array([-4.2041283, -3.2990875, -3.1167479, ...,  3.130167 ,  3.3436477,\n",
      "        4.162753 ], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-outdoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837662560c1c4005b9c24fdafefb478b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-415.14264, -320.7126 , -304.59628, ...,  350.46967,  357.34518,\n",
      "        387.3649 ], dtype=float32), np.int64(3): array([-208.8021 , -157.6937 , -156.72385, ...,  194.46358,  197.00255,\n",
      "        205.25179], dtype=float32), np.int64(4): array([-100.74018,  -90.40927,  -88.71211, ...,  104.64858,  107.72949,\n",
      "        108.12534], dtype=float32), np.int64(5): array([-52.56305 , -51.017727, -49.807095, ...,  53.81147 ,  54.65492 ,\n",
      "        54.657352], dtype=float32), np.int64(6): array([-28.531221, -27.89729 , -27.05191 , ...,  26.50343 ,  26.830542,\n",
      "        28.871508], dtype=float32), np.int64(7): array([-14.552585, -13.902477, -13.49639 , ...,  14.317672,  14.796275,\n",
      "        15.029884], dtype=float32), np.int64(8): array([-7.595953 , -7.101404 , -6.96275  , ...,  6.8406796,  7.0135164,\n",
      "        7.4805017], dtype=float32), np.int64(9): array([-4.074268 , -3.801346 , -3.7373464, ...,  3.7251546,  3.7947822,\n",
      "        4.1058774], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94049ea467545418f1d37a58440dce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-288.72623, -251.18277, -243.74817, ...,  246.75299,  264.31674,\n",
      "        328.78088], dtype=float32), np.int64(3): array([-176.78624, -166.6656 , -156.78073, ...,  174.71056,  177.87167,\n",
      "        182.39937], dtype=float32), np.int64(4): array([-99.25209 , -97.07921 , -92.95105 , ...,  91.16574 ,  94.126564,\n",
      "        94.944786], dtype=float32), np.int64(5): array([-54.929985, -51.6843  , -50.743706, ...,  52.3684  ,  54.32162 ,\n",
      "        56.154957], dtype=float32), np.int64(6): array([-27.281096, -26.798365, -26.552948, ...,  25.425812,  26.295454,\n",
      "        27.096546], dtype=float32), np.int64(7): array([-14.6117935, -13.536695 , -13.240603 , ...,  13.250528 ,\n",
      "        13.717231 ,  14.624173 ], dtype=float32), np.int64(8): array([-7.5894923, -7.095876 , -6.9061656, ...,  6.84876  ,  7.021058 ,\n",
      "        7.5134   ], dtype=float32), np.int64(9): array([-4.088404 , -3.816437 , -3.757285 , ...,  3.734187 ,  3.798826 ,\n",
      "        4.0970984], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5bc9253ade4af683e3aaa493fba6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-196.70172, -153.94421, -139.84595, ...,  141.78932,  154.55484,\n",
      "        157.39832], dtype=float32), np.int64(3): array([-98.546776, -82.49111 , -81.20995 , ...,  74.220924,  78.78026 ,\n",
      "        80.984474], dtype=float32), np.int64(4): array([-59.911884, -46.01485 , -45.02544 , ...,  50.858856,  52.777786,\n",
      "        60.17029 ], dtype=float32), np.int64(5): array([-35.781895, -30.53305 , -25.9118  , ...,  26.547308,  28.786488,\n",
      "        28.87988 ], dtype=float32), np.int64(6): array([-16.799593 , -15.157442 , -14.0464525, ...,  14.892853 ,\n",
      "        15.595773 ,  17.145672 ], dtype=float32), np.int64(7): array([-9.325859 , -7.8124566, -7.3611956, ...,  7.274867 ,  7.756201 ,\n",
      "        9.4278965], dtype=float32), np.int64(8): array([-5.2367806, -4.423679 , -4.2083635, ...,  4.195293 ,  4.408547 ,\n",
      "        5.2995944], dtype=float32), np.int64(9): array([-3.8839817, -3.093039 , -2.9087927, ...,  2.9530442,  3.136388 ,\n",
      "        3.926236 ], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-outdoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_backup2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
