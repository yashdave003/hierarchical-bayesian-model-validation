{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'approx1e5-coco-indoor-fourier' # + channel\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"coco-cropped-Indoor\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','coco')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'batch 1', 'batch 3', 'batch 2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch1-agriVision-RGB-cleaned\n",
      "batch2-agriVision-RGB-cleaned\n",
      "toy-agriVision-RGB-cleaned\n",
      "batch0-agriVision-RGB-cleaned\n",
      "full-agriVision-RGB-cleaned\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008052940675034493, 0.009260881776289667, 0.010650014042733115, 0.012247516149143082, 0.014084643571514543, 0.016197340107241723, 0.01862694112332798, 0.021420982291827175, 0.02463412963560125, 0.028329249080941435, 0.03257863644308265, 0.037465431909545044, 0.0430852466959768, 0.04954803370037331, 0.056980238755429305, 0.0655272745687437, 0.07535636575405526, 0.08665982061716354, 0.09965879370973807, 0.11460761276619877, 0.13179875468112856, 0.15156856788329784, 0.1743038530657925, 0.20044943102566135, 0.23051684567951053, 0.2650943725314371, 0.30485852841115263, 0.3505873076728255, 0.4031754038237493, 0.4636517143973116, 0.5331994715569083, 0.6131793922904445, 0.7051563011340111]\n"
     ]
    }
   ],
   "source": [
    "#Values obtained from plots in agriVisionFourierEDA.ipynb\n",
    "STARTING_VALUE = 0.008052940675034493\n",
    "ENDING_VALUE =0.6162627813472334\n",
    "MULT_FACTOR = 1.15\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"full-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")\n",
    "splits = getSplits(STARTING_VALUE,ENDING_VALUE, MULT_FACTOR)\n",
    "print(splits)\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [02:35<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00805294 0.00926088 0.01065001 0.01224752 0.01408464 0.01619734\n",
      " 0.01862694 0.02142098 0.02463413 0.02832925 0.03257864 0.03746543\n",
      " 0.04308525 0.04954803 0.05698024 0.06552727 0.07535637 0.08665982\n",
      " 0.09965879 0.11460761 0.13179875 0.15156857 0.17430385 0.20044943\n",
      " 0.23051685 0.26509437 0.30485853 0.35058731 0.4031754  0.46365171\n",
      " 0.53319947 0.61317939 0.7051563 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:12<00:00,  2.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[12.37854, 388.76587, -71.011154, -525.40607, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[22.619307, -0.6036585, 7.497328, 3.4352915, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[11.679032, -2.0639336, -2.0146694, 0.04964294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-18.864906, 2.5077233, 4.3224063, -0.9378565,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-4.914112, 0.8417485, -1.0893494, -1.8732375,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1     red                              (0.0, 0.0078125)   \n",
       "1     2     red  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3     red           (0.009765625, 0.010517900013934578)   \n",
       "3     4     red   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5     red  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [12.37854, 388.76587, -71.011154, -525.40607, ...  \n",
       "1                  3  [22.619307, -0.6036585, 7.497328, 3.4352915, -...  \n",
       "2                  3  [11.679032, -2.0639336, -2.0146694, 0.04964294...  \n",
       "3                  4  [-18.864906, 2.5077233, 4.3224063, -0.9378565,...  \n",
       "4                  6  [-4.914112, 0.8417485, -1.0893494, -1.8732375,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [02:33<00:00, 29.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00805294 0.00926088 0.01065001 0.01224752 0.01408464 0.01619734\n",
      " 0.01862694 0.02142098 0.02463413 0.02832925 0.03257864 0.03746543\n",
      " 0.04308525 0.04954803 0.05698024 0.06552727 0.07535637 0.08665982\n",
      " 0.09965879 0.11460761 0.13179875 0.15156857 0.17430385 0.20044943\n",
      " 0.23051685 0.26509437 0.30485853 0.35058731 0.4031754  0.46365171\n",
      " 0.53319947 0.61317939 0.7051563 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:08<00:00,  2.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[394.00897, -666.8051, -88.63963, -346.68665, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[26.316845, -5.964118, 4.277445, -0.005756075,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[3.8971589, -3.847043, -2.582688, -1.3424733, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-15.663755, 0.2849864, 1.8805587, 0.503372, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-6.3139224, 2.336338, -2.81662, -0.44819397, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1    blue                              (0.0, 0.0078125)   \n",
       "1     2    blue  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3    blue           (0.009765625, 0.010517900013934578)   \n",
       "3     4    blue   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5    blue  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [394.00897, -666.8051, -88.63963, -346.68665, ...  \n",
       "1                  3  [26.316845, -5.964118, 4.277445, -0.005756075,...  \n",
       "2                  3  [3.8971589, -3.847043, -2.582688, -1.3424733, ...  \n",
       "3                  4  [-15.663755, 0.2849864, 1.8805587, 0.503372, -...  \n",
       "4                  6  [-6.3139224, 2.336338, -2.81662, -0.44819397, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [03:02<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00805294 0.00926088 0.01065001 0.01224752 0.01408464 0.01619734\n",
      " 0.01862694 0.02142098 0.02463413 0.02832925 0.03257864 0.03746543\n",
      " 0.04308525 0.04954803 0.05698024 0.06552727 0.07535637 0.08665982\n",
      " 0.09965879 0.11460761 0.13179875 0.15156857 0.17430385 0.20044943\n",
      " 0.23051685 0.26509437 0.30485853 0.35058731 0.4031754  0.46365171\n",
      " 0.53319947 0.61317939 0.7051563 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:25<00:00,  2.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[166.38116, -696.27155, -199.10657, -450.9094,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[38.9928, -3.1236742, 4.1353054, 0.6367847, -2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[16.542994, -3.9311855, -2.0104222, -1.2822564...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-23.139984, 0.30325156, 2.0036407, 0.14319786...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-3.078197, 2.3377776, -1.9335574, -0.591884, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1   green                              (0.0, 0.0078125)   \n",
       "1     2   green  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3   green           (0.009765625, 0.010517900013934578)   \n",
       "3     4   green   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5   green  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [166.38116, -696.27155, -199.10657, -450.9094,...  \n",
       "1                  3  [38.9928, -3.1236742, 4.1353054, 0.6367847, -2...  \n",
       "2                  3  [16.542994, -3.9311855, -2.0104222, -1.2822564...  \n",
       "3                  4  [-23.139984, 0.30325156, 2.0036407, 0.14319786...  \n",
       "4                  6  [-3.078197, 2.3377776, -1.9335574, -0.591884, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [04:10<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00805294 0.00926088 0.01065001 0.01224752 0.01408464 0.01619734\n",
      " 0.01862694 0.02142098 0.02463413 0.02832925 0.03257864 0.03746543\n",
      " 0.04308525 0.04954803 0.05698024 0.06552727 0.07535637 0.08665982\n",
      " 0.09965879 0.11460761 0.13179875 0.15156857 0.17430385 0.20044943\n",
      " 0.23051685 0.26509437 0.30485853 0.35058731 0.4031754  0.46365171\n",
      " 0.53319947 0.61317939 0.7051563 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:22<00:00,  2.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[146.28271, -368.52505, -148.2057, -461.24997,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[32.649807, -2.6939397, 5.156004, 1.399945, -2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[13.645876, -3.3630786, -2.0767288, -0.8908882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[-21.007559, 0.9600556, 2.682488, -0.13888374,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-3.995517, 1.8902166, -1.7816994, -0.9584407,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1    gray                              (0.0, 0.0078125)   \n",
       "1     2    gray  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3    gray           (0.009765625, 0.010517900013934578)   \n",
       "3     4    gray   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5    gray  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [146.28271, -368.52505, -148.2057, -461.24997,...  \n",
       "1                  3  [32.649807, -2.6939397, 5.156004, 1.399945, -2...  \n",
       "2                  3  [13.645876, -3.3630786, -2.0767288, -0.8908882...  \n",
       "3                  4  [-21.007559, 0.9600556, 2.682488, -0.13888374,...  \n",
       "4                  6  [-3.995517, 1.8902166, -1.7816994, -0.9584407,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'approx1e5-agriVision-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"full-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [01:33<00:00, 48.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099611</td>\n",
       "      <td>L1</td>\n",
       "      <td>[12.37854, 388.76587, -71.011154, -525.40607, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>D</td>\n",
       "      <td>[-56.85054, 10.112775, -65.61645, 3.6756237, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>H</td>\n",
       "      <td>[426.77856, 36.807053, 2.2234993, 41.115826, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>V</td>\n",
       "      <td>[-458.58713, 52.57764, -45.266056, -4.2271876,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>3</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-192.24008, 1.2320688, -6.463406, 114.53845, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0     red      1   0.099611          L1   \n",
       "1     red      2   0.110679           D   \n",
       "2     red      2   0.110679           H   \n",
       "3     red      2   0.110679           V   \n",
       "4     red      3   0.124514           D   \n",
       "\n",
       "                                                data  \n",
       "0  [12.37854, 388.76587, -71.011154, -525.40607, ...  \n",
       "1  [-56.85054, 10.112775, -65.61645, 3.6756237, -...  \n",
       "2  [426.77856, 36.807053, 2.2234993, 41.115826, 3...  \n",
       "3  [-458.58713, 52.57764, -45.266056, -4.2271876,...  \n",
       "4  [-192.24008, 1.2320688, -6.463406, 114.53845, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1416/4500 [00:32<01:11, 43.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m TRANSFORM \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwavelet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m channel_wv \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_wavelet_basis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_opener\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnpz_opener\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m channel_wv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m channel_wv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SAVE_DF:\n",
      "File \u001b[0;32m~/Desktop/hierarchical-bayesian-model-validation/utilities/transform.py:63\u001b[0m, in \u001b[0;36mconvert_to_wavelet_basis\u001b[0;34m(folder_dir, color, basis, image_func, debug, image_opener)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image_opener \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[43mimage_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:,:,c]\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m         image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(file_list[k]))[:,:,c]\n",
      "File \u001b[0;32m~/Desktop/hierarchical-bayesian-model-validation/utilities/transform.py:23\u001b[0m, in \u001b[0;36mnpz_opener\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnpz_opener\u001b[39m(path):\n\u001b[1;32m     22\u001b[0m     npz_file \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path)\n\u001b[0;32m---> 23\u001b[0m     array_data \u001b[38;5;241m=\u001b[39m \u001b[43mnpz_file\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnpz_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array_data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/site-packages/numpy/lib/npyio.py:256\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/site-packages/numpy/lib/format.py:831\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    829\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[1;32m    830\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[0;32m--> 831\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    833\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/site-packages/numpy/lib/format.py:966\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 966\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m    968\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/zipfile.py:929\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 929\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/zipfile.py:1005\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_DEFLATED:\n\u001b[1;32m   1004\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m-> 1005\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39meof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:04<00:00, 365.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>L1</td>\n",
       "      <td>[0.20727114, -33.177452, -23.717556, -104.1030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-26.155533, 6.1044655, 21.780111, 24.545807, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>H</td>\n",
       "      <td>[-90.20362, -75.99399, 19.310474, -11.829856, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>V</td>\n",
       "      <td>[76.4653, 12.720116, -29.556787, -10.373663, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[53.602417, 3.668749, -16.509668, -0.57486, -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    blue      1   0.110679          L1   \n",
       "1    blue      2   0.124514           D   \n",
       "2    blue      2   0.124514           H   \n",
       "3    blue      2   0.124514           V   \n",
       "4    blue      3   0.142301           D   \n",
       "\n",
       "                                                data  \n",
       "0  [0.20727114, -33.177452, -23.717556, -104.1030...  \n",
       "1  [-26.155533, 6.1044655, 21.780111, 24.545807, ...  \n",
       "2  [-90.20362, -75.99399, 19.310474, -11.829856, ...  \n",
       "3  [76.4653, 12.720116, -29.556787, -10.373663, 0...  \n",
       "4  [53.602417, 3.668749, -16.509668, -0.57486, -1...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:04<00:00, 339.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gray</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>L1</td>\n",
       "      <td>[-6.1360106, 35.824085, -12.069928, -92.59161,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-20.23139, 5.5501356, 18.585161, 14.010576, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>H</td>\n",
       "      <td>[-54.903618, -72.86237, 8.412701, -6.4397974, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>V</td>\n",
       "      <td>[55.306328, 9.492829, -24.910969, -6.03024, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gray</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[36.00795, 3.1733897, -9.826171, -1.8638246, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    gray      1   0.110679          L1   \n",
       "1    gray      2   0.124514           D   \n",
       "2    gray      2   0.124514           H   \n",
       "3    gray      2   0.124514           V   \n",
       "4    gray      3   0.142301           D   \n",
       "\n",
       "                                                data  \n",
       "0  [-6.1360106, 35.824085, -12.069928, -92.59161,...  \n",
       "1  [-20.23139, 5.5501356, 18.585161, 14.010576, -...  \n",
       "2  [-54.903618, -72.86237, 8.412701, -6.4397974, ...  \n",
       "3  [55.306328, 9.492829, -24.910969, -6.03024, 0....  \n",
       "4  [36.00795, 3.1733897, -9.826171, -1.8638246, -...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HBMV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
