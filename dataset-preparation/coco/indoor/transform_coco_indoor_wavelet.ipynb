{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'coco-indoor-wavelet'\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"coco-indoor-cropped\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','coco')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000182611.jpg',\n",
       " '000000479126.jpg',\n",
       " '000000304396.jpg',\n",
       " '000000231339.jpg',\n",
       " '000000377393.jpg']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\n",
    "    filename\n",
    "    for filename in os.listdir(os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\"))\n",
    "    if not filename.startswith(\".\")\n",
    "]\n",
    "\n",
    "file_list = [\n",
    "    os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\", filename)\n",
    "    for filename in file_names\n",
    "]\n",
    "\n",
    "file_names[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco-indoor-cropped\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)  \n",
    "def jpg_opener(path):\n",
    "    \n",
    "    # Apply jitter\n",
    "    image = np.array(Image.open(path).convert('RGB'))\n",
    "    arr = image.astype(np.float64)\n",
    "    jitter = np.random.uniform(-0.5, 0.5, arr.shape)\n",
    "    arr += jitter\n",
    "    arr = arr - np.mean(arr)\n",
    "    arr = arr / np.std(arr)\n",
    "\n",
    "    \n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'coco-indoor-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7ce932e1fd47e0963d80b93cdacf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv_full = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=jpg_opener)\n",
    "channel_wv_full['data'] = channel_wv_full['data'].apply(lambda x: x.astype(np.float32))  # if needed, or skip if you jittered already\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = channel_wv_full[channel_wv_full['orientation'] == orientation_code].copy()\n",
    "\n",
    "    if SAVE_DF:\n",
    "        df_save_path = os.path.join(\n",
    "            ROOT_DIR,\n",
    "            \"transformed-data\",\n",
    "            f\"dataframes/{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"\n",
    "        )\n",
    "        pd.to_pickle(channel_wv, df_save_path)\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = {}\n",
    "    group_data_map_size = {}\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        filtered = channel_wv[channel_wv['layer'] == group]\n",
    "        if filtered.empty:\n",
    "            continue\n",
    "\n",
    "        data = filtered['data'].iloc[0]\n",
    "        sampled = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "\n",
    "        group_data_map[group] = sampled\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    freq_df_save_path = os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")\n",
    "    freq_df.to_csv(freq_df_save_path)\n",
    "\n",
    "    group_save_base = os.path.join(\n",
    "        ROOT_DIR,\n",
    "        \"transformed-data\",\n",
    "        f\"{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}\"\n",
    "    )\n",
    "    pd.to_pickle(group_data_map, f\"{group_save_base}.pickle\")\n",
    "    pd.to_pickle(group_data_map_size, f\"{group_save_base}-size.pickle\")\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n",
    "    gc.collect()\n",
    "\n",
    "del channel_wv_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8551e92b074b88b342563d85c3ae03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv_full = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=jpg_opener)\n",
    "channel_wv_full['data'] = channel_wv_full['data'].apply(lambda x: x.astype(np.float32))  # if needed, or skip if you jittered already\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = channel_wv_full[channel_wv_full['orientation'] == orientation_code].copy()\n",
    "\n",
    "    if SAVE_DF:\n",
    "        df_save_path = os.path.join(\n",
    "            ROOT_DIR,\n",
    "            \"transformed-data\",\n",
    "            f\"dataframes/{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"\n",
    "        )\n",
    "        pd.to_pickle(channel_wv, df_save_path)\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = {}\n",
    "    group_data_map_size = {}\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        filtered = channel_wv[channel_wv['layer'] == group]\n",
    "        if filtered.empty:\n",
    "            continue\n",
    "\n",
    "        data = filtered['data'].iloc[0]\n",
    "        sampled = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "\n",
    "        group_data_map[group] = sampled\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    freq_df_save_path = os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")\n",
    "    freq_df.to_csv(freq_df_save_path)\n",
    "\n",
    "    group_save_base = os.path.join(\n",
    "        ROOT_DIR,\n",
    "        \"transformed-data\",\n",
    "        f\"{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}\"\n",
    "    )\n",
    "    pd.to_pickle(group_data_map, f\"{group_save_base}.pickle\")\n",
    "    pd.to_pickle(group_data_map_size, f\"{group_save_base}-size.pickle\")\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n",
    "    gc.collect()\n",
    "\n",
    "del channel_wv_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35dfb0308104c86b1d495af6f57a87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-209.14372, -205.32481, -193.03166, ...,  232.02325,  234.02238,\n",
      "        242.3119 ], dtype=float32), np.int64(3): array([-165.42207, -156.1896 , -144.4635 , ...,  154.56436,  155.71172,\n",
      "        172.385  ], dtype=float32), np.int64(4): array([-111.452065, -107.44388 , -105.83926 , ...,   94.76358 ,\n",
      "         96.86688 ,   97.78854 ], dtype=float32), np.int64(5): array([-118.35611 ,  -65.309845,  -64.08341 , ...,   52.69262 ,\n",
      "         54.47514 ,   62.05505 ], dtype=float32), np.int64(6): array([-39.600914, -31.569727, -30.676874, ...,  26.044779,  29.158464,\n",
      "        43.438374], dtype=float32), np.int64(7): array([-23.702944, -17.20051 , -15.413932, ...,  14.36641 ,  16.539337,\n",
      "        25.011766], dtype=float32), np.int64(8): array([-12.406773 ,  -7.963714 ,  -7.288097 , ...,   7.1700425,\n",
      "         7.766318 ,  15.295829 ], dtype=float32), np.int64(9): array([-8.357713 , -4.2758417, -3.908142 , ...,  3.874356 ,  4.279595 ,\n",
      "        8.046624 ], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158451215eef4a45b6823ecba62b47d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-218.33394, -215.0107 , -212.84485, ...,  201.65616,  207.27568,\n",
      "        215.39304], dtype=float32), np.int64(3): array([-180.0537 , -158.98653, -158.16452, ...,  146.1452 ,  153.20169,\n",
      "        168.32726], dtype=float32), np.int64(4): array([-102.99306,  -91.85751,  -87.70578, ...,  100.92873,  104.5578 ,\n",
      "        106.58811], dtype=float32), np.int64(5): array([-129.50208 ,  -59.56608 ,  -58.537685, ...,   54.168423,\n",
      "         58.979385,   70.06082 ], dtype=float32), np.int64(6): array([-58.520107, -29.56545 , -27.445852, ...,  28.582026,  30.015251,\n",
      "        37.879807], dtype=float32), np.int64(7): array([-23.577524, -15.236538, -13.679176, ...,  13.424546,  14.596525,\n",
      "        21.304434], dtype=float32), np.int64(8): array([-15.727743,  -7.759533,  -7.125235, ...,   7.242122,   8.122948,\n",
      "        13.292139], dtype=float32), np.int64(9): array([-8.440437 , -4.201765 , -3.8236911, ...,  3.8760722,  4.2587643,\n",
      "        7.7269664], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0a7b497d7e464ead294b23f1a0bc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-156.43665, -118.24111, -113.1887 , ...,  142.31451,  144.11356,\n",
      "        155.46272], dtype=float32), np.int64(3): array([-99.79311 , -83.372055, -78.645485, ...,  84.35932 ,  86.46507 ,\n",
      "       106.43826 ], dtype=float32), np.int64(4): array([-62.71122 , -55.69331 , -52.485653, ...,  51.026512,  54.72633 ,\n",
      "        59.338837], dtype=float32), np.int64(5): array([-31.095133, -28.894058, -27.022274, ...,  27.416943,  28.295507,\n",
      "        33.379116], dtype=float32), np.int64(6): array([-19.000494 , -15.330213 , -13.88764  , ...,  13.9801235,\n",
      "        14.931963 ,  19.386864 ], dtype=float32), np.int64(7): array([-9.014478 , -7.0760965, -6.6735764, ...,  6.8456564,  7.6017165,\n",
      "       13.582847 ], dtype=float32), np.int64(8): array([-7.6805754, -4.3493037, -3.9175847, ...,  3.992868 ,  4.449641 ,\n",
      "        7.887759 ], dtype=float32), np.int64(9): array([-4.7546062, -2.537647 , -2.2908483, ...,  2.314405 ,  2.5833018,\n",
      "        5.0077767], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True,  image_opener=jpg_opener)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0799cf4b64bf41e0ae0a85ff316b4246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-206.10165, -192.92024, -186.0746 , ...,  200.80084,  215.35817,\n",
      "        217.34395], dtype=float32), np.int64(3): array([-148.06543, -148.06104, -135.29985, ...,  140.23227,  143.75026,\n",
      "        146.01054], dtype=float32), np.int64(4): array([-130.72935 ,  -91.3175  ,  -90.01253 , ...,   91.906975,\n",
      "         93.89082 ,  104.94781 ], dtype=float32), np.int64(5): array([-78.2476  , -72.741066, -64.75424 , ...,  51.633064,  51.7586  ,\n",
      "        52.63364 ], dtype=float32), np.int64(6): array([-43.232445, -31.849564, -29.387934, ...,  25.423326,  29.361069,\n",
      "        46.52628 ], dtype=float32), np.int64(7): array([-23.685347 , -15.736735 , -14.66332  , ...,  13.967749 ,\n",
      "        15.7094555,  23.056986 ], dtype=float32), np.int64(8): array([-11.189963 ,  -7.9330096,  -7.299925 , ...,   7.1044416,\n",
      "         7.8651967,  15.002885 ], dtype=float32), np.int64(9): array([-8.355759 , -4.2710223, -3.923322 , ...,  3.9044545,  4.317322 ,\n",
      "        8.037834 ], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd42047f3fa403e91a88a5795eadf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-243.15321, -216.73358, -196.74812, ...,  191.52583,  217.33353,\n",
      "        222.44739], dtype=float32), np.int64(3): array([-151.15465, -138.45146, -133.64568, ...,  128.03108,  129.03917,\n",
      "        137.53003], dtype=float32), np.int64(4): array([-102.97861 ,  -96.22225 ,  -92.56291 , ...,   96.078476,\n",
      "        101.126015,  101.367424], dtype=float32), np.int64(5): array([-129.46701 ,  -56.241383,  -53.217384, ...,   61.65741 ,\n",
      "         61.83803 ,   68.97361 ], dtype=float32), np.int64(6): array([-58.52675 , -29.792486, -26.348934, ...,  28.695293,  30.78247 ,\n",
      "        35.11588 ], dtype=float32), np.int64(7): array([-23.589542, -16.829092, -14.110415, ...,  13.347393,  14.501694,\n",
      "        18.151808], dtype=float32), np.int64(8): array([-15.755593 ,  -7.9046116,  -7.1506686, ...,   7.339482 ,\n",
      "         8.073767 ,  13.31218  ], dtype=float32), np.int64(9): array([-8.604647 , -4.245255 , -3.8652053, ...,  3.891601 ,  4.3025064,\n",
      "        7.495508 ], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a85298710d4db08a7fa6e49f32da95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-147.31705, -145.00305, -113.18277, ...,  134.92162,  136.119  ,\n",
      "        139.80762], dtype=float32), np.int64(3): array([-81.5915  , -78.98904 , -78.333015, ...,  74.32497 ,  79.13725 ,\n",
      "        97.02891 ], dtype=float32), np.int64(4): array([-53.876114, -49.39669 , -49.212963, ...,  48.89883 ,  51.026356,\n",
      "        58.1894  ], dtype=float32), np.int64(5): array([-31.268505, -24.796583, -24.455898, ...,  26.798277,  27.416666,\n",
      "        29.794231], dtype=float32), np.int64(6): array([-19.375076, -16.42993 , -14.185225, ...,  13.978925,  14.941851,\n",
      "        15.991492], dtype=float32), np.int64(7): array([-9.71762  , -7.09104  , -6.729268 , ...,  6.9316406,  7.7380195,\n",
      "       10.644024 ], dtype=float32), np.int64(8): array([-7.6706586, -4.385363 , -3.9817915, ...,  4.0233674,  4.543739 ,\n",
      "        7.714522 ], dtype=float32), np.int64(9): array([-4.6744328, -2.5577075, -2.309638 , ...,  2.3304358,  2.594105 ,\n",
      "        5.0701323], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True,  image_opener=jpg_opener)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_backup2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
