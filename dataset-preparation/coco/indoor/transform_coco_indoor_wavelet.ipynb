{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'coco-indoor-wavelet'\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"coco-indoor-cropped-normalized\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','coco')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indoor_000000000139.npz',\n",
       " 'indoor_000000000632.npz',\n",
       " 'indoor_000000000776.npz',\n",
       " 'indoor_000000000802.npz',\n",
       " 'indoor_000000001296.npz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\n",
    "    filename\n",
    "    for filename in os.listdir(os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\"))\n",
    "    if not filename.startswith(\".\")\n",
    "]\n",
    "\n",
    "file_list = [\n",
    "    os.path.join(data_dir, f\"{RAW_DATA_SUFFIX}\", filename)\n",
    "    for filename in file_names\n",
    "]\n",
    "\n",
    "file_names[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco-indoor-cropped-normalized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def npz_opener_pickle(path):\n",
    "    # Load the .npz file\n",
    "    with np.load(path) as data:\n",
    "        arr = data['image']  # Default key if saved without naming the array\n",
    "\n",
    "    arr = arr.astype(np.float32)\n",
    "    \n",
    "    # Apply jitter\n",
    "    jitter = np.random.uniform(-0.5, 0.5, arr.shape)\n",
    "    arr += jitter\n",
    "    arr = np.clip(arr, 0, 255)\n",
    "    \n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'coco-indoor-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18af1483cc348d8aa9a99187456377d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv_full = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "channel_wv_full['data'] = channel_wv_full['data'].apply(lambda x: x.astype(np.float32))  # if needed, or skip if you jittered already\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = channel_wv_full[channel_wv_full['orientation'] == orientation_code].copy()\n",
    "\n",
    "    if SAVE_DF:\n",
    "        df_save_path = os.path.join(\n",
    "            ROOT_DIR,\n",
    "            \"transformed-data\",\n",
    "            f\"dataframes/{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"\n",
    "        )\n",
    "        pd.to_pickle(channel_wv, df_save_path)\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = {}\n",
    "    group_data_map_size = {}\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        filtered = channel_wv[channel_wv['layer'] == group]\n",
    "        if filtered.empty:\n",
    "            continue\n",
    "\n",
    "        data = filtered['data'].iloc[0]\n",
    "        sampled = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "\n",
    "        group_data_map[group] = sampled\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    freq_df_save_path = os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")\n",
    "    freq_df.to_csv(freq_df_save_path)\n",
    "\n",
    "    group_save_base = os.path.join(\n",
    "        ROOT_DIR,\n",
    "        \"transformed-data\",\n",
    "        f\"{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}\"\n",
    "    )\n",
    "    pd.to_pickle(group_data_map, f\"{group_save_base}.pickle\")\n",
    "    pd.to_pickle(group_data_map_size, f\"{group_save_base}-size.pickle\")\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n",
    "    gc.collect()\n",
    "\n",
    "del channel_wv_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d829084b28b344fcb87ab2590357bcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv_full = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "channel_wv_full['data'] = channel_wv_full['data'].apply(lambda x: x.astype(np.float32))  # if needed, or skip if you jittered already\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = channel_wv_full[channel_wv_full['orientation'] == orientation_code].copy()\n",
    "\n",
    "    if SAVE_DF:\n",
    "        df_save_path = os.path.join(\n",
    "            ROOT_DIR,\n",
    "            \"transformed-data\",\n",
    "            f\"dataframes/{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"\n",
    "        )\n",
    "        pd.to_pickle(channel_wv, df_save_path)\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = {}\n",
    "    group_data_map_size = {}\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        filtered = channel_wv[channel_wv['layer'] == group]\n",
    "        if filtered.empty:\n",
    "            continue\n",
    "\n",
    "        data = filtered['data'].iloc[0]\n",
    "        sampled = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "\n",
    "        group_data_map[group] = sampled\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    freq_df_save_path = os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")\n",
    "    freq_df.to_csv(freq_df_save_path)\n",
    "\n",
    "    group_save_base = os.path.join(\n",
    "        ROOT_DIR,\n",
    "        \"transformed-data\",\n",
    "        f\"{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}\"\n",
    "    )\n",
    "    pd.to_pickle(group_data_map, f\"{group_save_base}.pickle\")\n",
    "    pd.to_pickle(group_data_map_size, f\"{group_save_base}-size.pickle\")\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n",
    "    gc.collect()\n",
    "\n",
    "del channel_wv_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ae4ed6caf44122af7242989db5672c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-251.82898, -228.83157, -226.35397, ...,  227.44359,  230.37117,\n",
      "        319.68768], dtype=float32), np.int64(3): array([-159.69775, -150.33289, -144.18079, ...,  162.3812 ,  167.34256,\n",
      "        200.5624 ], dtype=float32), np.int64(4): array([-101.61334,  -96.66931,  -93.65338, ...,   94.35974,   94.73074,\n",
      "        100.94613], dtype=float32), np.int64(5): array([-49.256405, -48.917606, -48.912422, ...,  46.403366,  46.682564,\n",
      "        46.89617 ], dtype=float32), np.int64(6): array([-26.573685, -25.482971, -24.83669 , ...,  24.831057,  25.2959  ,\n",
      "        26.291546], dtype=float32), np.int64(7): array([-13.683502, -12.996016, -12.564633, ...,  12.405188,  12.694693,\n",
      "        13.530101], dtype=float32), np.int64(8): array([-7.227001 , -6.669417 , -6.493014 , ...,  6.4137053,  6.571144 ,\n",
      "        7.1398487], dtype=float32), np.int64(9): array([-3.8906963, -3.616777 , -3.533586 , ...,  3.526249 ,  3.6064172,\n",
      "        3.896512 ], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1124302e2841bd905ca399bb2ff773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-287.62152, -262.60492, -256.65277, ...,  277.90027,  288.77338,\n",
      "        303.28226], dtype=float32), np.int64(3): array([-154.17052, -153.50735, -150.00531, ...,  145.39716,  154.25925,\n",
      "        155.35533], dtype=float32), np.int64(4): array([-95.79519 , -93.29342 , -88.4875  , ...,  89.495415,  91.6702  ,\n",
      "        92.66308 ], dtype=float32), np.int64(5): array([-51.94559 , -49.654755, -49.446083, ...,  47.89184 ,  49.26031 ,\n",
      "        49.470646], dtype=float32), np.int64(6): array([-27.17032 , -25.409565, -24.804907, ...,  24.18994 ,  24.997122,\n",
      "        26.313366], dtype=float32), np.int64(7): array([-13.2053795, -12.598123 , -12.19962  , ...,  12.404572 ,\n",
      "        12.721636 ,  13.503652 ], dtype=float32), np.int64(8): array([-7.3426266, -6.565537 , -6.4021273, ...,  6.4031553,  6.578902 ,\n",
      "        7.1682835], dtype=float32), np.int64(9): array([-3.8558877, -3.5851855, -3.5078993, ...,  3.4832351,  3.5825667,\n",
      "        3.8980029], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53ff56139684fc0a6a78826333758ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-184.46024, -158.34308, -140.92801, ...,  138.97397,  146.44958,\n",
      "        149.96622], dtype=float32), np.int64(3): array([-112.76155 , -101.693726,  -88.605385, ...,   81.93246 ,\n",
      "         88.39295 ,   92.710724], dtype=float32), np.int64(4): array([-53.570312, -52.00907 , -49.8506  , ...,  44.713432,  49.031773,\n",
      "        49.129326], dtype=float32), np.int64(5): array([-28.592522, -26.437925, -26.01212 , ...,  27.82864 ,  29.973656,\n",
      "        36.32309 ], dtype=float32), np.int64(6): array([-15.536121, -14.815262, -13.300306, ...,  12.785673,  13.723051,\n",
      "        15.125103], dtype=float32), np.int64(7): array([-8.513971 , -6.9113674, -6.5949607, ...,  6.317406 ,  6.8700237,\n",
      "        8.172414 ], dtype=float32), np.int64(8): array([-5.566472 , -4.0937486, -3.8067608, ...,  3.7603827,  3.9599862,\n",
      "        5.5112076], dtype=float32), np.int64(9): array([-3.7129433, -2.6747708, -2.4762883, ...,  2.5015645,  2.6860256,\n",
      "        3.6789432], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f4806a2e8044189290775061f4808f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-304.87573, -282.91327, -268.65845, ...,  286.0272 ,  290.2645 ,\n",
      "        378.17932], dtype=float32), np.int64(3): array([-204.46742, -179.72356, -175.6449 , ...,  194.51266,  203.67924,\n",
      "        235.22299], dtype=float32), np.int64(4): array([-120.30176 , -111.84119 , -106.71191 , ...,  116.12464 ,\n",
      "        117.05783 ,  119.482956], dtype=float32), np.int64(5): array([-58.908924, -58.043015, -57.81529 , ...,  53.71816 ,  53.75927 ,\n",
      "        55.994316], dtype=float32), np.int64(6): array([-30.558205, -30.059416, -29.381016, ...,  29.107008,  29.729864,\n",
      "        31.23067 ], dtype=float32), np.int64(7): array([-15.604708, -14.68929 , -14.320933, ...,  14.355756,  14.744203,\n",
      "        15.265714], dtype=float32), np.int64(8): array([-8.098208 , -7.5935025, -7.4320602, ...,  7.3458686,  7.583283 ,\n",
      "        8.257872 ], dtype=float32), np.int64(9): array([-4.3100977, -4.019562 , -3.935918 , ...,  3.9213746,  4.0075493,\n",
      "        4.4201946], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958c3bf665cd4eb7ac67dcc6573c5b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-313.286  , -279.3526 , -274.76392, ...,  281.72278,  315.69327,\n",
      "        323.6844 ], dtype=float32), np.int64(3): array([-215.61388, -187.73459, -177.39432, ...,  170.73833,  177.18047,\n",
      "        177.59546], dtype=float32), np.int64(4): array([-113.5234 , -113.09408, -111.69312, ...,  108.30007,  112.46825,\n",
      "        116.31825], dtype=float32), np.int64(5): array([-60.599964, -60.264446, -60.160618, ...,  56.843315,  58.423985,\n",
      "        58.523373], dtype=float32), np.int64(6): array([-31.809727, -29.70343 , -29.257376, ...,  29.002195,  29.278301,\n",
      "        31.501616], dtype=float32), np.int64(7): array([-15.769814, -15.026432, -14.585868, ...,  14.237423,  14.676295,\n",
      "        15.78852 ], dtype=float32), np.int64(8): array([-8.061981 , -7.564883 , -7.3301725, ...,  7.4161124,  7.6157727,\n",
      "        8.154937 ], dtype=float32), np.int64(9): array([-4.4229026, -4.0197654, -3.935263 , ...,  3.897871 ,  3.9935   ,\n",
      "        4.3497276], dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d737a3c9f9d45feba3bfbbf498d64e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing D\n",
      "{np.int64(2): array([-194.80089, -170.71121, -153.52812, ...,  165.51677,  167.30078,\n",
      "        207.76955], dtype=float32), np.int64(3): array([-138.83203, -105.87509, -102.42499, ...,   85.75875,   87.54909,\n",
      "         91.08873], dtype=float32), np.int64(4): array([-62.78834 , -61.81336 , -60.459106, ...,  48.492683,  51.83682 ,\n",
      "        58.99973 ], dtype=float32), np.int64(5): array([-32.930264, -30.863234, -28.471476, ...,  28.52134 ,  31.315874,\n",
      "        31.394108], dtype=float32), np.int64(6): array([-17.703634, -15.017699, -14.841733, ...,  14.846697,  15.507093,\n",
      "        16.645191], dtype=float32), np.int64(7): array([-9.670558 , -7.5887337, -7.184431 , ...,  7.109892 ,  7.694028 ,\n",
      "        9.369997 ], dtype=float32), np.int64(8): array([-5.656046 , -4.532997 , -4.215484 , ...,  4.1565433,  4.4757423,\n",
      "        6.00015  ], dtype=float32), np.int64(9): array([-4.016829 , -2.8986893, -2.6669817, ...,  2.6846423,  2.8904102,\n",
      "        4.0925107], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical', 'diagonal']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else ('V' if orientation_label == 'vertical' else 'D')\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_backup2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
