{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'coco-indoor-wavelet'\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"coco-cropped-Indoor\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'sandbox', 'raw-data','coco')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000001296.jpg',\n",
       " '000000000139.jpg',\n",
       " '000000000632.jpg',\n",
       " '000000000802.jpg',\n",
       " '000000001993.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\n",
    "    filename\n",
    "    for filename in os.listdir(os.path.join(data_dir, f\"toy-{RAW_DATA_SUFFIX}\"))\n",
    "    if not filename.startswith(\".\")\n",
    "]\n",
    "\n",
    "file_list = [\n",
    "    os.path.join(data_dir, f\"toy-{RAW_DATA_SUFFIX}\", filename)\n",
    "    for filename in file_names\n",
    "]\n",
    "\n",
    "file_names[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toy-coco-cropped-Indoor\n",
      "._toy-coco-cropped-Indoor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def npz_opener_pickle(path):\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    arr = np.array(image).astype(np.float32)\n",
    "    jitter = np.random.uniform(-0.5, 0.5, arr.shape)\n",
    "    arr += jitter\n",
    "    arr = np.clip(arr, 0, 255)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'coco-indoor-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"sandbox\", \"raw-data\", \"coco\", f\"toy-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"coco\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de70427f5edc4a9cbc4687de3dfd1697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv_full = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "channel_wv_full['data'] = channel_wv_full['data'].apply(lambda x: x.astype(np.float32))  # if needed, or skip if you jittered already\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = channel_wv_full[channel_wv_full['orientation'] == orientation_code].copy()\n",
    "\n",
    "    if SAVE_DF:\n",
    "        df_save_path = os.path.join(\n",
    "            ROOT_DIR,\n",
    "            \"transformed-data\",\n",
    "            f\"dataframes/{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"\n",
    "        )\n",
    "        pd.to_pickle(channel_wv, df_save_path)\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = {}\n",
    "    group_data_map_size = {}\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        filtered = channel_wv[channel_wv['layer'] == group]\n",
    "        if filtered.empty:\n",
    "            continue\n",
    "\n",
    "        data = filtered['data'].iloc[0]\n",
    "        sampled = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "\n",
    "        group_data_map[group] = sampled\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    freq_df_save_path = os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")\n",
    "    freq_df.to_csv(freq_df_save_path)\n",
    "\n",
    "    group_save_base = os.path.join(\n",
    "        ROOT_DIR,\n",
    "        \"transformed-data\",\n",
    "        f\"{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}\"\n",
    "    )\n",
    "    pd.to_pickle(group_data_map, f\"{group_save_base}.pickle\")\n",
    "    pd.to_pickle(group_data_map_size, f\"{group_save_base}-size.pickle\")\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n",
    "    gc.collect()\n",
    "\n",
    "del channel_wv_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d50a168d05f4235b2051d463e31445b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv_full = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "channel_wv_full['data'] = channel_wv_full['data'].apply(lambda x: x.astype(np.float32))  # if needed, or skip if you jittered already\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = channel_wv_full[channel_wv_full['orientation'] == orientation_code].copy()\n",
    "\n",
    "    if SAVE_DF:\n",
    "        df_save_path = os.path.join(\n",
    "            ROOT_DIR,\n",
    "            \"transformed-data\",\n",
    "            f\"dataframes/{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"\n",
    "        )\n",
    "        pd.to_pickle(channel_wv, df_save_path)\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = {}\n",
    "    group_data_map_size = {}\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        filtered = channel_wv[channel_wv['layer'] == group]\n",
    "        if filtered.empty:\n",
    "            continue\n",
    "\n",
    "        data = filtered['data'].iloc[0]\n",
    "        sampled = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "\n",
    "        group_data_map[group] = sampled\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    freq_df_save_path = os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")\n",
    "    freq_df.to_csv(freq_df_save_path)\n",
    "\n",
    "    group_save_base = os.path.join(\n",
    "        ROOT_DIR,\n",
    "        \"transformed-data\",\n",
    "        f\"{'' if BATCH_NUM is None else f'batch{BATCH_NUM}'}{FINAL_DATA_NAME_ORIENTED}-{channel}\"\n",
    "    )\n",
    "    pd.to_pickle(group_data_map, f\"{group_save_base}.pickle\")\n",
    "    pd.to_pickle(group_data_map_size, f\"{group_save_base}-size.pickle\")\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n",
    "    gc.collect()\n",
    "\n",
    "del channel_wv_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7258bbcfe64a454291db3a4ec44264a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-18656.088, -13917.058, -13473.333, ...,  18541.072,  18542.385,\n",
      "        19473.973], shape=(1604,), dtype=float32), np.int64(3): array([-11489.305, -10831.345, -10765.515, ...,  10922.157,  11048.591,\n",
      "        11585.475], shape=(6416,), dtype=float32), np.int64(4): array([-6686.0264, -6631.2876, -6623.013 , ...,  6230.6436,  7057.608 ,\n",
      "        7155.0044], shape=(25664,), dtype=float32), np.int64(5): array([-3415.0684, -3306.3215, -3272.6975, ...,  3212.463 ,  3222.9172,\n",
      "        3244.3333], shape=(100000,), dtype=float32), np.int64(6): array([-1752.1951, -1712.0693, -1647.8092, ...,  1586.6711,  1642.568 ,\n",
      "        1718.9742], shape=(100000,), dtype=float32), np.int64(7): array([-904.8463 , -814.9612 , -786.8406 , ...,  777.67   ,  811.8638 ,\n",
      "        889.41144], shape=(100000,), dtype=float32), np.int64(8): array([-468.88113, -414.365  , -398.99982, ...,  392.37805,  408.50107,\n",
      "        484.63342], shape=(100000,), dtype=float32), np.int64(9): array([-250.79726, -215.30281, -207.15152, ...,  205.76233,  215.01956,\n",
      "        254.6885 ], shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2df2961e20d49d98b8a8b67a1ec4dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-18437.377, -15845.146, -15433.076, ...,  15697.648,  16373.958,\n",
      "        19876.428], shape=(1604,), dtype=float32), np.int64(3): array([-12940.436, -12440.522, -11031.544, ...,   9259.625,   9426.131,\n",
      "         9618.772], shape=(6416,), dtype=float32), np.int64(4): array([-6277.2563, -5966.409 , -5947.389 , ...,  5699.646 ,  6210.4897,\n",
      "        6453.772 ], shape=(25664,), dtype=float32), np.int64(5): array([-3379.3005, -3200.5396, -3187.8923, ...,  3353.6882,  3424.1716,\n",
      "        3624.729 ], shape=(100000,), dtype=float32), np.int64(6): array([-1765.1881, -1690.8456, -1643.9956, ...,  1623.593 ,  1659.1816,\n",
      "        1802.0055], shape=(100000,), dtype=float32), np.int64(7): array([-896.9412 , -812.8974 , -785.7233 , ...,  784.42816,  808.7185 ,\n",
      "        917.4385 ], shape=(100000,), dtype=float32), np.int64(8): array([-461.11572, -411.02817, -393.9123 , ...,  396.0226 ,  411.9547 ,\n",
      "        472.73605], shape=(100000,), dtype=float32), np.int64(9): array([-252.1649 , -212.74664, -203.80486, ...,  203.55576,  211.20674,\n",
      "        251.95734], shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c9c545516e42588629db7b58824063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing H\n",
      "{np.int64(2): array([-18046.17 , -15119.611, -13620.7  , ...,  17981.717,  18238.512,\n",
      "        20482.15 ], shape=(1604,), dtype=float32), np.int64(3): array([-10891.25 ,  -9433.87 ,  -9411.007, ...,   9435.814,   9520.505,\n",
      "        11995.401], shape=(6416,), dtype=float32), np.int64(4): array([-6685.6235, -6635.6084, -6432.6646, ...,  6132.4697,  6484.425 ,\n",
      "        6842.939 ], shape=(25664,), dtype=float32), np.int64(5): array([-3341.3281, -3243.7388, -3209.5679, ...,  3124.346 ,  3183.7437,\n",
      "        3244.035 ], shape=(100000,), dtype=float32), np.int64(6): array([-1725.3325, -1684.8146, -1659.3945, ...,  1561.1526,  1632.7098,\n",
      "        1700.8501], shape=(100000,), dtype=float32), np.int64(7): array([-905.59955, -805.15454, -782.6099 , ...,  796.96844,  815.0164 ,\n",
      "        868.9331 ], shape=(100000,), dtype=float32), np.int64(8): array([-468.27838, -414.7426 , -400.20334, ...,  394.37344,  408.1205 ,\n",
      "        465.61118], shape=(100000,), dtype=float32), np.int64(9): array([-251.02061, -215.65083, -208.06914, ...,  206.6633 ,  215.87486,\n",
      "        249.84715], shape=(100000,), dtype=float32)}\n",
      "9 layers being used\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1a8fbe5f6d41d3a37791e68646960f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing V\n",
      "{np.int64(2): array([-20034.88 , -18218.379, -14094.329, ...,  14483.382,  17928.19 ,\n",
      "        20527.309], shape=(1604,), dtype=float32), np.int64(3): array([-10809.311, -10508.462, -10174.428, ...,   9099.71 ,   9140.332,\n",
      "         9511.079], shape=(6416,), dtype=float32), np.int64(4): array([-5983.4233, -5944.8677, -5802.57  , ...,  5222.2793,  6134.987 ,\n",
      "        6481.861 ], shape=(25664,), dtype=float32), np.int64(5): array([-3351.2898, -3324.8513, -3287.3142, ...,  2848.8083,  2931.7178,\n",
      "        2964.6187], shape=(100000,), dtype=float32), np.int64(6): array([-1739.8655, -1615.1284, -1606.9707, ...,  1571.4893,  1660.2672,\n",
      "        1747.2065], shape=(100000,), dtype=float32), np.int64(7): array([-895.9562 , -804.9418 , -779.0762 , ...,  771.69415,  800.4326 ,\n",
      "        971.1642 ], shape=(100000,), dtype=float32), np.int64(8): array([-457.42673, -411.60074, -395.37692, ...,  395.6803 ,  408.4005 ,\n",
      "        480.03125], shape=(100000,), dtype=float32), np.int64(9): array([-251.59521, -213.18108, -204.19783, ...,  204.19722,  213.15337,\n",
      "        253.44571], shape=(100000,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "for orientation_label in ['horizontal', 'vertical']:\n",
    "    FINAL_DATA_NAME_ORIENTED = f\"{FINAL_DATA_NAME}-{orientation_label}\"\n",
    "    orientation_code = 'H' if orientation_label == 'horizontal' else 'V'\n",
    "\n",
    "    channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug=True, image_opener=npz_opener_pickle)\n",
    "    channel_wv['data'] = channel_wv['data'].apply(lambda x: x.astype(np.float32))\n",
    "\n",
    "    if SAVE_DF:\n",
    "        if BATCH_NUM is None:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "        else:\n",
    "            pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-df.pickle\"))\n",
    "\n",
    "    min_group, max_group = 2, max(channel_wv['layer'])\n",
    "    group_data_map = dict()\n",
    "    group_data_map_size = dict()\n",
    "\n",
    "    for group in np.arange(min_group, max_group + 1):\n",
    "        data = channel_wv[(channel_wv['orientation'] == orientation_code) & (channel_wv['layer'] == group)]['data'].iloc[0]\n",
    "        group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        group_data_map_size[group] = data.size\n",
    "\n",
    "        freq_df.loc[f\"{DATASET}-indoor\", TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group) & (channel_wv['orientation'] == orientation_code)]['frequency'].iloc[0]\n",
    "\n",
    "    print(f\"printing {orientation_code}\")\n",
    "    freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\"))\n",
    "\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}.pickle\"))\n",
    "        pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME_ORIENTED}-{channel}-size.pickle\"))\n",
    "\n",
    "    print(group_data_map)\n",
    "\n",
    "    del channel_wv\n",
    "    del group_data_map\n",
    "    del group_data_map_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
