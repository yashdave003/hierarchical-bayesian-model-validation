{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import git\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial import distance\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "ROOT_DIR =  Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "save_path_with_hull = Path(os.path.join(ROOT_DIR, 'publication', 'paper', 'CSVs', 'final_results_with_hull.pickle'))\n",
    "save_path_without_hull = Path(os.path.join(ROOT_DIR, 'publication', 'paper', 'CSVs', 'final_results.csv'))\n",
    "plots_path = os.path.join(ROOT_DIR, \"publication\", \"paper\", \"draft_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_prior(r, eta, scale=1):\n",
    "    beta = (eta+1.5)/r\n",
    "    var_prior = scale * scipy.special.gamma(beta + 1/r)/scipy.special.gamma(beta)\n",
    "    return var_prior\n",
    "\n",
    "def kurtosis_prior(r, eta, scale=1, fisher=True):\n",
    "    beta = (eta+1.5)/r\n",
    "    kurtosis = scale*3*scipy.special.gamma(beta + 2/r)*scipy.special.gamma(beta)/scipy.special.gamma(beta+1/r)**2 # DOUBLE CHECK\n",
    "    if fisher:\n",
    "        return kurtosis - 3\n",
    "    else:\n",
    "        return kurtosis \n",
    "\n",
    "def find_master_dfs(root_dir: str) -> List[str]:\n",
    "    root_path = Path(root_dir)\n",
    "    if not root_path.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {root_dir}\")\n",
    "\n",
    "    master_df_paths = []\n",
    "    for current_dir, _, files in os.walk(root_path):\n",
    "        if 'master_df.csv' in files:\n",
    "            master_df_path = Path(os.path.join(current_dir, 'master_df.csv'))\n",
    "            master_df_paths.append(str(master_df_path.absolute()))\n",
    "    return master_df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hull(master_df, rEtaKsstats_dict, GROUP='group', debug=False):\n",
    "\n",
    "    master_df_copy = master_df.copy()\n",
    "    master_df_copy = master_df.set_index(GROUP)\n",
    "    groups = master_df_copy.index\n",
    "    master_df_copy[\"hull\"] = \"\"\n",
    "\n",
    "    for group in groups:\n",
    "        if master_df_copy.loc[group, \"total_samples\"] < 10:\n",
    "            master_df_copy.loc[group, \"hull\"] = np.nan\n",
    "           \n",
    "        else:\n",
    "            drop_keys =list(rEtaKsstats_dict[group].keys())[-3:]\n",
    "            if debug:\n",
    "                print(drop_keys)\n",
    "            pre_optimization = pd.DataFrame(rEtaKsstats_dict[group]).drop(drop_keys, axis = 1 )\n",
    "            optimization = pd.DataFrame(rEtaKsstats_dict[group])[drop_keys]\n",
    "            optimization = optimization.rename(columns = {\"r_optimize\": \"r\", \"eta_optimize\": \"eta\", drop_keys[-1]: \"ksstat\"})\n",
    "            optimization = optimization.dropna()\n",
    "            full_df = pre_optimization.merge(optimization, on=[\"r\", \"eta\"], how=\"outer\")\n",
    "            full_df = full_df.set_index([\"r\", \"eta\"])\n",
    "            full_df[\"ksstat\"] = full_df.min(axis=1)\n",
    "            full_df = full_df.reset_index()\n",
    "            full_df = full_df[[\"r\", \"eta\", \"ksstat\"]]\n",
    "            full_df[\"1/beta\"] = full_df[\"r\"]/(full_df[\"eta\"] + 1.5)\n",
    "            full_df[\"log_beta\"] = np.log10((full_df[\"eta\"] + 1.5) / full_df[\"r\"])\n",
    "            MULT = 1.2\n",
    "            significant_ksstat = master_df_copy.loc[group, \"kstest_stat_cutoff_0.05\"]\n",
    "            #cutoff = max(min(full_df[\"ksstat\"]) * MULT, 0.01)\n",
    "            cutoff = max(significant_ksstat, 0.01)\n",
    "            filtered_df = full_df[full_df[\"ksstat\"] < cutoff]\n",
    "            points = np.column_stack((filtered_df[\"r\"], filtered_df[\"1/beta\"])) + stats.norm.rvs(size=(len(filtered_df), 2)) * 0.001  # Adding small noise for convex hull computation\n",
    "            #points = np.column_stack((np.log10(filtered_df[\"r\"]), filtered_df[\"log_beta\"])) + stats.norm.rvs(size=(len(filtered_df), 2)) * 0.001  # Adding small noise for convex hull computation\n",
    "            if len(points) < 3:\n",
    "                hull=np.nan\n",
    "                master_df_copy.loc[group, \"intersect_roi\"] = -1\n",
    "            else:\n",
    "                hull = ConvexHull(points)\n",
    "\n",
    "                if np.any(filtered_df[\"eta\"] > 0) and np.any(filtered_df[\"eta\"] < 0):\n",
    "                    intersect_roi = 1\n",
    "                else:\n",
    "                    intersect_roi = 0\n",
    "                master_df_copy.loc[group, \"intersect_roi\"] = intersect_roi\n",
    "            master_df_copy.loc[group, \"hull\"] = hull\n",
    "\n",
    "    return master_df_copy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rEtaKsstats_dict(master_df_original, rEtaKsstats_dict, GROUP='group', debug=False):\n",
    "\n",
    "    master_df = master_df_original.copy()\n",
    "    master_df = master_df_original.set_index(GROUP)\n",
    "    groups = master_df.index\n",
    "    master_df[\"hull\"] = \"\"\n",
    "\n",
    "    for group in groups:\n",
    "        if master_df.loc[group, \"total_samples\"] < 10:\n",
    "            master_df.loc[group, \"hull\"] = np.nan\n",
    "           \n",
    "        else:\n",
    "            drop_keys =list(rEtaKsstats_dict[group].keys())[-3:]\n",
    "            if debug:\n",
    "                print(drop_keys)\n",
    "            pre_optimization = pd.DataFrame(rEtaKsstats_dict[group]).drop(drop_keys, axis = 1 )\n",
    "            optimization = pd.DataFrame(rEtaKsstats_dict[group])[drop_keys]\n",
    "            optimization = optimization.rename(columns = {\"r_optimize\": \"r\", \"eta_optimize\": \"eta\", drop_keys[-1]: \"ksstat\"})\n",
    "            optimization = optimization.dropna()\n",
    "\n",
    "            full_df = pre_optimization.merge(optimization, on=[\"r\", \"eta\"], how=\"outer\")\n",
    "            full_df = full_df.set_index([\"r\", \"eta\"])\n",
    "            full_df[\"ksstat\"] = full_df.min(axis=1)\n",
    "            full_df = full_df.reset_index()\n",
    "            full_df = full_df[[\"r\", \"eta\", \"ksstat\"]]\n",
    "            full_df[\"1/beta\"] = full_df[\"r\"]/(full_df[\"eta\"] + 1.5)\n",
    "            \n",
    "            MULT = 1.2\n",
    "            significant_ksstat = master_df.loc[group, \"kstest_stat_cutoff_0.05\"]\n",
    "            #cutoff = max(min(full_df[\"ksstat\"]) * MULT, 0.01)\n",
    "            cutoff = max(significant_ksstat, 0.01)\n",
    "            if min(full_df[\"ksstat\"]) * MULT > 0.01:\n",
    "                uses_practical_threshold = 0\n",
    "            else:\n",
    "                uses_practical_threshold = 1\n",
    "\n",
    "            master_df.loc[group, \"use_practical_threshold\"] = uses_practical_threshold \n",
    "            \n",
    "            filtered_df = full_df[full_df[\"ksstat\"] < cutoff]\n",
    "            points = np.column_stack((filtered_df[\"r\"], filtered_df[\"1/beta\"])) + stats.norm.rvs(size=(len(filtered_df), 2)) * 0.001  # Adding small noise for convex hull computation\n",
    "\n",
    "            if len(points) < 3:\n",
    "                hull=np.nan\n",
    "                hull_area = 0\n",
    "                intersect_roi = 0\n",
    "            else:\n",
    "                hull = ConvexHull(points)\n",
    "                hull_area = hull.volume\n",
    "\n",
    "                if np.any(filtered_df[\"eta\"] > 0) and np.any(filtered_df[\"eta\"] < 0):\n",
    "                    intersect_roi = 1\n",
    "                else:\n",
    "                    intersect_roi = 0\n",
    "\n",
    "            master_df.loc[group, \"hull\"] = hull    \n",
    "            master_df.loc[group, \"hull_area\"] = hull_area\n",
    "            master_df.loc[group, \"intersect_roi\"] = intersect_roi\n",
    "\n",
    "            master_df.loc[group, \"hull_r_lower\"] = filtered_df['r'].min()\n",
    "            master_df.loc[group, \"hull_r_upper\"] = filtered_df['r'].max()\n",
    "            master_df.loc[group, \"hull_beta_lower\"] = 1/filtered_df['1/beta'].max()\n",
    "            master_df.loc[group, \"hull_beta_upper\"] = 1/filtered_df['1/beta'].min()\n",
    "\n",
    "            # print(master_df.loc[group, \"hull_r_lower\"], master_df.loc[group, \"hull_r_upper\"], master_df.loc[group, \"hull_beta_lower\"], master_df.loc[group, \"hull_beta_upper\"])\n",
    "\n",
    "            # kurt_lower, kurt_upper = master_df.loc[group, \"kurt_lower\"], master_df.loc[group, \"kurt_upper\"]\n",
    "            # best_scale = master_df.loc[group, \"best_scale\"]\n",
    "\n",
    "            # kurt_df = full_df.copy()\n",
    "            # kurt_df['kurt'] = kurt_df.apply(lambda row : kurtosis_prior(r=row['r'], eta=row['eta'], scale=best_scale), axis=1)\n",
    "            # kurt_df['pass_kurt'] = (kurt_df['kurt'] > kurt_lower) & (kurt_df['kurt'] < kurt_upper)\n",
    "\n",
    "            # pass_kurt_anywhere = np.sum(kurt_df['pass_kurt'] > 0)\n",
    "            # if pass_kurt_anywhere >= 3:\n",
    "            #     temp = kurt_df[kurt_df['pass_kurt'] == 1]\n",
    "            #     points_kurt = np.column_stack((temp[\"r\"], temp[\"1/beta\"])) + stats.norm.rvs(size=(len(temp), 2)) * 0.001\n",
    "            #     hull_kurt = ConvexHull(points_kurt)\n",
    "            #     hull_kurt_area = hull_kurt.volume\n",
    "            # else:\n",
    "            #     hull_kurt = np.nan\n",
    "            #     hull_kurt_area = 0\n",
    "\n",
    "            # master_df.loc[group, \"hull_kurt\"] = hull_kurt\n",
    "            # master_df.loc[group, \"hull_kurt_area\"] = hull_kurt_area\n",
    "            # master_df.loc[group, \"num_pass_kurt_anywhere\"] = pass_kurt_anywhere\n",
    "            # master_df.loc[group, \"pass_kurt_anywhere\"] = int(pass_kurt_anywhere > 0)\n",
    "            # master_df.loc[group, \"num_pass_kurt_intersect_hull\"] = np.sum((kurt_df['pass_kurt'] == 1) & (kurt_df['ksstat'] < cutoff))\n",
    "            # master_df.loc[group, \"pass_kurt_intersect_hull\"] = int(master_df.loc[group, \"num_pass_kurt_intersect_hull\"] > 0)\n",
    "\n",
    "    return master_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\fourier\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\fourier\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\fourier\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\fourier\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\gabor\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\gabor\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\gabor\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\gabor\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\learned\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\wavelet\\\\diagonal\\\\blue\\\\CSVs\\\\master_df.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths = find_master_dfs(os.path.join(ROOT_DIR, \"results\", \"case-studies\"))\n",
    "all_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [01:24<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main DF (before frequency): (2325, 45)\n",
      "Main DF (after frequency): (2325, 46)\n",
      "Main DF (after result categorization): (2328, 48)\n"
     ]
    }
   ],
   "source": [
    "relevant_cols = [\n",
    "        'group', 'dataset', 'subset', 'transform', 'orientation', 'channel', 'dataset_type', \n",
    "        'obs_var', 'var_lower', 'var_upper', \n",
    "        'total_samples', 'initial_r', 'initial_eta',  'best_r', 'best_eta', 'best_scale',\n",
    "        'kstest_stat_initial', 'kstest_stat_cutoff_0.05', 'kstest_stat_best', 'n_pval_0.05', \n",
    "        'obs_kurt', 'kurt_lower', 'kurt_upper', \n",
    "        'intersect_roi', 'hull', 'hull_area',\n",
    "        'hull_r_lower', 'hull_r_upper', 'hull_beta_lower', 'hull_beta_upper', \n",
    "        # 'num_pass_kurt_anywhere', 'pass_kurt_anywhere', 'num_pass_kurt_intersect_hull', 'pass_kurt_intersect_hull', 'hull_kurt', 'hull_kurt_area',\n",
    "        'param_gaussian', 'kstest_stat_gaussian', 'kstest_pval_gaussian', \n",
    "        'param_laplace', 'kstest_stat_laplace', 'kstest_pval_laplace', \n",
    "        'param_t', 'kstest_stat_t', 'kstest_pval_t', 'kstest_pval_gengamma', \n",
    "        'github_plot']\n",
    "sample_limit = 10\n",
    "\n",
    "all_paths = find_master_dfs(os.path.join(ROOT_DIR, \"results\", \"case-studies\"))\n",
    "all_master_dfs = []\n",
    "github_plots_path = \"https://github.com/yashdave003/hierarchical-bayesian-model-validation/blob/main/results/case-studies/\"\n",
    "\n",
    "for i in tqdm(range(len(all_paths))):\n",
    "    path = all_paths[i]\n",
    "    if 'scaleTesting' in path:\n",
    "        continue\n",
    "    master_df = pd.read_csv(path)\n",
    "    master_df = master_df.rename(columns={master_df.columns[0]: 'group'})\n",
    "    parts = Path(path).parts[-7:]\n",
    "    if parts[0] == 'case-studies':\n",
    "        parts = parts[1:]\n",
    "    elif parts[0] == 'results':\n",
    "        parts = parts[2:]\n",
    "    if \"MRI\" in path and \"gabor\" not in path:\n",
    "        dataset, slice, transform, orientation, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = slice\n",
    "        master_df['channel'] = np.nan\n",
    "        master_df['orientation'] = orientation\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, slice, transform, orientation, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "    elif \"MRI\" in path and \"gabor\" in path:\n",
    "        dataset, slice, transform, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = slice\n",
    "        master_df['channel'] = np.nan\n",
    "        master_df['orientation'] = np.nan\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, slice, transform, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "    elif \"gabor\" in path:\n",
    "        dataset, subset, transform, channel, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = subset\n",
    "        master_df['channel'] = channel\n",
    "        master_df['orientation'] = np.nan\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, subset, transform, channel, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "\n",
    "    elif len(parts) > 6:\n",
    "        dataset, subset, transform, orientation, channel, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = subset\n",
    "        master_df['channel'] = channel\n",
    "        master_df['orientation'] = orientation\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, subset, transform, orientation, channel, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "    elif \"learned\" in path:\n",
    "        dataset, subset, transform, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = subset\n",
    "        master_df = master_df.rename(columns={'filter_group' : 'orientation'})\n",
    "        master_df['channel'] = np.nan\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, subset, transform, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "\n",
    "    else:\n",
    "        dataset, size, transform, channel, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = size\n",
    "        master_df['channel'] = channel\n",
    "        master_df['orientation'] = np.nan\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, size, transform, channel, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "    \n",
    "    if dataset in ['pastis', 'agriVision', 'spaceNet']:\n",
    "        master_df['dataset_type'] = 'remote sensing'\n",
    "    elif dataset in ['syntheticMRI2D', 'syntheticMRI3D']:\n",
    "        master_df['dataset_type'] = 'medical'\n",
    "    elif dataset in ['coco', 'segmentAnything', 'standardTesting']:\n",
    "        master_df['dataset_type'] = 'natural'\n",
    "    elif dataset in ['standardTesting']:\n",
    "        master_df['dataset_type'] = 'classical'\n",
    "\n",
    "    GROUP = 'layer' if transform.split(\"-\")[0] == 'wavelet' else ('band' if transform.split(\"-\")[0] == 'fourier' else 'filter_idx')\n",
    "    rEtaKsstatsDict = pd.read_pickle(path[:-18] + \"cache\" + os.sep + \"rEtaKsstats_dict.pickle\")\n",
    "    \n",
    "    master_df = process_rEtaKsstats_dict(master_df, rEtaKsstatsDict)\n",
    "    all_master_dfs.append(master_df[relevant_cols])\n",
    "    \n",
    "main_df = pd.concat(all_master_dfs)\n",
    "\n",
    "main_df['best_beta'] = (main_df['best_eta'] + 1.5)/main_df['best_r'] \n",
    "main_df['best_1/beta'] = 1/main_df['best_beta']\n",
    "main_df['beat_all_priors'] = (main_df['kstest_stat_best'] < np.minimum.reduce([main_df['kstest_stat_gaussian'], main_df['kstest_stat_laplace'], main_df['kstest_stat_t']])).astype(int)\n",
    "main_df[\"best_prior\"] = np.array([\"GenGamma\", \"Gaussian\", \"Laplace\", \"Student-T\", np.nan])[\n",
    "                                np.nanargmin(np.array([main_df['kstest_stat_best'], \n",
    "                                                        main_df['kstest_stat_gaussian'], \n",
    "                                                        main_df['kstest_stat_laplace'], \n",
    "                                                        main_df['kstest_stat_t'], \n",
    "                                                        0.99*np.ones_like(main_df['kstest_stat_t'])]\n",
    "                                                        ).T, axis=1)]\n",
    "\n",
    "print(\"Main DF (before frequency):\", main_df.shape)\n",
    "frequency_map = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")).set_index(['dataset', 'transform', 'group'])\n",
    "main_df = main_df.set_index(['dataset', 'subset', 'transform', 'group']).merge(frequency_map, left_index = True, right_index=True, how='left').reset_index()\n",
    "\n",
    "print(\"Main DF (after frequency):\", main_df.shape)\n",
    "old_fail_cat_df_path = os.path.join(ROOT_DIR, \"publication\", \"paper\", \"CSVs\", 'result_categorization_sheet - combined_categories.csv')\n",
    "old_fail_cat_df = pd.read_csv(old_fail_cat_df_path)\n",
    "main_df = main_df.merge(old_fail_cat_df[['github_plot', 'failure_category', 'failure_type']], on='github_plot', how='left')\n",
    "print(\"Main DF (after result categorization):\", main_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fail_cat_df_path = os.path.join(ROOT_DIR, \"publication\", \"paper\", \"CSVs\", 'new_fail_cat_df.csv')\n",
    "main_df[\"pass\"] = main_df[\"kstest_stat_best\"] <= main_df[\"kstest_stat_cutoff_0.05\"]\n",
    "main_df[main_df['transform'] == 'gabor'][[\"total_samples\",\"dataset\", \"subset\" , \"transform\" , \"orientation\" , \"channel\" , \"group\" , \n",
    "        \"kstest_stat_best\", \"kstest_stat_cutoff_0.05\", \"beat_all_priors\", \"pass\", \"failure_category\", \"failure_type\", \"github_plot\"]].to_csv(new_fail_cat_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cols = (relevant_cols +\n",
    "        ['total_samples', 'beat_all_priors', 'best_prior', 'failure_category', 'failure_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[save_cols].drop(['hull'], axis=1).to_csv(save_path_without_hull)\n",
    "pd.to_pickle(main_df[save_cols], save_path_with_hull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failure_category\n",
       "practically_pass       1759\n",
       "trivial_failure         280\n",
       "actually_pass           170\n",
       "borderline               72\n",
       "interesting_failure      46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['failure_category'].value_counts() #['transform'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
