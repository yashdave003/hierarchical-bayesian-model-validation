{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import git\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import clear_output\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.spatial import ConvexHull\n",
    "import pylustrator\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial import distance\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "ROOT_DIR =  Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "save_path_with_hull = Path(os.path.join(ROOT_DIR, 'publication', 'paper', 'CSVs', 'final_results_with_hull.pickle'))\n",
    "save_path_without_hull = Path(os.path.join(ROOT_DIR, 'publication', 'paper', 'CSVs', 'final_results.csv'))\n",
    "plots_path = os.path.join(ROOT_DIR, \"publication\", \"paper\", \"draft_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_prior(r, eta, scale=1):\n",
    "    beta = (eta+1.5)/r\n",
    "    var_prior = scale * scipy.special.gamma(beta + 1/r)/scipy.special.gamma(beta)\n",
    "    return var_prior\n",
    "\n",
    "def kurtosis_prior(r, eta, scale=1, fisher=True):\n",
    "    beta = (eta+1.5)/r\n",
    "    kurtosis = scale*3*scipy.special.gamma(beta + 2/r)*scipy.special.gamma(beta)/scipy.special.gamma(beta+1/r)**2 # DOUBLE CHECK\n",
    "    if fisher:\n",
    "        return kurtosis - 3\n",
    "    else:\n",
    "        return kurtosis \n",
    "\n",
    "def find_master_dfs(root_dir: str) -> List[str]:\n",
    "    root_path = Path(root_dir)\n",
    "    if not root_path.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {root_dir}\")\n",
    "\n",
    "    master_df_paths = []\n",
    "    for current_dir, _, files in os.walk(root_path):\n",
    "        if 'master_df.csv' in files:\n",
    "            master_df_path = Path(os.path.join(current_dir, 'master_df.csv'))\n",
    "            master_df_paths.append(str(master_df_path.absolute()))\n",
    "    return master_df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hull_and_kurt(master_df, rEtaKsstats_dict, GROUP='group', debug=False):\n",
    "\n",
    "    master_df_copy = master_df.copy()\n",
    "    master_df_copy = master_df.set_index(GROUP)\n",
    "    groups = master_df_copy.index\n",
    "    master_df_copy[\"hull\"] = \"\"\n",
    "\n",
    "    for group in groups:\n",
    "        obs_kurt, kurt_lower, kurt_upper = master_df_copy.loc[group, \"obs_kurt\"], master_df_copy.loc[group, \"kurt_lower\"], master_df_copy.loc[group, \"kurt_upper\"]\n",
    "        best_scale = master_df_copy.loc[group, \"best_scale\"]\n",
    "\n",
    "        if master_df_copy.loc[group, \"total_samples\"] < 10:\n",
    "            master_df_copy.loc[group, \"hull\"] = np.nan\n",
    "        else:\n",
    "            drop_keys =list(rEtaKsstats_dict[group].keys())[-3:]\n",
    "            if debug:\n",
    "                print(drop_keys)\n",
    "            pre_optimization = pd.DataFrame(rEtaKsstats_dict[group]).drop(drop_keys, axis = 1 )\n",
    "            optimization = pd.DataFrame(rEtaKsstats_dict[group])[drop_keys]\n",
    "            optimization = optimization.rename(columns = {\"r_optimize\": \"r\", \"eta_optimize\": \"eta\", drop_keys[-1]: \"ksstat\"})\n",
    "            optimization = optimization.dropna()\n",
    "            full_df = pre_optimization.merge(optimization, on=[\"r\", \"eta\"], how=\"outer\")\n",
    "            full_df['kurt'] = full_df.apply(lambda row : kurtosis_prior(r=row['r'], eta=row['eta'], scale=best_scale), axis=1)\n",
    "            full_df['pass_kurt'] = (full_df['kurt'] > kurt_lower) & (full_df['kurt'] < kurt_upper)\n",
    "            kurt_df = full_df.copy()\n",
    "            kurt_df[\"beta\"] = (kurt_df[\"eta\"] + 1.5)/kurt_df[\"r\"]\n",
    "            \n",
    "            full_df = full_df.set_index([\"r\", \"eta\"])\n",
    "            full_df[\"ksstat\"] = full_df.min(axis=1)\n",
    "            full_df = full_df.reset_index()\n",
    "            full_df = full_df[[\"r\", \"eta\", \"ksstat\"]]\n",
    "            full_df[\"beta\"] = (full_df[\"eta\"] + 1.5)/full_df[\"r\"]\n",
    "            full_df[\"1/beta\"] = 1/full_df[\"beta\"]\n",
    "            MULT = 1.2\n",
    "            cutoff = max(min(full_df[\"ksstat\"]) * MULT, 0.01)\n",
    "            filtered_df = full_df[full_df[\"ksstat\"] < cutoff]\n",
    "            points = np.column_stack((filtered_df[\"r\"], filtered_df[\"1/beta\"])) + stats.norm.rvs(size=(len(filtered_df), 2)) * 0.001  # Adding small noise for convex hull computation\n",
    "            if len(points) < 3:\n",
    "                hull=np.nan\n",
    "                master_df_copy.loc[group, \"intersect_roi\"] = -1\n",
    "            else:\n",
    "                hull = ConvexHull(points)\n",
    "\n",
    "                x_vals = np.logspace(0, 20, 1000)\n",
    "                eta_vals = 1.5 + np.zeros_like(x_vals)\n",
    "                roi = (eta_vals) / x_vals\n",
    "                \n",
    "                line_points = np.column_stack((x_vals, roi))\n",
    "                intersect_roi = int(np.any(in_hull(line_points, hull)))\n",
    "                master_df_copy.loc[group, \"intersect_roi\"] = intersect_roi\n",
    "\n",
    "            pass_kurt_anywhere = np.sum(kurt_df['pass_kurt'] > 0)\n",
    "            if pass_kurt_anywhere > 3:\n",
    "                temp = kurt_df[kurt_df['pass_kurt'] == 1]\n",
    "                kurt_points = np.column_stack((temp[\"r\"], temp[\"beta\"])) + stats.norm.rvs(size=(len(temp), 2)) * 0.001\n",
    "                master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
    "            else:\n",
    "                master_df_copy.loc[group, \"hull_kurt\"] = np.nan\n",
    "\n",
    "            \n",
    "            master_df_copy.loc[group, \"hull\"] = hull\n",
    "            master_df_copy.loc[group, \"num_pass_kurt_anywhere\"] = pass_kurt_anywhere\n",
    "            master_df_copy.loc[group, \"pass_kurt_anywhere\"] = int(pass_kurt_anywhere > 0)\n",
    "            master_df_copy.loc[group, \"num_pass_kurt_intersect_hull\"] = np.sum((kurt_df['pass_kurt'] == 1) & (kurt_df['ksstat'] < cutoff))\n",
    "            master_df_copy.loc[group, \"pass_kurt_intersect_hull\"] = int(master_df_copy.loc[group, \"num_pass_kurt_intersect_hull\"] > 0)\n",
    "\n",
    "    return master_df_copy.reset_index()\n",
    "\n",
    "def in_hull(p, hull):\n",
    "    if hasattr(hull, 'vertices') and not isinstance(hull, Delaunay):\n",
    "        hull = Delaunay(hull.points)\n",
    "    elif not isinstance(hull, Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "    return hull.find_simplex(p) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\fourier\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\fourier\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\fourier\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\fourier\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\learned\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\wavelet\\\\diagonal\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\wavelet\\\\diagonal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\wavelet\\\\diagonal\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\wavelet\\\\diagonal\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\wavelet\\\\horizVert\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\wavelet\\\\horizVert\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\wavelet\\\\horizVert\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\agriVision\\\\full\\\\wavelet\\\\horizVert\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\learned\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\diagonal\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\diagonal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\diagonal\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\diagonal\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\horizontal\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\horizontal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\horizontal\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\horizontal\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\vertical\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\vertical\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\vertical\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\indoor\\\\wavelet\\\\vertical\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\learned\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\diagonal\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\diagonal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\diagonal\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\diagonal\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\horizontal\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\horizontal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\horizontal\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\horizontal\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\vertical\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\vertical\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\vertical\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\coco\\\\outdoor\\\\wavelet\\\\vertical\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\experiments\\\\scaleTesting\\\\_\\\\samplePrior\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\fourier\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\fourier\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\fourier\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\fourier\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\learned\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\wavelet\\\\diagonal\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\wavelet\\\\diagonal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\wavelet\\\\diagonal\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\wavelet\\\\diagonal\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\wavelet\\\\horizVert\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\wavelet\\\\horizVert\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\wavelet\\\\horizVert\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\pastis\\\\full\\\\wavelet\\\\horizVert\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\scaleTesting\\\\wavelet\\\\full\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\scaleTesting\\\\wavelet\\\\full\\\\laplace\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\learned\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\diagonal\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\diagonal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\diagonal\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\diagonal\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\horizontal\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\horizontal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\horizontal\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\horizontal\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\vertical\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\vertical\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\vertical\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\segmentAnything\\\\full\\\\wavelet\\\\vertical\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\fourier\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\fourier\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\fourier\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\fourier\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\learned\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\wavelet\\\\diagonal\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\wavelet\\\\diagonal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\wavelet\\\\diagonal\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\wavelet\\\\diagonal\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\wavelet\\\\horizVert\\\\blue\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\wavelet\\\\horizVert\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\wavelet\\\\horizVert\\\\green\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\spaceNet\\\\full\\\\wavelet\\\\horizVert\\\\red\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\standardTesting\\\\full\\\\learned\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\standardTesting\\\\full\\\\wavelet\\\\diagonal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\standardTesting\\\\full\\\\wavelet\\\\horizontal\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\standardTesting\\\\full\\\\wavelet\\\\vertical\\\\gray\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI2D\\\\axial\\\\wavelet\\\\diagonal\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI2D\\\\axial\\\\wavelet\\\\horizontal\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI2D\\\\axial\\\\wavelet\\\\vertical\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI2D\\\\coronal\\\\wavelet\\\\diagonal\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI2D\\\\coronal\\\\wavelet\\\\horizontal\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI2D\\\\coronal\\\\wavelet\\\\vertical\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI2D\\\\sagittal\\\\wavelet\\\\diagonal\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI2D\\\\sagittal\\\\wavelet\\\\horizontal\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI2D\\\\sagittal\\\\wavelet\\\\vertical\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI3D\\\\full\\\\wavelet\\\\aad\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI3D\\\\full\\\\wavelet\\\\ada\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI3D\\\\full\\\\wavelet\\\\add\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI3D\\\\full\\\\wavelet\\\\daa\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI3D\\\\full\\\\wavelet\\\\dad\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI3D\\\\full\\\\wavelet\\\\dda\\\\CSVs\\\\master_df.csv',\n",
       " 'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\results\\\\case-studies\\\\syntheticMRI3D\\\\full\\\\wavelet\\\\ddd\\\\CSVs\\\\master_df.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths = find_master_dfs(os.path.join(ROOT_DIR, \"results\", \"case-studies\"))\n",
    "all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:00<?, ?it/s]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095A83950>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 13%|█▎        | 13/101 [18:12<2:01:25, 82.79s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095B7FC90>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 14%|█▍        | 14/101 [26:31<4:57:35, 205.23s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026096BA33D0>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 15%|█▍        | 15/101 [27:42<3:57:25, 165.65s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095AE8F90>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 16%|█▌        | 16/101 [28:54<3:14:54, 137.58s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095B95250>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 17%|█▋        | 17/101 [29:57<2:41:34, 115.41s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095B24CD0>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 18%|█▊        | 18/101 [31:02<2:19:05, 100.55s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095B1BAD0>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 19%|█▉        | 19/101 [32:48<2:19:23, 102.00s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095BBBF10>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 20%|█▉        | 20/101 [34:20<2:13:44, 99.06s/it] C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026096BBC210>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 21%|██        | 21/101 [35:41<2:04:45, 93.57s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026096BB73D0>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 22%|██▏       | 22/101 [36:48<1:52:44, 85.63s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095B8C510>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 23%|██▎       | 23/101 [37:53<1:43:29, 79.60s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095B8E8D0>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 24%|██▍       | 24/101 [39:04<1:38:40, 76.90s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095B81F50>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 25%|██▍       | 25/101 [40:17<1:36:02, 75.82s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095B960D0>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 27%|██▋       | 27/101 [1:37:59<21:57:53, 1068.56s/it]C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095AE8210>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 28%|██▊       | 28/101 [1:41:46<16:33:05, 816.24s/it] C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_92136\\3983134503.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<scipy.spatial._qhull.ConvexHull object at 0x0000026095ABDCD0>' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  master_df_copy.loc[group, \"hull_kurt\"] = ConvexHull(kurt_points)\n",
      " 28%|██▊       | 28/101 [1:47:12<4:39:30, 229.74s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m     GROUP \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transform\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwavelet\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mband\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transform\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfourier\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilter_idx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m     rEtaKsstatsDict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(path[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m18\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39msep \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrEtaKsstats_dict.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m     master_df \u001b[38;5;241m=\u001b[39m \u001b[43madd_hull_and_kurt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaster_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrEtaKsstatsDict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     all_master_dfs\u001b[38;5;241m.\u001b[39mappend(master_df[relevant_cols])\n\u001b[0;32m     78\u001b[0m main_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_master_dfs)\n",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m, in \u001b[0;36madd_hull_and_kurt\u001b[1;34m(master_df, rEtaKsstats_dict, GROUP, debug)\u001b[0m\n\u001b[0;32m     21\u001b[0m optimization \u001b[38;5;241m=\u001b[39m optimization\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     22\u001b[0m full_df \u001b[38;5;241m=\u001b[39m pre_optimization\u001b[38;5;241m.\u001b[39mmerge(optimization, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m\"\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkurt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfull_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkurtosis_prior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_scale\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_kurt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkurt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m kurt_lower) \u001b[38;5;241m&\u001b[39m (full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkurt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m kurt_upper)\n\u001b[0;32m     25\u001b[0m kurt_df \u001b[38;5;241m=\u001b[39m full_df\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\yashd\\.conda\\envs\\hbmv_backup2\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yashd\\.conda\\envs\\hbmv_backup2\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashd\\.conda\\envs\\hbmv_backup2\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\yashd\\.conda\\envs\\hbmv_backup2\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m, in \u001b[0;36madd_hull_and_kurt.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     21\u001b[0m optimization \u001b[38;5;241m=\u001b[39m optimization\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     22\u001b[0m full_df \u001b[38;5;241m=\u001b[39m pre_optimization\u001b[38;5;241m.\u001b[39mmerge(optimization, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m\"\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkurt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m full_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row : \u001b[43mkurtosis_prior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_scale\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass_kurt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkurt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m kurt_lower) \u001b[38;5;241m&\u001b[39m (full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkurt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m kurt_upper)\n\u001b[0;32m     25\u001b[0m kurt_df \u001b[38;5;241m=\u001b[39m full_df\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m, in \u001b[0;36mkurtosis_prior\u001b[1;34m(r, eta, scale, fisher)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkurtosis_prior\u001b[39m(r, eta, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, fisher\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      7\u001b[0m     beta \u001b[38;5;241m=\u001b[39m (eta\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1.5\u001b[39m)\u001b[38;5;241m/\u001b[39mr\n\u001b[1;32m----> 8\u001b[0m     kurtosis \u001b[38;5;241m=\u001b[39m scale\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mscipy\u001b[38;5;241m.\u001b[39mspecial\u001b[38;5;241m.\u001b[39mgamma(beta \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39mr)\u001b[38;5;241m*\u001b[39m\u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mscipy\u001b[38;5;241m.\u001b[39mspecial\u001b[38;5;241m.\u001b[39mgamma(beta\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mr)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# DOUBLE CHECK\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fisher:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m kurtosis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "relevant_cols = [\n",
    "        'group', 'dataset', 'subset', 'transform', 'orientation', 'channel', 'dataset_type', \n",
    "        'obs_var', 'var_lower', 'var_upper', \n",
    "        'total_samples', 'initial_r', 'initial_eta',  'best_r', 'best_eta', 'best_scale',\n",
    "        'kstest_stat_initial', 'kstest_stat_cutoff_0.05', 'kstest_stat_best',\n",
    "        'obs_kurt', 'kurt_lower', 'kurt_upper', 'num_pass_kurt_anywhere', 'pass_kurt_anywhere', 'num_pass_kurt_intersect_hull', 'pass_kurt_intersect_hull', 'hull', 'hull_kurt',\n",
    "        'param_gaussian', 'kstest_stat_gaussian', 'kstest_pval_gaussian', \n",
    "        'param_laplace', 'kstest_stat_laplace', 'kstest_pval_laplace', \n",
    "        'param_t', 'kstest_stat_t', 'kstest_pval_t', 'kstest_pval_gengamma', \n",
    "        'github_plot', 'intersect_roi', 'hull_kurt']\n",
    "\n",
    "all_paths = find_master_dfs(os.path.join(ROOT_DIR, \"results\", \"case-studies\"))\n",
    "all_master_dfs = []\n",
    "github_plots_path = \"https://github.com/yashdave003/hierarchical-bayesian-model-validation/blob/main/results/case-studies/\"\n",
    "\n",
    "for i in tqdm(range(len(all_paths))):\n",
    "    path = all_paths[i]\n",
    "    if 'scaleTesting' in path:\n",
    "        continue\n",
    "    if path in all_paths[:4]: # just test agriVision fourier\n",
    "        continue\n",
    "    master_df = pd.read_csv(path)\n",
    "    master_df = master_df.rename(columns={master_df.columns[0]: 'group'})\n",
    "    parts = Path(path).parts[-7:]\n",
    "    if parts[0] == 'case-studies':\n",
    "        parts = parts[1:]\n",
    "    elif parts[0] == 'results':\n",
    "        parts = parts[2:]\n",
    "    if \"MRI\" in path:\n",
    "        dataset, slice, transform, orientation, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = slice\n",
    "        master_df['channel'] = np.nan\n",
    "        master_df['orientation'] = orientation\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, slice, transform, orientation, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "    elif len(parts) > 6:\n",
    "        dataset, subset, transform, orientation, channel, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = subset\n",
    "        master_df['channel'] = channel\n",
    "        master_df['orientation'] = orientation\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, subset, transform, orientation, channel, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "    elif \"learned\" in path:\n",
    "        dataset, subset, transform, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = subset\n",
    "        master_df = master_df.rename(columns={'filter_group' : 'orientation'})\n",
    "        master_df['channel'] = np.nan\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, subset, transform, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "\n",
    "    else:\n",
    "        dataset, size, transform, channel, _, _ = parts\n",
    "        master_df['dataset'] = dataset\n",
    "        master_df['transform'] = transform\n",
    "        master_df['subset'] = size\n",
    "        master_df['channel'] = channel\n",
    "        master_df['orientation'] = np.nan\n",
    "        master_df['github_plot'] = [github_plots_path+'/'.join([dataset, size, transform, channel, 'plots', f'compare_cdf_pdf_layer_{group}.jpg']) for group in master_df['group']]\n",
    "    \n",
    "    if dataset in ['pastis', 'agriVision', 'spaceNet']:\n",
    "        master_df['dataset_type'] = 'remote sensing'\n",
    "    elif dataset in ['syntheticMRI2D', 'syntheticMRI3D']:\n",
    "        master_df['dataset_type'] = 'medical'\n",
    "    elif dataset in ['coco', 'segmentAnything', 'standardTesting']:\n",
    "        master_df['dataset_type'] = 'natural'\n",
    "    elif dataset in ['standardTesting']:\n",
    "        master_df['dataset_type'] = 'classical'\n",
    "\n",
    "    GROUP = 'layer' if transform.split(\"-\")[0] == 'wavelet' else ('band' if transform.split(\"-\")[0] == 'fourier' else 'filter_idx')\n",
    "    rEtaKsstatsDict = pd.read_pickle(path[:-18] + \"cache\" + os.sep + \"rEtaKsstats_dict.pickle\")\n",
    "    \n",
    "    master_df = add_hull_and_kurt(master_df, rEtaKsstatsDict)\n",
    "    all_master_dfs.append(master_df[relevant_cols])\n",
    "    \n",
    "main_df = pd.concat(all_master_dfs)\n",
    "\n",
    "main_df['best_beta'] = (main_df['best_eta'] + 1.5)/main_df['best_r'] \n",
    "main_df['best_1/beta'] = 1/main_df['best_beta']\n",
    "main_df['beat_all_priors'] = (main_df['kstest_stat_best'] < np.minimum.reduce([main_df['kstest_stat_gaussian'], main_df['kstest_stat_laplace'], main_df['kstest_stat_t']])).astype(int)\n",
    "main_df[\"best_prior\"] = np.array([\"GenGamma\", \"Gaussian\", \"Laplace\", \"Student-T\", np.nan])[\n",
    "                                np.nanargmin(np.array([main_df['kstest_stat_best'], \n",
    "                                                        main_df['kstest_stat_gaussian'], \n",
    "                                                        main_df['kstest_stat_laplace'], \n",
    "                                                        main_df['kstest_stat_t'], \n",
    "                                                        0.99*np.ones_like(main_df['kstest_stat_t'])]\n",
    "                                                        ).T, axis=1)]\n",
    "\n",
    "print(\"Main DF (before frequency):\", main_df.shape)\n",
    "frequency_map = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", \"master-frequency-map.csv\")).set_index(['dataset', 'transform', 'group'])\n",
    "main_df = main_df.set_index(['dataset', 'subset', 'transform', 'group']).merge(frequency_map, left_index = True, right_index=True, how='left').reset_index()\n",
    "\n",
    "print(\"Main DF (after frequency):\", main_df.shape)\n",
    "old_fail_cat_df_path = os.path.join(ROOT_DIR, \"publication\", \"paper\", \"CSVs\", 'result_categorization_sheet - combined_categories.csv')\n",
    "old_fail_cat_df = pd.read_csv(old_fail_cat_df_path)\n",
    "main_df = main_df.merge(old_fail_cat_df[['github_plot', 'failure_category', 'failure_type', 'which_ones']], on='github_plot', how='left')\n",
    "print(\"Main DF (after result categorization):\", main_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hull'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\yashd\\.conda\\envs\\hbmv_backup2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hull'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmaster_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashd\\.conda\\envs\\hbmv_backup2\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\yashd\\.conda\\envs\\hbmv_backup2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hull'"
     ]
    }
   ],
   "source": [
    "master_df['hull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cols = ([\n",
    "        'group', 'dataset', 'subset', 'transform', 'orientation', 'channel', 'dataset_type', \n",
    "        'obs_var', 'var_lower', 'var_upper', \n",
    "        'total_samples', 'initial_r', 'initial_eta',  'best_r', 'best_eta', 'best_scale',\n",
    "        'kstest_stat_initial', 'kstest_stat_cutoff_0.05', 'kstest_stat_best',\n",
    "        'obs_kurt', 'kurt_lower', 'kurt_upper', 'num_pass_kurt_anywhere', 'pass_kurt_anywhere', 'num_pass_kurt_intersect_hull', 'pass_kurt_intersect_hull', 'hull', 'hull_kurt',\n",
    "        'param_gaussian', 'kstest_stat_gaussian', 'kstest_pval_gaussian', \n",
    "        'param_laplace', 'kstest_stat_laplace', 'kstest_pval_laplace', \n",
    "        'param_t', 'kstest_stat_t', 'kstest_pval_t', 'kstest_pval_gengamma', \n",
    "        'github_plot', 'intersect_roi', 'hull_kurt'] +\n",
    "        ['total_samples', 'beat_all_priors', 'best_prior', 'failure_category', 'failure_type', 'which_ones']) # relevant_cols + more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[save_cols].drop('hull', axis=1).to_csv(save_path_without_hull)\n",
    "pd.to_pickle(main_df[save_cols], save_path_with_hull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_hull_list(p, hulls):\n",
    "   return np.any([in_hull(p, hull) for hull in hulls], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_pickle(save_path_with_hull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intersect_roi\n",
       "1.0    135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['intersect_roi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mall_paths\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_paths' is not defined"
     ]
    }
   ],
   "source": [
    "all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_points = 150\n",
    "JITTER_FACTOR = 50\n",
    "size = 1\n",
    "datasets = [(\"pastis\", \"full\")] #[(\"agriVision\", \"full\"), (\"pastis\", \"full\"), (\"spaceNet\", \"full\")]\n",
    "directions = [\"fourier\", \"horizVert\", \"diagonal\"]\n",
    "\n",
    "\n",
    "# Add a fourth column to the right for the new plots\n",
    "fig, axes = plt.subplots(3, 4, figsize=(24, 18), sharex=True, sharey=True)\n",
    "global_xmax = 0\n",
    "global_ymax = 0\n",
    "global_xmin = np.inf\n",
    "global_ymin = np.inf\n",
    "for i, DATASET in enumerate(datasets):\n",
    "    for j, direction in enumerate(directions):\n",
    "        ax = axes[i, j]\n",
    "        df = main_df[(main_df[\"dataset\"] == DATASET[0]) & (main_df[\"subset\"] == DATASET[1]) & (main_df[\"transform\"] != \"learned\") & (main_df[\"orientation\"] == direction)].copy()\n",
    "        df = df.dropna(subset=[\"hull\"])\n",
    "        df[\"best_1/beta\"] = 1 / df[\"best_beta\"]\n",
    "        group_list = df[\"group\"].unique()\n",
    "        hull_list = []\n",
    "        all_hulls = []\n",
    "        for group in group_list:\n",
    "            hull_list.append(df[df[\"group\"] == group][\"hull\"])\n",
    "            all_hulls.extend(df[df[\"group\"] == group][\"hull\"])\n",
    "        if len(all_hulls) == 0:\n",
    "            continue\n",
    "        all_points = np.vstack([hull.points for hull in all_hulls])\n",
    "        xmin, xmax = all_points[:, 0].min(), all_points[:, 0].max()\n",
    "        ymin, ymax = all_points[:, 1].min(), all_points[:, 1].max()\n",
    "\n",
    "        if xmax > global_xmax:\n",
    "            global_xmax = xmax\n",
    "        if ymax > global_ymax:\n",
    "            global_ymax = ymax\n",
    "        if xmin < global_xmin:\n",
    "            global_xmin = xmin\n",
    "        if ymin < global_ymin:\n",
    "            global_ymin = ymin\n",
    "            \n",
    "        color_map = plt.get_cmap('viridis')\n",
    "        num_groups = len(group_list)\n",
    "        group_colors = {group: color_map(idx / max(num_groups - 1, 1)) for idx, group in enumerate(group_list)}\n",
    "        x_vals = np.logspace(np.log10(xmin), np.log10(xmax), num_points)\n",
    "        y_vals = np.logspace(np.log10(ymin), np.log10(ymax), num_points)\n",
    "        \n",
    "        xx, yy = np.meshgrid(x_vals, y_vals)\n",
    "        points_grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "        for k, hull in enumerate(hull_list):\n",
    "            hull_mask = in_hull_list(points_grid, hull)\n",
    "            points = points_grid[hull_mask]\n",
    "            points = points + np.random.normal(scale=points / JITTER_FACTOR, size=points.shape)\n",
    "            ax.scatter(points[:, 0], 1/points[:, 1], s=size, label=group_list[k], alpha=0.5, color=group_colors[group_list[k]])\n",
    "        ax.set_xlabel(\"r\")\n",
    "        ax.set_ylabel(\"beta\")\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        temp_df = df[df[\"orientation\"] == direction]\n",
    "        ax.set_title(f\"{DATASET[0]}-{direction} \\n {sum(temp_df['intersect_roi'])}/{len(temp_df)} hulls intersect ROI\")\n",
    "\n",
    "    # Fourth column: plot by orientation for each DATASET\n",
    "    ax4 = axes[i, 3]\n",
    "    df = main_df[(main_df[\"dataset\"] == DATASET[0]) & (main_df[\"subset\"] == DATASET[1]) & (main_df[\"transform\"] != \"learned\")].copy()\n",
    "    df = df.dropna(subset=[\"hull\"])\n",
    "    df[\"best_1/beta\"] = 1 / df[\"best_beta\"]\n",
    "    if df[\"dataset_type\"].unique()[0] == \"remote sensing\":\n",
    "        df[\"orientation\"] = df[\"orientation\"].fillna(\"fourier\")\n",
    "    orientation_list = df[\"orientation\"].unique()\n",
    "    hull_list = []\n",
    "    all_hulls = []\n",
    "    for orientation in orientation_list:\n",
    "        hull_list.append(df[df[\"orientation\"] == orientation][\"hull\"])\n",
    "        all_hulls.extend(df[df[\"orientation\"] == orientation][\"hull\"])\n",
    "    if len(all_hulls) == 0:\n",
    "        continue\n",
    "    all_points = np.vstack([hull.points for hull in all_hulls])\n",
    "    xmin, xmax = all_points[:, 0].min(), all_points[:, 0].max()\n",
    "    ymin, ymax = all_points[:, 1].min(), all_points[:, 1].max()\n",
    "    orientation_colors = {\"horizVert\": \"blue\", \"diagonal\": \"green\", \"fourier\": \"orange\", \"vertical\": \"purple\", \"horizontal\": \"red\"}\n",
    "    x_vals = np.logspace(np.log10(xmin), np.log10(xmax), num_points)\n",
    "    y_vals = np.logspace(np.log10(ymin), np.log10(ymax), num_points)\n",
    "    \n",
    "    xx, yy = np.meshgrid(x_vals, y_vals)\n",
    "    points_grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    for k, hull in enumerate(hull_list):\n",
    "        hull_mask = in_hull_list(points_grid, hull)\n",
    "        points = points_grid[hull_mask]\n",
    "        points = points + np.random.normal(scale=points / JITTER_FACTOR, size=points.shape)\n",
    "        ax4.scatter(points[:, 0], 1/points[:, 1], s=size, label=orientation_list[k], alpha=0.5, color=orientation_colors[orientation_list[k]])\n",
    "    ax4.set_xlabel(\"r\")\n",
    "    ax4.set_ylabel(\"beta\")\n",
    "    ax4.set_xscale('log')\n",
    "    ax4.set_yscale('log')\n",
    "    ax4.set_title(f\"Points in Hulls - {DATASET} \\n {sum(df['intersect_roi'])}/{len(df)} hulls intersect ROI\")\n",
    "    ax4.legend()\n",
    "\n",
    "for i in range(axes.shape[0]):\n",
    "    for j in range(axes.shape[1]):\n",
    "        ax = axes[i, j]\n",
    "        x_vals_global = np.logspace(np.log10(global_xmin) -1 , np.log10(global_xmax+1) + 1, num_points)\n",
    "        eta_vals_global = 0 * np.zeros_like(x_vals_global)\n",
    "        eta_roi_lower = -0.1 * np.zeros_like(x_vals_global)\n",
    "        eta_roi_upper = 0.1 * np.zeros_like(x_vals_global)\n",
    "        eta_20_vals_global = 25 + np.zeros_like(x_vals_global)\n",
    "        eta_lower_global = -1.4 + np.zeros_like(x_vals_global)\n",
    "        eta_neg_1 = -1 + np.zeros_like(x_vals_global)\n",
    "        \n",
    "        roi_global = (eta_vals_global + 1.5) / x_vals_global\n",
    "        roi_lower = (eta_roi_lower + 1.5) / x_vals_global\n",
    "        roi_upper = (eta_roi_upper + 1.5) / x_vals_global\n",
    "        beta_20_global = (eta_20_vals_global + 1.5) / x_vals_global\n",
    "        beta_lower_global = (eta_lower_global + 1.5) / x_vals_global\n",
    "        beta_neg_1_global = (eta_neg_1 + 1.5) / x_vals_global\n",
    "        \n",
    "        ax.plot(x_vals_global, roi_global, color='xkcd:light red', linestyle='-', label='ROI', zorder=0, linewidth=2)\n",
    "       #ax.fill_between(x_vals_global, roi_lower, roi_upper, color='xkcd:light red')\n",
    "        ax.plot(x_vals_global, beta_20_global, color='black', linestyle='--', label='ROI', zorder=0, linewidth=2)\n",
    "        ax.plot(x_vals_global, beta_lower_global, color='black', linestyle='--', label='ROI', zorder=0, linewidth=2)\n",
    "        ax.plot(x_vals_global, beta_neg_1_global, color='purple', linestyle='--', label='ROI', zorder=0, linewidth=2, alpha=0.5)\n",
    "        ax.axvline(x=1, color='xkcd:nice blue', linestyle='--', label='r=1', zorder=0, linewidth=2, alpha=0.5)\n",
    "\n",
    "        \n",
    "\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.fill_between(x_vals_global, ylim[0], beta_lower_global, color='gray', alpha=0.2)\n",
    "        ax.fill_between(x_vals_global, ylim[1], beta_20_global, color='gray', alpha=0.2)\n",
    "\n",
    "        ax.set_xlabel(\"r\")\n",
    "        ax.set_ylabel(\"beta\")\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xlim(global_xmin/1.2, global_xmax*1.2)\n",
    "        ax.set_ylim(ylim)\n",
    "        #ax.set_ylim(global_ymin, global_ymax)\n",
    "       \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(os.path.join(plots_path, \"region_pointalism_remote_sensing.png\"), bbox_inches='tight', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_backup2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
