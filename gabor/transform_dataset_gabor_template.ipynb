{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e81854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import scipy.ndimage as ndi\n",
    "import pandas as pd\n",
    "from skimage.filters import gabor_kernel\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from learned import *\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"coco\"\n",
    "RAW_DATA_SUFFIX = \"outdoor-coco-cropped-normalized\"\n",
    "FINAL_DATA_NAME = ...\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "\n",
    "num_images=1000\n",
    "jitter=False \n",
    "normalize=False \n",
    "\n",
    "#data_dir = os.path.join(ROOT_DIR, 'raw-data', DATASET, RAW_DATA_SUFFIX)\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data', RAW_DATA_SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27b89233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_gabor_kernel_skimage_cached(frequency: float,\n",
    "                                          wave_number: int,\n",
    "                                          theta: float,\n",
    "                                          aspect_ratio: float,\n",
    "                                          dtype_str: str) -> np.ndarray:\n",
    "    if frequency <= 0:\n",
    "        raise ValueError(\"frequency must be positive (cycles/pixel).\")\n",
    "    \n",
    "    # choose n_stds explicitly (same value you pass to gabor_kernel; default is 3)\n",
    "    n_stds = 3\n",
    "    sigma_x = wave_number / (2.0 * n_stds * frequency)   # NOT 4*frequency\n",
    "    sigma_y = aspect_ratio * sigma_x\n",
    "    k_complex = gabor_kernel(frequency=frequency, theta=theta, sigma_x=sigma_x, sigma_y=sigma_y, n_stds=n_stds)\n",
    "\n",
    "    k = np.real(k_complex).astype(np.dtype(dtype_str), copy=False)\n",
    "    k -= k.mean()\n",
    "    nrm = np.linalg.norm(k.ravel())\n",
    "    if nrm > 1e-12:\n",
    "        k = k / nrm\n",
    "    return k\n",
    "\n",
    "def generate_gabor_kernel_skimage(frequency: float,\n",
    "                                  wave_number: int,\n",
    "                                  theta: float = 0.0,\n",
    "                                  aspect_ratio: float = 1.0,\n",
    "                                  dtype=np.float64) -> np.ndarray:\n",
    "    \"\"\"Public wrapper returning a copy to avoid accidental mutation of cached data.\"\"\"\n",
    "    arr = _generate_gabor_kernel_skimage_cached(\n",
    "        float(frequency), int(wave_number), float(theta),\n",
    "        float(aspect_ratio), np.dtype(dtype).name\n",
    "    )\n",
    "    if arr is not None:\n",
    "        return arr.copy()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8ea3ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 69)\n",
      "20 6\n"
     ]
    }
   ],
   "source": [
    "param_df = pd.read_csv(os.path.join(ROOT_DIR, \"gabor\", \"gabor_test.csv\"))\n",
    "\n",
    "orientations = [0, np.pi/6, np.pi/3, np.pi/2, 2*np.pi/3, 5*np.pi/6]\n",
    "\n",
    "filters = []\n",
    "for i in range(len(param_df)):\n",
    "    fil_orients = []\n",
    "\n",
    "    for j in range(len(orientations)):\n",
    "        fil = generate_gabor_kernel_skimage(param_df[\"frequency\"][i], param_df[\"wave_number\"][i], orientations[j], param_df[\"aspect_ratio\"][i])\n",
    "        if fil is not None:\n",
    "            fil_orients.append(fil)\n",
    "    \n",
    "    filters.append(fil_orients)\n",
    "\n",
    "print(filters[0][0].shape)\n",
    "print(len(filters), len(filters[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "781fff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2361f872903402a8d920abec9644138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading images:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_images, H, W, channels: (2, 256, 256, 3) \n",
      "num_filters 20\n"
     ]
    }
   ],
   "source": [
    "images = load_images_from_directory(data_dir, n=num_images, jitter=jitter, normalize=normalize)\n",
    "print(\"num_images, H, W, channels:\", images.shape, \"\\nnum_filters\", len(filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89f45a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(image, filter):\n",
    "    \"\"\"\n",
    "    Applies Gabor filter to the input RGB image.\n",
    "    \"\"\"\n",
    "    # print(image.shape)\n",
    "    # print(filter.shape)\n",
    "    out = np.zeros_like(image)\n",
    "    for ch in range(3):\n",
    "        out[:, :, ch] = ndi.convolve(\n",
    "            image[:, :, ch],\n",
    "            filter,\n",
    "            mode='reflect'\n",
    "        )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f34c4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13aed56d173043f8bc3d9faf7efb1b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m fil \u001b[38;5;241m=\u001b[39m filters[i][j]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n\u001b[0;32m----> 9\u001b[0m     convolved \u001b[38;5;241m=\u001b[39m \u001b[43mapply_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     curr_transformed\u001b[38;5;241m.\u001b[39mappend(convolved\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m     12\u001b[0m curr_transformed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(curr_transformed)\n",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m, in \u001b[0;36mapply_filter\u001b[0;34m(image, filter)\u001b[0m\n\u001b[1;32m      7\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(image)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     out[:, :, ch] \u001b[38;5;241m=\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreflect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hbmv_2/lib/python3.11/site-packages/scipy/ndimage/_filters.py:1064\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(input, weights, output, mode, cval, origin, axes)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;129m@_ni_docstrings\u001b[39m\u001b[38;5;241m.\u001b[39mdocfiller\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvolve\u001b[39m(\u001b[38;5;28minput\u001b[39m, weights, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m'\u001b[39m, cval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    951\u001b[0m              origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    952\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;124;03m    Multidimensional convolution.\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_correlate_or_convolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hbmv_2/lib/python3.11/site-packages/scipy/ndimage/_filters.py:872\u001b[0m, in \u001b[0;36m_correlate_or_convolve\u001b[0;34m(input, weights, output, mode, cval, origin, convolution, axes)\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sequence of modes is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    871\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[0;32m--> 872\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m temp_needed:\n\u001b[1;32m    874\u001b[0m     temp[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filter_data_map = dict()\n",
    "\n",
    "for i in tqdm(range(len(filters))):\n",
    "    transformed = []\n",
    "    for j in range(len(filters[i])):   \n",
    "        curr_transformed = []    \n",
    "        fil = filters[i][j]\n",
    "        for k, image in enumerate(images):\n",
    "            convolved = apply_filter(image, fil)\n",
    "            curr_transformed.append(convolved.flatten())\n",
    "\n",
    "        curr_transformed = np.hstack(curr_transformed)\n",
    "        transformed = np.concatenate((transformed, curr_transformed))\n",
    "    \n",
    "    # select max of CONSTANT_SAMPLE_SIZE coefs\n",
    "    transformed = np.sort(transformed)[np.round(np.linspace(0, transformed.size - 1, min(transformed.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "    filter_data_map[i] = transformed\n",
    "\n",
    "filter_data_map[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f201e6",
   "metadata": {},
   "source": [
    "# Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without subsampling size: 196608000\n"
     ]
    }
   ],
   "source": [
    "data_output_file = os.path.join(ROOT_DIR, 'transformed-data', f\"{FINAL_DATA_NAME}-gabor.pickle\") \n",
    "size_output_file = os.path.join(ROOT_DIR, 'transformed-data', f\"{FINAL_DATA_NAME}-gabor-size.pickle\")\n",
    "\n",
    "total_samples = np.prod(images.shape)\n",
    "print(\"Without subsampling size:\", total_samples)\n",
    "print(\"With subsampling, per-filter:\", len(filter_data_map[0]))\n",
    "pd.to_pickle(filter_data_map, data_output_file)\n",
    "pd.to_pickle({i : total_samples for i in range(len(filter_data_map))}, size_output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
