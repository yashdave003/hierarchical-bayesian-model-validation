{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e81854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import scipy.ndimage as ndi\n",
    "import pandas as pd\n",
    "from skimage.filters import gabor_kernel\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from learned import *\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1f2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"syntheticMRI2D\"\n",
    "RAW_DATA_SUFFIX = \"full-cleaned 2\"\n",
    "FINAL_DATA_NAME = \"syntheticMRI2D-coronal-full\"\n",
    "PARAM_CSV = \"gabor_new.csv\"\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "\n",
    "num_images=1000\n",
    "jitter=False \n",
    "normalize=False \n",
    "\n",
    "#data_dir = os.path.join(ROOT_DIR, 'raw-data', DATASET, RAW_DATA_SUFFIX)\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data', RAW_DATA_SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b89233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_gabor_kernel_skimage_cached(frequency: float,\n",
    "                                          wave_number: int,\n",
    "                                          theta: float,\n",
    "                                          aspect_ratio: float,\n",
    "                                          dtype_str: str) -> np.ndarray:\n",
    "    if frequency <= 0:\n",
    "        raise ValueError(\"frequency must be positive (cycles/pixel).\")\n",
    "    \n",
    "    # choose n_stds explicitly (same value you pass to gabor_kernel; default is 3)\n",
    "    n_stds = 3\n",
    "    sigma_x = wave_number / (2.0 * n_stds * frequency)   # NOT 4*frequency\n",
    "    sigma_y = aspect_ratio * sigma_x\n",
    "    k_complex = gabor_kernel(frequency=frequency, theta=theta, sigma_x=sigma_x, sigma_y=sigma_y, n_stds=n_stds)\n",
    "\n",
    "    k = np.real(k_complex).astype(np.dtype(dtype_str), copy=False)\n",
    "    k -= k.mean()\n",
    "    nrm = np.linalg.norm(k.ravel())\n",
    "    if nrm > 1e-12:\n",
    "        k = k / nrm\n",
    "    return k\n",
    "\n",
    "def generate_gabor_kernel_skimage(frequency: float,\n",
    "                                  wave_number: int,\n",
    "                                  theta: float = 0.0,\n",
    "                                  aspect_ratio: float = 1.0,\n",
    "                                  dtype=np.float64) -> np.ndarray:\n",
    "    \"\"\"Public wrapper returning a copy to avoid accidental mutation of cached data.\"\"\"\n",
    "    arr = _generate_gabor_kernel_skimage_cached(\n",
    "        float(frequency), int(wave_number), float(theta),\n",
    "        float(aspect_ratio), np.dtype(dtype).name\n",
    "    )\n",
    "    if arr is not None:\n",
    "        return arr.copy()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea3ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 47)\n",
      "1 6\n"
     ]
    }
   ],
   "source": [
    "param_df = pd.read_csv(os.path.join(ROOT_DIR, \"gabor\", PARAM_CSV))\n",
    "# param_df = pd.read_csv(os.path.join(ROOT_DIR, \"gabor\", \"gabor_test.csv\"))\n",
    "\n",
    "orientations = [0, np.pi/6, np.pi/3, np.pi/2, 2*np.pi/3, 5*np.pi/6]\n",
    "\n",
    "filters = []\n",
    "for i in range(len(param_df)):\n",
    "    fil_orients = []\n",
    "\n",
    "    for j in range(len(orientations)):\n",
    "        fil = generate_gabor_kernel_skimage(param_df[\"frequency\"][i], param_df[\"wave_number\"][i], orientations[j], param_df[\"aspect_ratio\"][i])\n",
    "        if fil is not None:\n",
    "            fil_orients.append(fil)\n",
    "    \n",
    "    filters.append(fil_orients)\n",
    "\n",
    "#TODO\n",
    "filters = [filters[0]]\n",
    "\n",
    "print(filters[0][0].shape)\n",
    "print(len(filters), len(filters[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c98eae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0, params: (2.0, 0.5, 0.044), orientation: 0.000, size: (25, 47)\n",
      "index: 0, params: (2.0, 0.5, 0.044), orientation: 0.524, size: (25, 41)\n",
      "index: 0, params: (2.0, 0.5, 0.044), orientation: 1.047, size: (41, 25)\n",
      "index: 0, params: (2.0, 0.5, 0.044), orientation: 1.571, size: (47, 25)\n",
      "index: 0, params: (2.0, 0.5, 0.044), orientation: 2.094, size: (41, 25)\n",
      "index: 0, params: (2.0, 0.5, 0.044), orientation: 2.618, size: (25, 41)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filters)):\n",
    "    for j in range(len(filters[i])):\n",
    "        print(f\"index: {i}, params: {tuple(param_df.loc[i])[1:]}, orientation: {orientations[j]:.3f}, size: {filters[i][j].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781fff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9d42195c6c430f8cc468221a25de17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading images:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_images, H, W, channels: (10, 369, 369) \n",
      "num_filters 1\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "num_images = 10\n",
    "\n",
    "images = load_images_from_directory(data_dir, n=num_images, jitter=jitter, normalize=normalize)\n",
    "print(\"num_images, H, W, channels:\", images.shape, \"\\nnum_filters\", len(filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89f45a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT doesn't work with NaNs\n",
    "def apply_filter(image, filter):\n",
    "    \"\"\"\n",
    "    Applies Gabor filter to the input RGB image.\n",
    "    \"\"\"\n",
    "    # print(image.shape)\n",
    "    # print(filter.shape)\n",
    "    out = np.zeros_like(image)\n",
    "\n",
    "    if image.ndim == 2:\n",
    "        out = ndi.convolve(\n",
    "            image,\n",
    "            filter,\n",
    "            mode='reflect'\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        C = image.shape[2]\n",
    "        for ch in range(C):\n",
    "            out[:, :, ch] = ndi.convolve(\n",
    "                image[:, :, ch],\n",
    "                filter,\n",
    "                mode='reflect'\n",
    "            )\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f34c4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae6f421881449cb8a0449d9f822b918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN proportion: 0.3695918802006448\n",
      "NaN proportion: 0.3875705965731744\n",
      "NaN proportion: 0.34377685240267036\n",
      "NaN proportion: 0.37886766401539357\n",
      "NaN proportion: 0.3843685049316618\n",
      "NaN proportion: 0.34959349593495936\n",
      "NaN proportion: 0.3648695294541021\n",
      "NaN proportion: 0.3760254404712069\n",
      "NaN proportion: 0.37012066597630744\n",
      "NaN proportion: 0.36130756971526357\n",
      "NaN proportion: 0.37709770051630054\n",
      "NaN proportion: 0.3514883116310838\n",
      "NaN proportion: 0.39104442534940254\n",
      "NaN proportion: 0.3857271906052394\n",
      "NaN proportion: 0.3916466535939072\n",
      "NaN proportion: 0.4059679350181036\n",
      "NaN proportion: 0.3944521559036729\n",
      "NaN proportion: 0.3963690043404499\n",
      "NaN proportion: 0.4112778255153825\n",
      "NaN proportion: 0.3659931992273852\n",
      "NaN proportion: 0.3511945417557157\n",
      "NaN proportion: 0.3967729379190811\n",
      "NaN proportion: 0.3916466535939072\n",
      "NaN proportion: 0.39104442534940254\n",
      "NaN proportion: 0.37709770051630054\n",
      "NaN proportion: 0.33541909944844706\n",
      "NaN proportion: 0.33432480666270076\n",
      "NaN proportion: 0.36130756971526357\n",
      "NaN proportion: 0.34959349593495936\n",
      "NaN proportion: 0.3744904928724084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1459.3129873 , -1358.77534372, -1305.00933066, ...,\n",
       "        1305.00933066,  1358.77534372,  1459.3129873 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_data_map = dict()\n",
    "images_per_orient = 166 # ~= 1000 / 6\n",
    "\n",
    "#TODO\n",
    "images_per_orient = 5\n",
    "\n",
    "for i in tqdm(range(len(filters))):\n",
    "    transformed = []\n",
    "    for j in range(len(filters[i])):   \n",
    "        curr_transformed = []    \n",
    "        fil = filters[i][j]\n",
    "\n",
    "        indices = np.random.choice(len(images), size=images_per_orient, replace=False)\n",
    "        image_orient_subset = images[indices]\n",
    "\n",
    "        for k, image in enumerate(image_orient_subset):\n",
    "            convolved = apply_filter(image, fil)\n",
    "\n",
    "            #handle NaNs\n",
    "            print(f\"NaN proportion: {np.sum(np.isnan(convolved.flatten())) / len(convolved.flatten())}\")\n",
    "            convolved = convolved[~np.isnan(convolved)]\n",
    "\n",
    "            curr_transformed.append(convolved.flatten())\n",
    "\n",
    "        #handle NaNs\n",
    "        if len(curr_transformed) == 0:\n",
    "            continue\n",
    "\n",
    "        curr_transformed = np.hstack(curr_transformed)\n",
    "\n",
    "        # intermediate subsample to limit size\n",
    "        curr_transformed = np.sort(curr_transformed)[np.round(np.linspace(0, curr_transformed.size - 1, min(curr_transformed.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "        transformed = np.concatenate((transformed, curr_transformed))\n",
    "\n",
    "    # append the negation of all coefficients to account for other orientations\n",
    "    neg_transformed = -1 * transformed\n",
    "    transformed = np.concatenate((transformed, neg_transformed))\n",
    "    \n",
    "    # select max of CONSTANT_SAMPLE_SIZE coefs\n",
    "    transformed = np.sort(transformed)[np.round(np.linspace(0, transformed.size - 1, min(transformed.size, CONSTANT_SAMPLE_SIZE))).astype(int)]\n",
    "    filter_data_map[i] = transformed\n",
    "\n",
    "filter_data_map[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f201e6",
   "metadata": {},
   "source": [
    "# Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without subsampling size: 786432000\n",
      "With subsampling, per-filter: 100000\n"
     ]
    }
   ],
   "source": [
    "data_output_file = os.path.join(ROOT_DIR, 'transformed-data', f\"{FINAL_DATA_NAME}-gabor.pickle\") \n",
    "size_output_file = os.path.join(ROOT_DIR, 'transformed-data', f\"{FINAL_DATA_NAME}-gabor-size.pickle\")\n",
    "\n",
    "total_samples = np.prod(images.shape)\n",
    "print(\"Without subsampling size:\", total_samples)\n",
    "print(\"With subsampling, per-filter:\", len(filter_data_map[0]))\n",
    "pd.to_pickle(filter_data_map, data_output_file)\n",
    "pd.to_pickle({i : total_samples for i in range(len(filter_data_map))}, size_output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
