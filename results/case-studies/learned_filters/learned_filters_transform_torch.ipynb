{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install torch\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'coco-full-indoor-learned'\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data', DATASET, \"coco-indoor-cropped-normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Load pretrained AlexNet\n",
    "alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "alexnet.eval()  # set to evaluation mode\n",
    "\n",
    "# Extract the first convolutional layer filters\n",
    "first_conv = alexnet.features[0]\n",
    "filters = first_conv.weight.data.clone().cpu().numpy()  # shape: [out_channels, in_channels, height, width]\n",
    "\n",
    "filter_groups = {\n",
    "    \"single_edge\": [3, 6, 10, 11, 12, 13, 14, 23, 24, 28, 29, 30, 32, 34, 43, 48, 49, 50, 55, 57], #gabor-like / edge detector\n",
    "    \"multi_edge\": [9, 16, 18, 22, 25, 27, 33, 41, 54, 63], #complex gabor / complex edge detector\n",
    "    \"eye\": [21, 31, 37, 39, 45, 46,], # color contrast\n",
    "    \"dual_color\": [0, 2, 4, 5, 17, 20, 26, 38, 42, 44, 47, 56, 59], # color contrast\n",
    "    \"inside_out\": [7, 15, 19, 35, 40, 51, 52, 53, 58], # smoothing\n",
    "    \"misc\": [1, 8, 36, 60, 61, 62] # misc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_learned_filters(image, filters):\n",
    "    \"\"\"\n",
    "    image: a numpy array of shape (H, W, 3) in range [0, 255] or normalized appropriately.\n",
    "    filters: numpy array of shape (num_filters, in_channels, kH, kW).\n",
    "    Returns: list of feature maps (one per filter).\n",
    "    \"\"\"\n",
    "    # Ensure image is normalized to [0, 1]\n",
    "    if image.max() > 1:\n",
    "        image = image / 255.0\n",
    "\n",
    "    # Convert image to shape (1, 3, H, W)\n",
    "    image = np.transpose(image, (2, 0, 1))[np.newaxis, ...]\n",
    "\n",
    "    # Perform convolution using numpy\n",
    "    feature_maps = []\n",
    "    for filter in filters:\n",
    "        feature_map = np.zeros_like(image[0, 0])\n",
    "        for c in range(filter.shape[0]):  # Iterate over channels\n",
    "            feature_map += np.convolve(image[0, c], filter[c], mode='constant')\n",
    "        feature_maps.append(feature_map)\n",
    "    \n",
    "    return np.array(feature_maps)  # shape: (num_filters, H_out, W_out)\n",
    "\n",
    "\n",
    "def apply_learned_filters_batch(images, filters):\n",
    "    \"\"\"\n",
    "    images: NumPy array of shape (N, H, W, 3) or list of images in HWC format, dtype float32 or uint8.\n",
    "    filters: NumPy array of shape (num_filters, in_channels, kH, kW).\n",
    "    Returns: numpy array of shape (N, num_filters, H_out, W_out)\n",
    "    \"\"\"\n",
    "    # Ensure images are normalized to [0, 1]\n",
    "    if images.max() > 1:\n",
    "        images = images / 255.0\n",
    "\n",
    "    # Convert images to shape (N, 3, H, W)\n",
    "    images = np.transpose(images, (0, 3, 1, 2))\n",
    "\n",
    "    # Perform convolution for each image\n",
    "    batch_feature_maps = []\n",
    "    for image in images:\n",
    "        feature_maps = []\n",
    "        for filter in filters:\n",
    "            feature_map = np.zeros_like(image[0])\n",
    "            for c in range(filter.shape[0]):  # Iterate over channels\n",
    "                feature_map += np.convolve(image[c], filter[c], mode='constant')\n",
    "            feature_maps.append(feature_map)\n",
    "        batch_feature_maps.append(feature_maps)\n",
    "    \n",
    "    return np.array(batch_feature_maps)  # shape: (N, num_filters, H_out, W_out)\n",
    "\n",
    "\n",
    "def load_images_from_directory(directory, n=None, pastis=False):\n",
    "    \"\"\"\n",
    "    Loads images from a directory in .npz format.\n",
    "    \"\"\"\n",
    "    if not n:\n",
    "        n = len(os.listdir(directory))\n",
    "    images = []\n",
    "    for filename in os.listdir(directory)[:n]:\n",
    "        if filename.endswith('.npz'):\n",
    "            img = np.load(os.path.join(directory, filename))['image'].astype(np.float32)\n",
    "        else:\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def transform_images(images, filters):\n",
    "    \"\"\"\n",
    "    images: list or np.array of (N, H, W, 3)\n",
    "    filters: numpy array of shape (num_filters, in_channels, kH, kW)\n",
    "    \"\"\"\n",
    "    # Apply filters in batch\n",
    "    feature_maps = apply_learned_filters_batch(images, filters)  # (N, num_filters, H_out, W_out)\n",
    "\n",
    "    # Flatten per-filter results across all images\n",
    "    num_filters = feature_maps.shape[1]\n",
    "    feature_maps = feature_maps.transpose(1, 0, 2, 3)  # (num_filters, N, H_out, W_out)\n",
    "    flattened = feature_maps.reshape(num_filters, -1)  # Each row: all outputs of one filter\n",
    "\n",
    "    return flattened  # shape: (num_filters, total_pixels_across_all_images)\n",
    "\n",
    "\n",
    "def bootstrap_skew(data, n_bootstrap=10000, sample_size=20000):\n",
    "    \"\"\"\n",
    "    Bootstrap the skewness of the data to compute a confidence interval.\n",
    "    \"\"\"\n",
    "    if len(data) > sample_size:\n",
    "        data = np.random.choice(data, size=sample_size, replace=False)  # Downsample\n",
    "    bootstrapped_skews = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrapped_skews.append(skew(sample))\n",
    "    return np.percentile(bootstrapped_skews, [2.5, 97.5])\n",
    "\n",
    "\n",
    "def run_skew_test_with_filters(all_group_coef, filter_groups, filters, n_bootstrap=10000, sample_size=20000):\n",
    "    \"\"\"\n",
    "    Run skewness test with filters.\n",
    "    \"\"\"\n",
    "    skewed_data = []\n",
    "    nonskewed_data = []\n",
    "    skewed_groups = [] \n",
    "    nonskewed_groups = []\n",
    "    skewed_indices = [] \n",
    "    nonskewed_indices = []\n",
    "\n",
    "    for group in all_group_coef.keys():\n",
    "        for i in range(len(all_group_coef[group])):\n",
    "            coefficients = all_group_coef[group][i].flatten()\n",
    "            ci = bootstrap_skew(coefficients, n_bootstrap=n_bootstrap, sample_size=sample_size)\n",
    "\n",
    "            # Test if 0 is outside the CI\n",
    "            if ci[0] > 0 or ci[1] < 0:\n",
    "                skewed_data.append(coefficients)\n",
    "                skewed_groups.append(group)\n",
    "                skewed_indices.append(filter_groups[group][i])\n",
    "            else:\n",
    "                nonskewed_data.append(coefficients)\n",
    "                nonskewed_groups.append(group)\n",
    "                nonskewed_indices.append(filter_groups[group][i])\n",
    "\n",
    "    return skewed_data, nonskewed_data, skewed_groups, nonskewed_groups, skewed_indices, nonskewed_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_learned_filters(image, filters, device='cpu'):\n",
    "#     \"\"\"\n",
    "#     image: a numpy array of shape (H, W, 3) in range [0, 255] or normalized appropriately.\n",
    "#     filters: numpy array of shape (num_filters, in_channels, kH, kW).\n",
    "#     Returns: list of feature maps (one per filter).\n",
    "#     \"\"\"\n",
    "#     # Convert image to a tensor and add batch dimension: shape [1, 3, H, W]\n",
    "#     # Assume image is in HxWxC format and normalized [0,1].\n",
    "#     transform = transforms.ToTensor()  # converts to range [0, 1] and shape (C, H, W)\n",
    "#     image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "#     # Convert filters to torch tensor and place on the same device.\n",
    "#     filter_tensor = torch.tensor(filters, dtype=torch.float32).to(device)\n",
    "    \n",
    "#     # Convolve the image with all filters.\n",
    "#     feature_maps = F.conv2d(image_tensor, filter_tensor, bias=None, stride=1, padding=first_conv.padding)\n",
    "    \n",
    "#     # feature_maps shape: [1, num_filters, H_out, W_out]\n",
    "#     return feature_maps.squeeze(0).cpu().detach().numpy()  # shape: (num_filters, H_out, W_out)\n",
    "\n",
    "# def apply_learned_filters_batch(images, filters, device='cpu'):\n",
    "#     \"\"\"\n",
    "#     images: NumPy array of shape (N, H, W, 3) or list of images in HWC format, dtype float32 or uint8.\n",
    "#     filters: NumPy array of shape (num_filters, in_channels, kH, kW).\n",
    "#     Returns: torch tensor of shape (N, num_filters, H_out, W_out)\n",
    "#     \"\"\"\n",
    "#     # Convert to torch tensor: shape (N, C, H, W)\n",
    "#     images = torch.stack([transforms.ToTensor()(img) for img in images])  # (N, 3, H, W)\n",
    "#     images = images.to(device)\n",
    "\n",
    "#     # Convert filters to tensor\n",
    "#     filter_tensor = torch.tensor(filters, dtype=torch.float32).to(device)\n",
    "\n",
    "#     # Run batch convolution (groups=1, so apply all filters to each image)\n",
    "#     feature_maps = F.conv2d(images, filter_tensor, bias=None, stride=1, padding='same')  # or customize padding\n",
    "\n",
    "#     return feature_maps.cpu().detach()  # shape: (N, num_filters, H_out, W_out)\n",
    "\n",
    "\n",
    "# def load_images_from_directory(directory, n=None, pastis=False):\n",
    "#     \"\"\"\n",
    "#     Loads images from a directory.\n",
    "#     \"\"\"\n",
    "#     if not n:\n",
    "#         n = len(os.listdir(directory))\n",
    "#     images = []\n",
    "#     for filename in os.listdir(directory)[:n]:\n",
    "#         if pastis:\n",
    "#             img = np.load(os.path.join(directory, filename))[\"image\"].astype(np.float32)\n",
    "#         else:\n",
    "#             img = cv2.imread(os.path.join(directory, filename))\n",
    "#         images.append(img)\n",
    "#     return np.array(images)\n",
    "\n",
    "# def transform_images(images, filters, device='cpu'):\n",
    "#     \"\"\"\n",
    "#     images: list or np.array of (N, H, W, 3)\n",
    "#     filters: numpy array of shape (num_filters, in_channels, kH, kW)\n",
    "#     \"\"\"\n",
    "#     # Apply filters in batch\n",
    "#     feature_maps = apply_learned_filters_batch(images, filters, device)  # (N, num_filters, H_out, W_out)\n",
    "\n",
    "#     # Flatten per-filter results across all images\n",
    "#     num_filters = feature_maps.shape[1]\n",
    "#     feature_maps = feature_maps.permute(1, 0, 2, 3)  # (num_filters, N, H_out, W_out)\n",
    "#     flattened = feature_maps.reshape(num_filters, -1)  # Each row: all outputs of one filter\n",
    "\n",
    "#     return flattened.numpy()  # shape: (num_filters, total_pixels_across_all_images)\n",
    "\n",
    "# def bootstrap_skew(data, n_bootstrap=10000, sample_size=20000):\n",
    "#     # From each filter distribution of around 600k coefficients, take a random sample of sample_size, and then bootstrap n_bootsrap times\n",
    "#     \"\"\"Bootstrap the skewness of the data to compute a confidence interval.\"\"\"\n",
    "#     if len(data) > sample_size:\n",
    "#         data = np.random.choice(data, size=sample_size, replace=False)  # Downsample\n",
    "#     bootstrapped_skews = []\n",
    "#     for _ in range(n_bootstrap):\n",
    "#         sample = np.random.choice(data, size=len(data), replace=True)\n",
    "#         bootstrapped_skews.append(skew(sample))\n",
    "#     return np.percentile(bootstrapped_skews, [2.5, 97.5])\n",
    "\n",
    "# def run_skew_test_with_filters(all_group_coef, filter_groups, filters, n_bootstrap=10000, sample_size=20000):\n",
    "#     skewed_data = []\n",
    "#     nonskewed_data = []\n",
    "#     skewed_groups = [] \n",
    "#     nonskewed_groups = []\n",
    "#     skewed_indices = [] # Alex Indices\n",
    "#     nonskewed_indices = []\n",
    "\n",
    "#     for group in all_group_coef.keys():\n",
    "#         for i in range(len(all_group_coef[group])):\n",
    "#             coefficients = all_group_coef[group][i].flatten()\n",
    "#             ci = bootstrap_skew(coefficients, n_bootstrap=n_bootstrap, sample_size=sample_size)\n",
    "\n",
    "#             # Test if 0 is outside the CI\n",
    "#             if ci[0] > 0 or ci[1] < 0:\n",
    "#                 skewed_data.append(coefficients)\n",
    "#                 skewed_groups.append(group)\n",
    "#                 skewed_indices.append(filter_groups[group][i])\n",
    "#             else:\n",
    "#                 nonskewed_data.append(coefficients)\n",
    "#                 #nonskewed_labels.append(f'{label}, CI: [{ci[0]:.3f}, {ci[1]:.3f}]')\n",
    "#                 nonskewed_groups.append(group)\n",
    "#                 nonskewed_indices.append(filter_groups[group][i])\n",
    "\n",
    "#     return skewed_data, nonskewed_data, skewed_groups, nonskewed_groups, skewed_indices, nonskewed_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mode must be one of 'valid', 'same', or 'full' (got 'constant')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m images \u001b[38;5;241m=\u001b[39m load_images_from_directory(data_dir)\n\u001b[0;32m      2\u001b[0m filter_groups_coef \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     key: filters[val] \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m filter_groups\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m      4\u001b[0m }\n\u001b[1;32m----> 6\u001b[0m group_transform_coef \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_groups_coef\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilter_groups_coef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m      8\u001b[0m skewed_data, nonskewed_data, skewed_groups, nonskewed_groups, skewed_indices, nonskewed_indices \u001b[38;5;241m=\u001b[39m run_skew_test_with_filters(\n\u001b[0;32m      9\u001b[0m     group_transform_coef, filter_groups, filters, n_bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[1;32mIn[38], line 6\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m images \u001b[38;5;241m=\u001b[39m load_images_from_directory(data_dir)\n\u001b[0;32m      2\u001b[0m filter_groups_coef \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     key: filters[val] \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m filter_groups\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m      4\u001b[0m }\n\u001b[1;32m----> 6\u001b[0m group_transform_coef \u001b[38;5;241m=\u001b[39m {group: \u001b[43mtransform_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_groups_coef\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m filter_groups_coef\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[0;32m      8\u001b[0m skewed_data, nonskewed_data, skewed_groups, nonskewed_groups, skewed_indices, nonskewed_indices \u001b[38;5;241m=\u001b[39m run_skew_test_with_filters(\n\u001b[0;32m      9\u001b[0m     group_transform_coef, filter_groups, filters, n_bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[1;32mIn[35], line 74\u001b[0m, in \u001b[0;36mtransform_images\u001b[1;34m(images, filters)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03mimages: list or np.array of (N, H, W, 3)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03mfilters: numpy array of shape (num_filters, in_channels, kH, kW)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Apply filters in batch\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m feature_maps \u001b[38;5;241m=\u001b[39m \u001b[43mapply_learned_filters_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (N, num_filters, H_out, W_out)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Flatten per-filter results across all images\u001b[39;00m\n\u001b[0;32m     77\u001b[0m num_filters \u001b[38;5;241m=\u001b[39m feature_maps\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[35], line 45\u001b[0m, in \u001b[0;36mapply_learned_filters_batch\u001b[1;34m(images, filters)\u001b[0m\n\u001b[0;32m     43\u001b[0m     feature_map \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(image[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):  \u001b[38;5;66;03m# Iterate over channels\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m         feature_map \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     feature_maps\u001b[38;5;241m.\u001b[39mappend(feature_map)\n\u001b[0;32m     47\u001b[0m batch_feature_maps\u001b[38;5;241m.\u001b[39mappend(feature_maps)\n",
      "File \u001b[1;32mc:\\Users\\yashd\\.conda\\envs\\hbmv_backup2\\Lib\\site-packages\\numpy\\_core\\numeric.py:889\u001b[0m, in \u001b[0;36mconvolve\u001b[1;34m(a, v, mode)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: mode must be one of 'valid', 'same', or 'full' (got 'constant')"
     ]
    }
   ],
   "source": [
    "images = load_images_from_directory(data_dir)\n",
    "filter_groups_coef = {\n",
    "    key: filters[val] for key, val in filter_groups.items()\n",
    "}\n",
    "\n",
    "group_transform_coef = {group: transform_images(images, filter_groups_coef[group]) for group in filter_groups_coef.keys()}\n",
    "\n",
    "skewed_data, nonskewed_data, skewed_groups, nonskewed_groups, skewed_indices, nonskewed_indices = run_skew_test_with_filters(\n",
    "    group_transform_coef, filter_groups, filters, n_bootstrap=100, sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>total_filters</th>\n",
       "      <th>passed_skew_test</th>\n",
       "      <th>proportion_passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>single_edge</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multi_edge</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eye</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dual_color</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inside_out</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>misc</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group  total_filters  passed_skew_test  proportion_passed\n",
       "0  single_edge             20                 3              0.150\n",
       "1   multi_edge             10                 0              0.000\n",
       "2          eye              6                 0              0.000\n",
       "3   dual_color             13                 0              0.000\n",
       "4   inside_out              9                 0              0.000\n",
       "5         misc              6                 0              0.000\n",
       "6          all             64                 3              0.047"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skew Test Summary\n",
    "\n",
    "total_filters = {group: len(filters) for group, filters in filter_groups.items()}\n",
    "\n",
    "passed_counts = defaultdict(int)\n",
    "for group in nonskewed_groups:\n",
    "    passed_counts[group] += 1\n",
    "\n",
    "summary = []\n",
    "for group in total_filters:\n",
    "    total = total_filters[group]\n",
    "    passed = passed_counts.get(group, 0)\n",
    "    failed = total - passed\n",
    "    summary.append((group, total, passed, failed))\n",
    "\n",
    "summary_df = pd.DataFrame(summary, columns=[\n",
    "    \"group\", \"total_filters\", \"passed_skew_test\", \"failed_skew_test\"\n",
    "])\n",
    "\n",
    "summary_df = summary_df.drop(columns=[\"failed_skew_test\"])\n",
    "\n",
    "summary_df[\"proportion_passed\"] = np.round(summary_df[\"passed_skew_test\"] / summary_df[\"total_filters\"], 3)\n",
    "\n",
    "# Calculate sums for each numeric column\n",
    "summary_totals = summary_df[[\"total_filters\", \"passed_skew_test\"]].sum()\n",
    "\n",
    "# Create new row with label 'all' and the totals\n",
    "all_row = pd.DataFrame([{\n",
    "    \"group\": \"all\",\n",
    "    \"total_filters\": summary_totals[\"total_filters\"],\n",
    "    \"passed_skew_test\": summary_totals[\"passed_skew_test\"],\n",
    "    \"proportion_passed\": np.round(summary_totals[\"passed_skew_test\"] / summary_totals[\"total_filters\"], 3)\n",
    "}])\n",
    "\n",
    "# Append to the summary DataFrame\n",
    "summary_df_with_total = pd.concat([summary_df, all_row], ignore_index=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "summary_df_with_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_file = os.path.join(ROOT_DIR, 'transformed-data', FINAL_DATA_NAME) + \".pickle\"\n",
    "size_output_file = os.path.join(ROOT_DIR, 'transformed-data', FINAL_DATA_NAME + \"-size\") + \".pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alex_idx</th>\n",
       "      <th>group</th>\n",
       "      <th>group_idx</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.025653917342424393, 0.055067531764507294, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.39415326714515686, -0.37656694650650024, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.6912024021148682, -1.6043668985366821, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alex_idx        group  group_idx  \\\n",
       "0         3  single_edge          0   \n",
       "1         6  single_edge          1   \n",
       "2        10  single_edge          2   \n",
       "\n",
       "                                                data  \n",
       "0  [0.025653917342424393, 0.055067531764507294, 0...  \n",
       "1  [-0.39415326714515686, -0.37656694650650024, -...  \n",
       "2  [-1.6912024021148682, -1.6043668985366821, -1....  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for i in range(len(nonskewed_data)):\n",
    "    group = nonskewed_groups[i]\n",
    "    alex_idx = nonskewed_indices[i]\n",
    "    id_in_group = filter_groups[group].index(alex_idx) if alex_idx in filter_groups[group] else None\n",
    "    coefs = group_transform_coef[group][id_in_group]\n",
    "    rows.append({\n",
    "        'alex_idx': alex_idx,\n",
    "        'group': group,\n",
    "        'group_idx': id_in_group,\n",
    "        'data': coefs\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312500,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"data\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alex_idx</th>\n",
       "      <th>group</th>\n",
       "      <th>group_idx</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>0</td>\n",
       "      <td>312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>1</td>\n",
       "      <td>312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>2</td>\n",
       "      <td>312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alex_idx        group  group_idx    size\n",
       "0         3  single_edge          0  312500\n",
       "1         6  single_edge          1  312500\n",
       "2        10  single_edge          2  312500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_size_counts = df['data'].apply(len)\n",
    "size_df = df.copy().drop(columns = ['data'])\n",
    "size_df['size'] = group_size_counts\n",
    "size_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient data has been saved to /Users/michaelmurphy/Documents/GitHub/hierarchical-bayesian-model-validation/transformed-data/toy-coco-cropped-allObjects-learned.pickle\n",
      "size data has been saved to /Users/michaelmurphy/Documents/GitHub/hierarchical-bayesian-model-validation/transformed-data/toy-coco-cropped-allObjects-learned-size.pickle\n"
     ]
    }
   ],
   "source": [
    "# Save the nonskewed_data to a pickle file\n",
    "with open(data_output_file, \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"coefficient data has been saved to {data_output_file}\")\n",
    "\n",
    "with open(size_output_file, \"wb\") as f:\n",
    "    pickle.dump(size_df, f)\n",
    "\n",
    "print(f\"size data has been saved to {size_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_backup2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
