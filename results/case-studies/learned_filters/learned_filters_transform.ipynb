{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"coco\"\n",
    "FINAL_DATA_NAME = 'toy-coco-cropped-allObjects-learned'\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'dataset-preparation', 'raw-data', DATASET, \"toy-coco-cropped-allObjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Load pretrained AlexNet\n",
    "alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "alexnet.eval()  # set to evaluation mode\n",
    "\n",
    "# Extract the first convolutional layer filters\n",
    "first_conv = alexnet.features[0]\n",
    "filters = first_conv.weight.data.clone().cpu().numpy()  # shape: [out_channels, in_channels, height, width]\n",
    "\n",
    "filter_groups = {\n",
    "    \"single_edge\": [3, 6, 10, 11, 12, 13, 14, 23, 24, 28, 29, 30, 32, 34, 43, 48, 49, 50, 55, 57], #gabor-like / edge detector\n",
    "    \"multi_edge\": [9, 16, 18, 22, 25, 27, 33, 41, 54, 63], #complex gabor / complex edge detector\n",
    "    \"eye\": [21, 31, 37, 39, 45, 46,], # color contrast\n",
    "    \"dual_color\": [0, 2, 4, 5, 17, 20, 26, 38, 42, 44, 47, 56, 59], # color contrast\n",
    "    \"inside_out\": [7, 15, 19, 35, 40, 51, 52, 53, 58], # smoothing\n",
    "    \"misc\": [1, 8, 36, 60, 61, 62] # misc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_learned_filters(image, filters, device='cpu'):\n",
    "    \"\"\"\n",
    "    image: a numpy array of shape (H, W, 3) in range [0, 255] or normalized appropriately.\n",
    "    filters: numpy array of shape (num_filters, in_channels, kH, kW).\n",
    "    Returns: list of feature maps (one per filter).\n",
    "    \"\"\"\n",
    "    # Convert image to a tensor and add batch dimension: shape [1, 3, H, W]\n",
    "    # Assume image is in HxWxC format and normalized [0,1].\n",
    "    transform = transforms.ToTensor()  # converts to range [0, 1] and shape (C, H, W)\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Convert filters to torch tensor and place on the same device.\n",
    "    filter_tensor = torch.tensor(filters, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Convolve the image with all filters.\n",
    "    feature_maps = F.conv2d(image_tensor, filter_tensor, bias=None, stride=1, padding=first_conv.padding)\n",
    "    \n",
    "    # feature_maps shape: [1, num_filters, H_out, W_out]\n",
    "    return feature_maps.squeeze(0).cpu().detach().numpy()  # shape: (num_filters, H_out, W_out)\n",
    "\n",
    "def apply_learned_filters_batch(images, filters, device='cpu'):\n",
    "    \"\"\"\n",
    "    images: NumPy array of shape (N, H, W, 3) or list of images in HWC format, dtype float32 or uint8.\n",
    "    filters: NumPy array of shape (num_filters, in_channels, kH, kW).\n",
    "    Returns: torch tensor of shape (N, num_filters, H_out, W_out)\n",
    "    \"\"\"\n",
    "    # Convert to torch tensor: shape (N, C, H, W)\n",
    "    images = torch.stack([transforms.ToTensor()(img) for img in images])  # (N, 3, H, W)\n",
    "    images = images.to(device)\n",
    "\n",
    "    # Convert filters to tensor\n",
    "    filter_tensor = torch.tensor(filters, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Run batch convolution (groups=1, so apply all filters to each image)\n",
    "    feature_maps = F.conv2d(images, filter_tensor, bias=None, stride=1, padding='same')  # or customize padding\n",
    "\n",
    "    return feature_maps.cpu().detach()  # shape: (N, num_filters, H_out, W_out)\n",
    "\n",
    "\n",
    "def load_images_from_directory(directory, n=None, pastis=False):\n",
    "    \"\"\"\n",
    "    Loads images from a directory.\n",
    "    \"\"\"\n",
    "    if not n:\n",
    "        n = len(os.listdir(directory))\n",
    "    images = []\n",
    "    for filename in os.listdir(directory)[:n]:\n",
    "        if pastis:\n",
    "            img = np.load(os.path.join(directory, filename))[\"image\"].astype(np.float32)\n",
    "        else:\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "def transform_images(images, filters, device='cpu'):\n",
    "    \"\"\"\n",
    "    images: list or np.array of (N, H, W, 3)\n",
    "    filters: numpy array of shape (num_filters, in_channels, kH, kW)\n",
    "    \"\"\"\n",
    "    # Apply filters in batch\n",
    "    feature_maps = apply_learned_filters_batch(images, filters, device)  # (N, num_filters, H_out, W_out)\n",
    "\n",
    "    # Flatten per-filter results across all images\n",
    "    num_filters = feature_maps.shape[1]\n",
    "    feature_maps = feature_maps.permute(1, 0, 2, 3)  # (num_filters, N, H_out, W_out)\n",
    "    flattened = feature_maps.reshape(num_filters, -1)  # Each row: all outputs of one filter\n",
    "\n",
    "    return flattened.numpy()  # shape: (num_filters, total_pixels_across_all_images)\n",
    "\n",
    "def bootstrap_skew(data, n_bootstrap=10000, sample_size=20000):\n",
    "    # From each filter distribution of around 600k coefficients, take a random sample of sample_size, and then bootstrap n_bootsrap times\n",
    "    \"\"\"Bootstrap the skewness of the data to compute a confidence interval.\"\"\"\n",
    "    if len(data) > sample_size:\n",
    "        data = np.random.choice(data, size=sample_size, replace=False)  # Downsample\n",
    "    bootstrapped_skews = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrapped_skews.append(skew(sample))\n",
    "    return np.percentile(bootstrapped_skews, [2.5, 97.5])\n",
    "\n",
    "def run_skew_test_with_filters(all_group_coef, filter_groups, filters, n_bootstrap=10000, sample_size=20000):\n",
    "    skewed_data = []\n",
    "    nonskewed_data = []\n",
    "    skewed_groups = [] \n",
    "    nonskewed_groups = []\n",
    "    skewed_indices = [] # Alex Indices\n",
    "    nonskewed_indices = []\n",
    "\n",
    "    for group in all_group_coef.keys():\n",
    "        for i in range(len(all_group_coef[group])):\n",
    "            coefficients = all_group_coef[group][i].flatten()\n",
    "            ci = bootstrap_skew(coefficients, n_bootstrap=n_bootstrap, sample_size=sample_size)\n",
    "\n",
    "            # Test if 0 is outside the CI\n",
    "            if ci[0] > 0 or ci[1] < 0:\n",
    "                skewed_data.append(coefficients)\n",
    "                skewed_groups.append(group)\n",
    "                skewed_indices.append(filter_groups[group][i])\n",
    "            else:\n",
    "                nonskewed_data.append(coefficients)\n",
    "                #nonskewed_labels.append(f'{label}, CI: [{ci[0]:.3f}, {ci[1]:.3f}]')\n",
    "                nonskewed_groups.append(group)\n",
    "                nonskewed_indices.append(filter_groups[group][i])\n",
    "\n",
    "    return skewed_data, nonskewed_data, skewed_groups, nonskewed_groups, skewed_indices, nonskewed_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images_from_directory(data_dir)\n",
    "filter_groups_coef = {\n",
    "    key: filters[val] for key, val in filter_groups.items()\n",
    "}\n",
    "\n",
    "group_transform_coef = {group: transform_images(images, filter_groups_coef[group]) for group in filter_groups_coef.keys()}\n",
    "\n",
    "skewed_data, nonskewed_data, skewed_groups, nonskewed_groups, skewed_indices, nonskewed_indices = run_skew_test_with_filters(\n",
    "    group_transform_coef, filter_groups, filters, n_bootstrap=100, sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>total_filters</th>\n",
       "      <th>passed_skew_test</th>\n",
       "      <th>proportion_passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>single_edge</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multi_edge</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eye</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dual_color</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inside_out</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>misc</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group  total_filters  passed_skew_test  proportion_passed\n",
       "0  single_edge             20                 3              0.150\n",
       "1   multi_edge             10                 0              0.000\n",
       "2          eye              6                 0              0.000\n",
       "3   dual_color             13                 0              0.000\n",
       "4   inside_out              9                 0              0.000\n",
       "5         misc              6                 0              0.000\n",
       "6          all             64                 3              0.047"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skew Test Summary\n",
    "\n",
    "total_filters = {group: len(filters) for group, filters in filter_groups.items()}\n",
    "\n",
    "passed_counts = defaultdict(int)\n",
    "for group in nonskewed_groups:\n",
    "    passed_counts[group] += 1\n",
    "\n",
    "summary = []\n",
    "for group in total_filters:\n",
    "    total = total_filters[group]\n",
    "    passed = passed_counts.get(group, 0)\n",
    "    failed = total - passed\n",
    "    summary.append((group, total, passed, failed))\n",
    "\n",
    "summary_df = pd.DataFrame(summary, columns=[\n",
    "    \"group\", \"total_filters\", \"passed_skew_test\", \"failed_skew_test\"\n",
    "])\n",
    "\n",
    "summary_df = summary_df.drop(columns=[\"failed_skew_test\"])\n",
    "\n",
    "summary_df[\"proportion_passed\"] = np.round(summary_df[\"passed_skew_test\"] / summary_df[\"total_filters\"], 3)\n",
    "\n",
    "# Calculate sums for each numeric column\n",
    "summary_totals = summary_df[[\"total_filters\", \"passed_skew_test\"]].sum()\n",
    "\n",
    "# Create new row with label 'all' and the totals\n",
    "all_row = pd.DataFrame([{\n",
    "    \"group\": \"all\",\n",
    "    \"total_filters\": summary_totals[\"total_filters\"],\n",
    "    \"passed_skew_test\": summary_totals[\"passed_skew_test\"],\n",
    "    \"proportion_passed\": np.round(summary_totals[\"passed_skew_test\"] / summary_totals[\"total_filters\"], 3)\n",
    "}])\n",
    "\n",
    "# Append to the summary DataFrame\n",
    "summary_df_with_total = pd.concat([summary_df, all_row], ignore_index=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "summary_df_with_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_file = os.path.join(ROOT_DIR, 'transformed-data', FINAL_DATA_NAME) + \".pickle\"\n",
    "size_output_file = os.path.join(ROOT_DIR, 'transformed-data', FINAL_DATA_NAME + \"-size\") + \".pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alex_idx</th>\n",
       "      <th>group</th>\n",
       "      <th>group_idx</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.025653917342424393, 0.055067531764507294, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.39415326714515686, -0.37656694650650024, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.6912024021148682, -1.6043668985366821, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alex_idx        group  group_idx  \\\n",
       "0         3  single_edge          0   \n",
       "1         6  single_edge          1   \n",
       "2        10  single_edge          2   \n",
       "\n",
       "                                                data  \n",
       "0  [0.025653917342424393, 0.055067531764507294, 0...  \n",
       "1  [-0.39415326714515686, -0.37656694650650024, -...  \n",
       "2  [-1.6912024021148682, -1.6043668985366821, -1....  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for i in range(len(nonskewed_data)):\n",
    "    group = nonskewed_groups[i]\n",
    "    alex_idx = nonskewed_indices[i]\n",
    "    id_in_group = filter_groups[group].index(alex_idx) if alex_idx in filter_groups[group] else None\n",
    "    coefs = group_transform_coef[group][id_in_group]\n",
    "    rows.append({\n",
    "        'alex_idx': alex_idx,\n",
    "        'group': group,\n",
    "        'group_idx': id_in_group,\n",
    "        'data': coefs\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312500,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"data\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alex_idx</th>\n",
       "      <th>group</th>\n",
       "      <th>group_idx</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>0</td>\n",
       "      <td>312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>1</td>\n",
       "      <td>312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>single_edge</td>\n",
       "      <td>2</td>\n",
       "      <td>312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alex_idx        group  group_idx    size\n",
       "0         3  single_edge          0  312500\n",
       "1         6  single_edge          1  312500\n",
       "2        10  single_edge          2  312500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_size_counts = df['data'].apply(len)\n",
    "size_df = df.copy().drop(columns = ['data'])\n",
    "size_df['size'] = group_size_counts\n",
    "size_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient data has been saved to /Users/michaelmurphy/Documents/GitHub/hierarchical-bayesian-model-validation/transformed-data/toy-coco-cropped-allObjects-learned.pickle\n",
      "size data has been saved to /Users/michaelmurphy/Documents/GitHub/hierarchical-bayesian-model-validation/transformed-data/toy-coco-cropped-allObjects-learned-size.pickle\n"
     ]
    }
   ],
   "source": [
    "# Save the nonskewed_data to a pickle file\n",
    "with open(data_output_file, \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"coefficient data has been saved to {data_output_file}\")\n",
    "\n",
    "with open(size_output_file, \"wb\") as f:\n",
    "    pickle.dump(size_df, f)\n",
    "\n",
    "print(f\"size data has been saved to {size_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
